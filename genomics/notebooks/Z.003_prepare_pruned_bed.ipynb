{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load libraries\n",
    "from IPython.display import display, HTML\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "import numpy, scipy\n",
    "import plotnine as plt9\n",
    "import copy\n",
    "\n",
    "import os\n",
    "import subprocess\n",
    "\n",
    "version = %env WORKSPACE_CDR\n",
    "my_bucket = os.getenv('WORKSPACE_BUCKET')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !gsutil ls {my_bucket}/data/stg001/eur/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_dsub_status(user=None, full=False):\n",
    "    \"\"\"Check status of dsub jobs for the specified user\"\"\"\n",
    "    if user is None:\n",
    "        # Get current user if not specified\n",
    "        user = os.getenv(\"OWNER_EMAIL\").split('@')[0]\n",
    "    \n",
    "    project = os.getenv(\"GOOGLE_PROJECT\")\n",
    "\n",
    "    if full:\n",
    "        make_full = ' --full'\n",
    "    else:\n",
    "        make_full = ''\n",
    "    \n",
    "    cmd = f\"dstat --provider google-cls-v2 --user {user} --status '*' --project {project}{make_full}\"\n",
    "    # cmd = f\"ddel --provider google-cls-v2 --project terra-vpc-sc-840afe1e --location us-central1 --jobs 'transances--bwaxse--250319-022343-75' --users 'bwaxse'\"\n",
    "    print(f\"Running: {cmd}\")\n",
    "    return subprocess.run(cmd, shell=True, capture_output=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def job_details(user=None, job=None):\n",
    "    \"\"\"List all jobs for the user, including failed ones\"\"\"\n",
    "    project = os.getenv(\"GOOGLE_PROJECT\")\n",
    "    \n",
    "    if user is None:\n",
    "        user = os.getenv(\"OWNER_EMAIL\").split('@')[0]\n",
    "        \n",
    "    if job is None:\n",
    "        job = \"'*' \"\n",
    "    else:\n",
    "        job = f'--jobs {job} '\n",
    "    \n",
    "    cmd = f\"dstat --provider google-cls-v2 --project {project} --user {user} --status {job}--full\"\n",
    "    print(f\"Running: {cmd}\")\n",
    "    return subprocess.run(cmd, shell=True, capture_output=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cancel_running_jobs():\n",
    "    \"\"\"Cancel only running/pending jobs (safer)\"\"\"\n",
    "    project = os.getenv(\"GOOGLE_PROJECT\")\n",
    "    \n",
    "    # Cancel only running jobs\n",
    "    cancel_cmd = f\"ddel --provider google-cls-v2 --project {project} --users 'bwaxse' --jobs '*'\"\n",
    "    print(f\"Canceling running jobs: {cancel_cmd}\")\n",
    "    \n",
    "    return subprocess.run(cancel_cmd, shell=True, capture_output=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cancel_job(job_id):\n",
    "    \"\"\"Cancel a specific job\"\"\"\n",
    "    project = os.getenv(\"GOOGLE_PROJECT\")\n",
    "    \n",
    "    cmd = f\"ddel --provider google-cls-v2 --project {project} --jobs {job_id}\"\n",
    "    print(f\"Running: {cmd}\")\n",
    "    return subprocess.run(cmd, shell=True, capture_output=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variant filter script and function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile run_ld_prune_sequential.sh\n",
    "\n",
    "#!/bin/bash\n",
    "\n",
    "# Serial LD pruning per chromosome\n",
    "# Input: Multiple chromosome pgen files\n",
    "# Output: Multiple LD-pruned bed files per chromosome\n",
    "\n",
    "nthread=$(python -c \"import os; print(len(os.sched_getaffinity(0)))\");\n",
    "echo \"Running with $nthread threads\";\n",
    "\n",
    "# Parse output prefix\n",
    "OUTPUT_PREFIX=\"${OUTPUT_RESULTS%\\*}\"\n",
    "ancestry=$ANCESTRY\n",
    "start_chrom=$START_CHROM \n",
    "\n",
    "echo \"Processing ancestry: $ancestry\"\n",
    "echo \"Output prefix: $OUTPUT_PREFIX\"\n",
    "echo \"Starting from chromosome: $start_chrom\"\n",
    "\n",
    "# Process chromosomes serially - use seq instead of brace expansion\n",
    "for chrom in $(seq $start_chrom 22); do\n",
    "    echo \"LD pruning chromosome $chrom...\"\n",
    "    \n",
    "    # Download chromosome files for this iteration\n",
    "    echo \"Downloading chromosome $chrom files...\"\n",
    "    gsutil -u $GOOGLE_PROJECT cp \"${INPUT_PGEN_BASE_TEMPLATE//CHR_PLACEHOLDER/chr${chrom}}.pgen\" .\n",
    "    gsutil -u $GOOGLE_PROJECT cp \"${INPUT_PGEN_BASE_TEMPLATE//CHR_PLACEHOLDER/chr${chrom}}.psam\" .\n",
    "    gsutil -u $GOOGLE_PROJECT cp \"${INPUT_PGEN_BASE_TEMPLATE//CHR_PLACEHOLDER/chr${chrom}}.pvar\" .\n",
    "    \n",
    "    # Local input base\n",
    "    in_base=\"genotypes_chr${chrom}\"\n",
    "    out_full=\"${OUTPUT_PREFIX}${chrom}_pruned\"\n",
    "    \n",
    "    echo \"Processing: $in_base -> $out_full\"\n",
    "    \n",
    "    # Convert to bed format with exclusions (Step 1)\n",
    "    echo \"Step 1: Converting to BED and excluding high-LD regions...\"\n",
    "    plink2 \\\n",
    "        --pfile $in_base \\\n",
    "        --exclude bed1 ${EXCLUDE_BED} \\\n",
    "        --set-all-var-ids @:#:\\$r:\\$a \\\n",
    "        --new-id-max-allele-len 1000 \\\n",
    "        --make-bed \\\n",
    "        --memory ${MEMORY} \\\n",
    "        --threads $nthread \\\n",
    "        --out chr${chrom}_clean\n",
    "\n",
    "    # Check what IDs look like after cleaning\n",
    "    echo \"Sample variant IDs after cleaning:\"\n",
    "    head -5 chr${chrom}_clean.bim\n",
    "\n",
    "    # Count missing IDs\n",
    "    missing_ids=$(awk '$2==\".\" || $2==\"\" {count++} END {print count+0}' chr${chrom}_clean.bim)\n",
    "    echo \"Missing IDs after cleaning: $missing_ids\"\n",
    "\n",
    "    # LD pruning (Step 2) \n",
    "    echo \"Step 2: LD pruning...\"\n",
    "    plink2 \\\n",
    "        --bfile chr${chrom}_clean \\\n",
    "        --indep-pairwise ${WINDOW} ${STEP} ${R2} \\\n",
    "        --memory ${MEMORY} \\\n",
    "        --threads $nthread \\\n",
    "        --out chr${chrom}_prune\n",
    "\n",
    "    # Extract pruned SNPs (Step 3)\n",
    "    echo \"Step 3: Creating final pruned dataset...\"\n",
    "    plink2 \\\n",
    "        --bfile chr${chrom}_clean \\\n",
    "        --extract chr${chrom}_prune.prune.in \\\n",
    "        --make-bed \\\n",
    "        --memory ${MEMORY} \\\n",
    "        --threads $nthread \\\n",
    "        --out $out_full\n",
    "\n",
    "    # Copy pruning logs and lists (so dsub uploads them)\n",
    "    cp chr${chrom}_prune.log ${out_full}.prune.log\n",
    "    cp chr${chrom}_prune.prune.in ${out_full}.prune.in\n",
    "    cp chr${chrom}_prune.prune.out ${out_full}.prune.out\n",
    "\n",
    "    echo \"Completed LD pruning for chromosome $chrom\"\n",
    "    \n",
    "    # Remove input and intermediate files to save space\n",
    "    rm genotypes_chr${chrom}.pgen genotypes_chr${chrom}.psam genotypes_chr${chrom}.pvar\n",
    "    rm chr${chrom}_clean.bed chr${chrom}_clean.bim chr${chrom}_clean.fam\n",
    "    rm chr${chrom}_prune.prune.in chr${chrom}_prune.prune.out chr${chrom}_prune.log\n",
    "done\n",
    "\n",
    "echo \"Serial LD pruning complete for $ancestry\"\n",
    "echo \"Generated files:\"\n",
    "ls -la ${OUTPUT_PREFIX}*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # copy csv file to the bucket\n",
    "# args = [\"gsutil\", \"cp\", f\"./high-LD-regions-hg38-GRCh38.bed\", f\"{my_bucket}/data/\"]\n",
    "# output = subprocess.run(args, capture_output=True)\n",
    "\n",
    "# # print output from gsutil\n",
    "# output.stderr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_ld_prune(\n",
    "    my_bucket,\n",
    "    anc,\n",
    "    start_chrom=1,\n",
    "    script='run_ld_prune_sequential.sh',\n",
    "):\n",
    "    \"\"\"\n",
    "    Run LD pruning with serial chromosome processing\n",
    "    One job per ancestry, processes chromosomes serially\n",
    "    Outputs: 22 LD-pruned bed files per ancestry\n",
    "    \"\"\"\n",
    "\n",
    "    # Output directory\n",
    "    out_dir = f'{my_bucket}/data/stg003/pruned_genotypes/{anc}'\n",
    "\n",
    "    # Check if already exists (check for a few chromosome files)\n",
    "    existing_files = get_file_list(out_dir)\n",
    "    if any('genotypes_chr1_pruned.bed' in f for f in existing_files):\n",
    "        print(f\"LD pruned files already exist for {anc}\")\n",
    "        return\n",
    "        \n",
    "    print(f\"Starting serial LD pruning for {anc} ancestry...\")\n",
    "\n",
    "    dsub_script(\n",
    "        machine_type='c3-standard-22',\n",
    "        out_dir=out_dir,\n",
    "        anc=anc,\n",
    "        start_chrom=start_chrom,\n",
    "        boot_disk=200,\n",
    "        disk_size=400,\n",
    "        script=script\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_file_list(query_dir):\n",
    "    tmp = subprocess.run(\n",
    "        f'gsutil ls {query_dir}',\n",
    "        shell=True,\n",
    "        capture_output=True\n",
    "    )\n",
    "    files = tmp.stdout.decode('utf-8').split('\\n')\n",
    "    return(files)\n",
    "\n",
    "def dsub_script(\n",
    "    machine_type,\n",
    "    out_dir,\n",
    "    anc,\n",
    "    start_chrom=1,\n",
    "    window=1000,\n",
    "    step=80,\n",
    "    r2=0.05,\n",
    "    boot_disk=100,\n",
    "    disk_size=150,\n",
    "    script='run_ld_prune_sequential.sh'\n",
    "):\n",
    "    \n",
    "    # get useful info\n",
    "    dsub_user_name = os.getenv(\"OWNER_EMAIL\").split('@')[0]\n",
    "    user_name = os.getenv(\"OWNER_EMAIL\").split('@')[0].replace('.', '-')\n",
    "\n",
    "    job_name = f'{anc}_prune'\n",
    "\n",
    "    # Template for input files (will be substituted in script)\n",
    "    my_bucket = os.getenv('WORKSPACE_BUCKET') \n",
    "    in_pfile_template = f'{my_bucket}/data/stg001/{anc}/genotypes_CHR_PLACEHOLDER'\n",
    "    excl_bed = f'{my_bucket}/data/high-LD-regions-hg38-GRCh38.bed'\n",
    "    \n",
    "    # Build dsub command\n",
    "    cmd = [\n",
    "        'dsub',\n",
    "        '--provider', 'google-cls-v2',\n",
    "        '--machine-type', machine_type,\n",
    "        '--disk-type', 'pd-ssd',\n",
    "        '--boot-disk-size', str(boot_disk),\n",
    "        '--disk-size', str(disk_size),\n",
    "        '--user-project', os.environ['GOOGLE_PROJECT'],\n",
    "        '--project', os.environ['GOOGLE_PROJECT'],\n",
    "        '--image', 'us.gcr.io/broad-dsp-gcr-public/terra-jupyter-aou:2.2.14',\n",
    "        '--network', 'network',\n",
    "        '--subnetwork', 'subnetwork',\n",
    "        '--service-account', subprocess.check_output(['gcloud', 'config', 'get-value', 'account']).decode().strip(),\n",
    "        '--user', dsub_user_name,\n",
    "        '--logging', f\"{os.environ['WORKSPACE_BUCKET']}/dsub/logs/{{job-name}}/{{user-id}}/{{job-id}}-{{task-id}}-{{task-attempt}}.log\",\n",
    "        '--name', job_name,\n",
    "        '--env', f'GOOGLE_PROJECT={os.environ[\"GOOGLE_PROJECT\"]}',\n",
    "        '--env', f'WINDOW={window}',\n",
    "        '--env', f'STEP={step}',\n",
    "        '--env', f'R2={r2}',\n",
    "        '--env', f'MEMORY=30000',\n",
    "        '--env', f'ANCESTRY={anc}',\n",
    "        '--env', f'START_CHROM={start_chrom}',\n",
    "        '--env', f'INPUT_PGEN_BASE_TEMPLATE={in_pfile_template}',\n",
    "        # Input files\n",
    "        '--input', f'EXCLUDE_BED={excl_bed}',\n",
    "        # Output files\n",
    "        '--output', f'OUTPUT_RESULTS={out_dir}/genotypes_chr*',\n",
    "        '--script', script\n",
    "    ]\n",
    "\n",
    "            \n",
    "    subprocess.run(cmd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ancestries_considered = ['eur', 'afr', 'amr', 'eas', 'sas', 'mid']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Test\n",
    "# run_ld_prune(my_bucket, 'mid', start_chrom=22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for anc in ancestries_considered:\n",
    "    run_ld_prune(my_bucket, anc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_ld_prune(my_bucket, 'all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check dsub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_dsub_status(full=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_id = 'all-prune--bwaxse--250618-194023-28'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_details(job=job_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gsutil cat {bucket or my_bucket}/dsub/logs/all-prune/bwaxse/all-prune--bwaxse--250618-194023-28-task-None.log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gsutil ls {bucket or my_bucket}/data/stg003/pruned_genotypes/all/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pruning Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_pruning_stats(my_bucket, ancestries, chroms=range(1, 23)):\n",
    "    \"\"\"\n",
    "    Collect LD pruning statistics for all ancestries and chromosomes\n",
    "    Returns a polars DataFrame with comprehensive stats\n",
    "    \"\"\"\n",
    "    \n",
    "    data = []\n",
    "    \n",
    "    for anc in ancestries:\n",
    "        print(f\"Processing {anc} ancestry...\")\n",
    "        base_dir = f'{my_bucket}/data/stg003/pruned_genotypes/{anc}'\n",
    "        \n",
    "        for chrom in chroms:\n",
    "            try:\n",
    "                # Download pruning files for this ancestry/chromosome\n",
    "                prune_in_file = f'{base_dir}/genotypes_chr_chr{chrom}_pruned.prune.in'\n",
    "                prune_out_file = f'{base_dir}/genotypes_chr_chr{chrom}_pruned.prune.out' \n",
    "                bim_file = f'{base_dir}/genotypes_chr_chr{chrom}_pruned.bim'\n",
    "                \n",
    "                # Download files locally\n",
    "                subprocess.run(f'gsutil -q cp {prune_in_file} chr{chrom}_{anc}.prune.in', shell=True, check=True)\n",
    "                subprocess.run(f'gsutil -q cp {prune_out_file} chr{chrom}_{anc}.prune.out', shell=True, check=True)\n",
    "                subprocess.run(f'gsutil -q cp {bim_file} chr{chrom}_{anc}.bim', shell=True, check=True)\n",
    "                \n",
    "                # Count variants\n",
    "                with open(f'chr{chrom}_{anc}.prune.in', 'r') as f:\n",
    "                    kept_variants = sum(1 for line in f if line.strip())\n",
    "                \n",
    "                with open(f'chr{chrom}_{anc}.prune.out', 'r') as f:\n",
    "                    removed_variants = sum(1 for line in f if line.strip())\n",
    "                \n",
    "                with open(f'chr{chrom}_{anc}.bim', 'r') as f:\n",
    "                    final_variants = sum(1 for line in f if line.strip())\n",
    "                \n",
    "                total_before = kept_variants + removed_variants\n",
    "                pruning_rate = (removed_variants / total_before * 100) if total_before > 0 else 0\n",
    "                \n",
    "                data.append({\n",
    "                    'ancestry': anc,\n",
    "                    'chromosome': chrom,\n",
    "                    'variants_before_pruning': total_before,\n",
    "                    'variants_kept': kept_variants,\n",
    "                    'variants_removed': removed_variants,\n",
    "                    'final_variants_in_bim': final_variants,\n",
    "                    'pruning_rate_pct': pruning_rate\n",
    "                })\n",
    "                \n",
    "                # Cleanup\n",
    "                subprocess.run(f'rm -f chr{chrom}_{anc}.prune.* chr{chrom}_{anc}.bim', shell=True)\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"  ⚠️  Failed to process {anc} chr{chrom}: {e}\")\n",
    "                continue\n",
    "    \n",
    "    # Convert to polars DataFrame\n",
    "    df = pl.DataFrame(data)\n",
    "    \n",
    "    print(f\"\\nCollected data for {len(data)} ancestry-chromosome combinations\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_pruning_patterns(df):\n",
    "    \"\"\"Analyze pruning patterns across ancestries and chromosomes\"\"\"\n",
    "    \n",
    "    print(\"=== LD PRUNING ANALYSIS SUMMARY ===\\n\")\n",
    "    \n",
    "    # 1. Overall statistics by ancestry\n",
    "    print(\"1. PRUNING RATES BY ANCESTRY\")\n",
    "    ancestry_stats = df.group_by('ancestry').agg([\n",
    "        pl.col('pruning_rate_pct').mean().alias('mean_pruning_rate'),\n",
    "        pl.col('pruning_rate_pct').std().alias('std_pruning_rate'),\n",
    "        pl.col('final_variants_in_bim').mean().alias('mean_final_variants'),\n",
    "        pl.col('final_variants_in_bim').std().alias('std_final_variants'),\n",
    "        pl.col('variants_before_pruning').mean().alias('mean_before_pruning'),\n",
    "        pl.col('chromosome').count().alias('n_chromosomes')\n",
    "    ]).sort('ancestry')\n",
    "    \n",
    "    print(ancestry_stats)\n",
    "    \n",
    "    # 2. Chromosome-specific patterns\n",
    "    print(\"\\n2. PRUNING RATES BY CHROMOSOME\")\n",
    "    chrom_stats = df.group_by('chromosome').agg([\n",
    "        pl.col('pruning_rate_pct').mean().alias('mean_pruning_rate'),\n",
    "        pl.col('pruning_rate_pct').std().alias('std_pruning_rate'),\n",
    "        pl.col('final_variants_in_bim').mean().alias('mean_final_variants'),\n",
    "        pl.col('final_variants_in_bim').std().alias('std_final_variants')\n",
    "    ]).sort('chromosome')\n",
    "    \n",
    "    print(chrom_stats)\n",
    "    \n",
    "    # 3. Identify outliers\n",
    "    print(\"\\n3. OUTLIER DETECTION\")\n",
    "    \n",
    "    # Calculate z-scores for pruning rates\n",
    "    overall_mean = df['pruning_rate_pct'].mean()\n",
    "    overall_std = df['pruning_rate_pct'].std()\n",
    "    \n",
    "    outliers = df.with_columns([\n",
    "        ((pl.col('pruning_rate_pct') - overall_mean) / overall_std).alias('pruning_rate_zscore')\n",
    "    ]).filter(\n",
    "        pl.col('pruning_rate_zscore').abs() > 2.0  # More than 2 standard deviations\n",
    "    ).sort(pl.col('pruning_rate_zscore').abs(), descending=True)\n",
    "    \n",
    "    if len(outliers) > 0:\n",
    "        print(\"Outliers (|z-score| > 2.0):\")\n",
    "        print(outliers.select(['ancestry', 'chromosome', 'pruning_rate_pct', 'pruning_rate_zscore']))\n",
    "    else:\n",
    "        print(\"No significant outliers detected.\")\n",
    "        \n",
    "    return ancestry_stats, chrom_stats, outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pruning_visualizations(df):\n",
    "    \"\"\"Create visualizations of pruning patterns\"\"\"\n",
    "    \n",
    "    # Convert to pandas for plotting\n",
    "    df_pd = df.to_pandas()\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "    \n",
    "    # 1. Pruning rate by ancestry\n",
    "    sns.boxplot(data=df_pd, x='ancestry', y='pruning_rate_pct', ax=axes[0,0])\n",
    "    axes[0,0].set_title('Pruning Rate Distribution by Ancestry')\n",
    "    axes[0,0].set_ylabel('Pruning Rate (%)')\n",
    "    \n",
    "    # 2. Final variant count by ancestry  \n",
    "    sns.boxplot(data=df_pd, x='ancestry', y='final_variants_in_bim', ax=axes[0,1])\n",
    "    axes[0,1].set_title('Final Variant Count by Ancestry')\n",
    "    axes[0,1].set_ylabel('Final Variants')\n",
    "    \n",
    "    # 3. Pruning rate by chromosome\n",
    "    sns.lineplot(data=df_pd, x='chromosome', y='pruning_rate_pct', hue='ancestry', ax=axes[1,0])\n",
    "    axes[1,0].set_title('Pruning Rate by Chromosome')\n",
    "    axes[1,0].set_ylabel('Pruning Rate (%)')\n",
    "    axes[1,0].legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    \n",
    "    # 4. Final variants by chromosome\n",
    "    sns.lineplot(data=df_pd, x='chromosome', y='final_variants_in_bim', hue='ancestry', ax=axes[1,1])\n",
    "    axes[1,1].set_title('Final Variant Count by Chromosome')\n",
    "    axes[1,1].set_ylabel('Final Variants')\n",
    "    axes[1,1].legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ancestries = ['eur', 'afr', 'amr', 'eas', 'sas', 'mid']\n",
    "\n",
    "print(\"Collecting LD pruning statistics...\")\n",
    "stats_df = collect_pruning_stats(my_bucket, ancestries)\n",
    "\n",
    "print(\"\\nAnalyzing patterns...\")\n",
    "ancestry_stats, chrom_stats, outliers = analyze_pruning_patterns(stats_df)\n",
    "\n",
    "print(\"\\nCreating visualizations...\")\n",
    "fig = create_pruning_visualizations(stats_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
