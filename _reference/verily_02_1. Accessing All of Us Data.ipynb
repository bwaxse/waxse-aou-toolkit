{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6713a22f-3b5c-41f4-93e3-8f9da02e2797",
   "metadata": {},
   "source": [
    "# Accessing the *All of Us* Data\n",
    "\n",
    "*We recommend that all new users read this notebook to learn the basics of accessing the All of Us dataset*\n",
    "\n",
    "Below you will find recommendedinstructions for accessing the *All of Us* Curated Data Repository (CDR) data for analysis. \n",
    "\n",
    "This notebook was run using a standard JupyterLab Compute Engine VM with the default configuration.  \n",
    "\n",
    "## Tutorial's Objectives\n",
    "\n",
    "**What should you expect?** This notebook will give you an overview of what data is available in and how to access and analyze the data in Verily Workbench. \n",
    "\n",
    "This tutorial is divided into the following sections:\n",
    "1. **Data Overview:** *All of Us* CDR Registered Tier Version 8 overview \n",
    "2. **Setup:** How to set up this notebook, install and import software packages, and create a variable for your dataset.\n",
    "3. **Data Access & Visualization:** Examples to access & visualize the data via queries\n",
    "6. **Saving data & visualizations**: How to save data & visualizations to your workspace bucket\n",
    "7. **Provenance**: How to save metadata on this notebook.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b26d4d47-f1ac-4127-8fb9-a21690bbee04",
   "metadata": {},
   "source": [
    "## Setup\n",
    "<a id='read-from-bq'></a>\n",
    "\n",
    "Before we begin, we will first install a few packages we will use in our analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91b46010-e101-4dda-9b16-98d13e35183f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install polars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2466828-3d64-4660-82e3-6924689d38dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import bigquery\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "import os\n",
    "import subprocess\n",
    "from pathlib import Path\n",
    "import pandas_gbq\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import psutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7527b1e-14a8-49f8-a377-612094d27491",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_resource_usage():\n",
    "  \"\"\"Monitor memory and CPU usage\"\"\"\n",
    "  memory = psutil.virtual_memory()\n",
    "  cpu_percent = psutil.cpu_percent(interval=1)\n",
    "\n",
    "  print(f\"Memory: {memory.used / 1e9:.1f}GB / {memory.total / 1e9:.1f}GB \"\n",
    "        f\"({memory.percent:.1f}% used)\")\n",
    "  print(f\"CPU: {cpu_percent:.1f}% used across {os.cpu_count()} cores\")\n",
    "\n",
    "  # Recommendations\n",
    "  if memory.percent > 85:\n",
    "      print(\"HIGH MEMORY - Consider upgrading to highmem or downsizing data\")\n",
    "  elif memory.percent < 40 and cpu_percent < 40:\n",
    "      print(\"LOW USAGE - Could downsize to save costs\")\n",
    "  else:\n",
    "      print(\"Good utilization\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "025822cd-9051-42f5-b929-709ccbc712cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This line allows for the plots to be displayed inline in the Jupyter notebook\n",
    "%matplotlib inline\n",
    "\n",
    "sns.set(style=\"ticks\",font_scale=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5d6f0e6-4796-412a-8efa-282ea2bbb9f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.Config.set_fmt_str_lengths(128)\n",
    "\n",
    "# Set the row limit to a higher value\n",
    "pl.Config.set_tbl_rows(50)\n",
    "\n",
    "# show all columns in pandas\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "\n",
    "# show full column width\n",
    "pd.set_option('display.max_colwidth', 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11509d35-df61-45e9-ae50-f9b24bfad472",
   "metadata": {},
   "source": [
    "## Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b08ae9a-0b9f-4863-a409-04ddf1d4a3b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def polars_gbq(query):\n",
    "    \"\"\"Execute BigQuery SQL and return polars DataFrame\"\"\"\n",
    "    client = bigquery.Client()\n",
    "    return pl.from_arrow(client.query(query).result().to_arrow())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a28822b-2d6d-4c1c-8620-2a26ba2e5852",
   "metadata": {},
   "source": [
    "## Data Access\n",
    "\n",
    "In the first notebook, we discussed how to create a variable to easily reference the CDR data in our analysis. However, for our purposes, we have already generated the variables in a notebook and will source this notebook to automatically obtain the variables we need below. Assuming you have run this notebook `/home/jupyter/workspace/aou-tutorial-notebooks/I. Getting Started with Verily Workbench/01_1. Getting Started with Workbench (Python).ipynb` or this one, `/home/jupyter/workspace/aou-tutorial-notebooks/Setting_Env_Variables.ipynb` already.\n",
    "\n",
    "And then you can run the cell below to load the variables.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc47d9b0-0da0-42ab-b5ac-240f7d893119",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run /home/jupyter/workspace/test-notebooks/Setting_Env_Variables_p2.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7f54b52-3b47-4264-9ba0-29a2971dff41",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_bucket = os.environ['WORKSPACE_TEMP_BUCKET']\n",
    "temp_bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b71a5b40-0fd9-47d9-a89a-627eadf0fd4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = os.environ.get(\"WORKSPACE_CDR\")\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a25df811-9043-4eae-85eb-f678fc078305",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "Verily Workbench will be updated to include environment variables soon, which will let researchers access the CDR using one environment variable from any notebook. All notebook will be updated once environment variables are available. For now, we recommend you set the dataset variable in each notebook you create using the code provided above.\n",
    "</blockquote></div>   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10d81468-29eb-498f-b230-90252fd682c7",
   "metadata": {},
   "source": [
    "## Sample Queries & Visualizations\n",
    "<a id='read-from-bq'></a>\n",
    "\n",
    "There are multiple ways to interact with your data from a Verily Workbench cloud environment (e.g. JupyterLab). This notebook provides examples of how you may interact with your data using the [`pandas-gbq` library](https://googleapis.dev/python/pandas-gbq/latest/index.html). You can also access the data using [IPython magics for BigQuery](https://cloud.google.com/python/docs/reference/bigquery/latest/magics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd1ab094-4734-40ba-9f3d-369d499c39e3",
   "metadata": {},
   "source": [
    "First, we can view and create a dataframe of all of the tables available in our dataset using the following query:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fc98510-5eac-4712-ac7c-04a2c7dbf2b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "query= f\"\"\"\n",
    "SELECT\n",
    "  table_name,\n",
    "  table_type,\n",
    "  creation_time\n",
    "FROM\n",
    "    `{dataset}`.INFORMATION_SCHEMA.TABLES\n",
    "ORDER BY\n",
    "  table_name\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2455ecce-eefc-4a70-821c-83ba380f2d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=polars_gbq(query)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc71b832-5db7-437a-b816-11eb4f23c63d",
   "metadata": {},
   "source": [
    "We can make a CSV of all of the tables to reference later if needed, this will be saved to our bucket:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96fa8a95-8005-4997-b645-362b7adcb1d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make DF a CSV and save in bucket \n",
    "new_id = os.environ.get(\"WORKSPACE_CDR\", \"unknown_dataset\")\n",
    "# Extract the dataset name by splitting on the '.' character\n",
    "dataset_name = new_id.split('.')[-1]  # e.g., \"R2024Q3R8\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7afc9b47-d3d8-4209-9aad-c3efa24243c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dynamically create the output file name\n",
    "output_file = f\"{dataset_name}_CT_tables.csv\"\n",
    "print(output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8846faa9-10f0-4dfe-b180-4c77a6c6274a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save DataFrame to CSV\n",
    "df.write_csv(output_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67c22c1f-1291-41fe-bb41-ea42b200e2c0",
   "metadata": {},
   "source": [
    "### Sample Device Data Visualization\n",
    "\n",
    "The example below shows creating a query & visualizing data from the activity table. First we create a query & a dataframe of all columns from activity summary "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad26bb22-6f07-4097-9868-75285d34a797",
   "metadata": {},
   "outputs": [],
   "source": [
    "activity_query= f\"\"\"\n",
    "    SELECT * from `{dataset}`.activity_summary LIMIT 1000\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27b5b8b0-b81a-468a-a302-bbaf5dabebee",
   "metadata": {},
   "outputs": [],
   "source": [
    "activity_df=polars_gbq(activity_query)\n",
    "activity_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44066d0a-b8ad-4537-b670-9331d1eefb92",
   "metadata": {},
   "source": [
    "We can create a scatterplot of steps vs calories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ff7969b-2abc-4910-8cc9-2d75461d9c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(activity_df['steps'], activity_df['activity_calories'], alpha=0.5)\n",
    "plt.title('Steps vs. Activity Calories')\n",
    "plt.xlabel('Steps')\n",
    "plt.ylabel('Activity Calories')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b1813e1-6566-4cee-a5ec-000862b38380",
   "metadata": {},
   "source": [
    "Create a distribution of sedentary vs active minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54da28fc-5cb7-4881-8cc8-a8c7f85406d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "# Sedentary minutes (drop nulls)\n",
    "sedentary = activity_df['sedentary_minutes'].drop_nulls()\n",
    "plt.hist(sedentary, bins=30, alpha=0.5, label='Sedentary Minutes')\n",
    "\n",
    "# Total active minutes (drop nulls)\n",
    "total_active = (\n",
    "    activity_df['fairly_active_minutes'] +\n",
    "    activity_df['lightly_active_minutes'] +\n",
    "    activity_df['very_active_minutes']\n",
    ").drop_nulls()\n",
    "plt.hist(total_active, bins=30, alpha=0.5, label='Total Active Minutes')\n",
    "\n",
    "plt.legend()\n",
    "plt.title('Distribution of Sedentary vs. Active Minutes')\n",
    "plt.xlabel('Minutes')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55fafd04-8e9b-462c-a9a6-5246d14e87dc",
   "metadata": {},
   "source": [
    "## Extract All of Us CDR Schema Information\n",
    "\n",
    "Extract schema information for reference when developing queries and analyses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f984b2cd-0757-4949-8e81-49f1c9530cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract all schema information\n",
    "schema_data = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "203ab949-337a-4306-849c-eacbfa3d8cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_query = f\"\"\"\n",
    "    SELECT\n",
    "        table_name,\n",
    "        column_name,\n",
    "        ordinal_position,\n",
    "        data_type,\n",
    "        is_nullable\n",
    "    FROM `{dataset}.INFORMATION_SCHEMA.COLUMNS`\n",
    "    WHERE table_name IN (\n",
    "        'person',\n",
    "        'death',\n",
    "        'condition_occurrence',\n",
    "        'drug_exposure',\n",
    "        'measurement',\n",
    "        'observation',\n",
    "        'visit_occurrence',\n",
    "        'procedure_occurrence',\n",
    "        'device_exposure',\n",
    "        'concept',\n",
    "        'concept_relationship',\n",
    "        'concept_ancestor',\n",
    "        'cb_criteria',\n",
    "        'cb_criteria_ancestor',\n",
    "        'cb_search_person',\n",
    "        'cb_search_all_events'\n",
    "    )\n",
    "    ORDER BY table_name, ordinal_position\n",
    "    \"\"\"\n",
    "\n",
    "schema_data['table_schemas'] = polars_gbq(table_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65a5df2a-ce4f-408a-ba1e-682302a1940c",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema_data['table_schemas'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc2ec70a-4ea7-4457-b142-b994d2e56979",
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = []\n",
    "for table in schema_data['table_schemas'].unique('table_name')['table_name'].to_list():\n",
    "    try:\n",
    "        query = f\"SELECT COUNT(*) as row_count FROM `{dataset}.{table}`\"\n",
    "        result = polars_gbq(query)\n",
    "        count = result['row_count'][0]\n",
    "        counts.append({'table_name': table, 'row_count': count})\n",
    "        print(f\"  {table}: {count:,} rows\")\n",
    "    except Exception as e:\n",
    "        print(f\"  {table}: Error - {e}\")\n",
    "        counts.append({'table_name': table, 'row_count': None})\n",
    "\n",
    "schema_data['table_row_counts'] = pl.DataFrame(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a7a411a-2f0a-4c46-9dc4-1efc36433048",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_query = f\"\"\"\n",
    "    SELECT\n",
    "        vocabulary_id,\n",
    "        domain_id,\n",
    "        COUNT(*) AS concept_count,\n",
    "        COUNT(DISTINCT concept_class_id) AS class_count,\n",
    "        COUNT(DISTINCT CASE WHEN standard_concept = 'S' THEN concept_id END) AS standard_concept_count,\n",
    "        COUNT(DISTINCT CASE WHEN invalid_reason IS NULL THEN concept_id END) AS valid_concept_count\n",
    "    FROM `{dataset}.concept`\n",
    "    GROUP BY vocabulary_id, domain_id\n",
    "    ORDER BY concept_count DESC\n",
    "    \"\"\"\n",
    "\n",
    "schema_data['vocabulary_structure'] = polars_gbq(vocab_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b4183b1-fb46-48d7-adb7-6acee3b4ff12",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema_data['vocabulary_structure'] = schema_data['vocabulary_structure'].with_columns([\n",
    "    pl.when(pl.col('standard_concept_count').is_between(1, 19))\n",
    "      .then(-9)\n",
    "      .otherwise(pl.col('standard_concept_count'))\n",
    "      .alias('standard_concept_count'),\n",
    "    \n",
    "    pl.when(pl.col('valid_concept_count').is_between(1, 19))\n",
    "      .then(-9)\n",
    "      .otherwise(pl.col('valid_concept_count'))\n",
    "      .alias('valid_concept_count')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65615f1b-d4dc-4d58-9979-bbf27a000448",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema_data['vocabulary_structure'].sort('valid_concept_count', descending=True).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "767fbb34-9e38-4df8-b24a-66082c7b2a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "concept_domains_query = f\"\"\"\n",
    "    SELECT\n",
    "        domain_id,\n",
    "        concept_class_id,\n",
    "        vocabulary_id,\n",
    "        COUNT(*) AS concept_count,\n",
    "        COUNT(DISTINCT CASE WHEN standard_concept = 'S' THEN concept_id END) AS standard_count\n",
    "    FROM `{dataset}.concept`\n",
    "    WHERE domain_id IN (\n",
    "        'Condition',\n",
    "        'Drug',\n",
    "        'Measurement',\n",
    "        'Observation',\n",
    "        'Procedure',\n",
    "        'Visit',\n",
    "        'Device'\n",
    "    )\n",
    "    GROUP BY domain_id, concept_class_id, vocabulary_id\n",
    "    ORDER BY domain_id, concept_count DESC\n",
    "    \"\"\"\n",
    "\n",
    "schema_data['concept_domains'] = polars_gbq(concept_domains_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a2c34ab-fba0-4ca9-a5ea-bde51fa0a1bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema_data['concept_domains'] = schema_data['concept_domains'].with_columns([\n",
    "    pl.when(pl.col('concept_count').is_between(1, 19))\n",
    "      .then(-9)\n",
    "      .otherwise(pl.col('concept_count'))\n",
    "      .alias('concept_count'),\n",
    "    \n",
    "    pl.when(pl.col('standard_count').is_between(1, 19))\n",
    "      .then(-9)\n",
    "      .otherwise(pl.col('standard_count'))\n",
    "      .alias('standard_count')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8762d4fe-13ac-4384-9708-810b758c4581",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema_data['concept_domains'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b79dfb2f-7790-44f9-a863-81d57cd8bb0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "measurement_concepts_query = f\"\"\"\n",
    "    WITH measurement_counts AS (\n",
    "        SELECT\n",
    "            measurement_concept_id,\n",
    "            COUNT(DISTINCT person_id) AS person_count,\n",
    "            COUNT(*) AS measurement_count\n",
    "        FROM `{dataset}.measurement`\n",
    "        GROUP BY measurement_concept_id\n",
    "        HAVING person_count > 100\n",
    "    )\n",
    "    SELECT\n",
    "        mc.measurement_concept_id,\n",
    "        c.concept_name,\n",
    "        c.concept_code,\n",
    "        c.vocabulary_id,\n",
    "        c.concept_class_id,\n",
    "        mc.person_count,\n",
    "        mc.measurement_count\n",
    "    FROM measurement_counts mc\n",
    "    JOIN `{dataset}.concept` c\n",
    "        ON mc.measurement_concept_id = c.concept_id\n",
    "    ORDER BY mc.measurement_count DESC\n",
    "    LIMIT 1000\n",
    "    \"\"\"\n",
    "\n",
    "schema_data['measurement_concepts'] = polars_gbq(measurement_concepts_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b408d72e-8933-460f-a4b1-40284ed47ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema_data['measurement_concepts'].sort('measurement_count', descending=True).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5e4e626-3e28-450b-9af5-207eb6e7ec95",
   "metadata": {},
   "outputs": [],
   "source": [
    "visit_concepts_query = f\"\"\"\n",
    "    SELECT\n",
    "        v.visit_concept_id,\n",
    "        c.concept_name AS visit_type,\n",
    "        COUNT(DISTINCT v.person_id) AS person_count,\n",
    "        COUNT(*) AS visit_count\n",
    "    FROM `{dataset}.visit_occurrence` v\n",
    "    JOIN `{dataset}.concept` c\n",
    "        ON v.visit_concept_id = c.concept_id\n",
    "    GROUP BY v.visit_concept_id, c.concept_name\n",
    "    ORDER BY visit_count DESC\n",
    "    \"\"\"\n",
    "\n",
    "schema_data['visit_concepts'] = polars_gbq(visit_concepts_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef445df8-715a-4f7a-a0de-90fc7544967e",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema_data['visit_concepts'] = schema_data['visit_concepts'].with_columns([\n",
    "    pl.when(pl.col('person_count').is_between(1, 19))\n",
    "      .then(-9)\n",
    "      .otherwise(pl.col('person_count'))\n",
    "      .alias('person_count'),\n",
    "    \n",
    "    pl.when(pl.col('visit_count').is_between(1, 19))\n",
    "      .then(-9)\n",
    "      .otherwise(pl.col('visit_count'))\n",
    "      .alias('visit_count')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f594c8c-e2a8-4c7c-9edd-27a3894c695a",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema_data['visit_concepts'].sort('visit_count', descending=True).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23ab6a04-2bd5-4f3f-80e0-4b4a9a1dc1fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "condition_vocabularies_query = f\"\"\"\n",
    "    SELECT\n",
    "        c.vocabulary_id,\n",
    "        COUNT(DISTINCT co.person_id) AS person_count,\n",
    "        COUNT(*) AS condition_count,\n",
    "        COUNT(DISTINCT co.condition_concept_id) AS unique_concepts\n",
    "    FROM `{dataset}.condition_occurrence` co\n",
    "    JOIN `{dataset}.concept` c\n",
    "        ON co.condition_source_concept_id = c.concept_id\n",
    "    WHERE c.vocabulary_id IN ('ICD9CM', 'ICD10CM', 'SNOMED')\n",
    "    GROUP BY c.vocabulary_id\n",
    "    ORDER BY condition_count DESC\n",
    "    \"\"\"\n",
    "\n",
    "schema_data['condition_vocabularies'] = polars_gbq(condition_vocabularies_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "798237f5-2228-4c77-ac4a-6d3b0f36b214",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema_data['condition_vocabularies']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31a601ca-6285-4926-9513-109cd97741ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, df in schema_data.items():\n",
    "    gcs_path = f\"{temp_bucket}/schema_data/{name}.tsv\"\n",
    "    df.write_csv(gcs_path, separator='\\t')\n",
    "    print(f\"  Saved: {gcs_path} ({len(df):,} rows)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "008868a5-3198-46f4-8b56-a0a153708176",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p schema_data\n",
    "\n",
    "for name, df in schema_data.items():\n",
    "    output_path = f\"schema_data/{name}.tsv\"\n",
    "    df.write_csv(output_path, separator='\\t')\n",
    "    print(f\"  Saved: {output_path} ({len(df):,} rows)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0ec7d3e-befa-4c02-a108-2f4886530160",
   "metadata": {},
   "source": [
    "## Provenance\n",
    "We recommend reviewing the additional notebooks in the ```aou-tutorial-notebook``` bucket for more getting started resources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ca77880-b2e5-4d2c-97e8-1cc22973cf7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86d37ea6-d669-4ca2-ae1d-99fe5dd8b506",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Conda and pip installed packages:\n",
    "!conda env export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7f6afb4-c5c0-42ef-a7ef-2e2301dbfd56",
   "metadata": {},
   "outputs": [],
   "source": [
    "#JupyterLab extensions:\n",
    "!jupyter labextension list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee717c3d-9d8c-4199-beaf-c4976b58a1d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Number of cores:\n",
    "!grep ^processor /proc/cpuinfo | wc -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24d60059-25c3-459c-bae0-1c6237df96d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Memory:\n",
    "!grep \"^MemTotal:\" /proc/meminfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "2e29a7a4-9696-4046-8eda-37d4a3d96d6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory: 3.4GB / 202.8GB (1.7% used)\n",
      "CPU: 0.0% used across 48 cores\n",
      "LOW USAGE - Could downsize to save costs\n"
     ]
    }
   ],
   "source": [
    "print_resource_usage()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
