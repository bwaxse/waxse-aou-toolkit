{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Packages and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, HTML\n",
    "from google.cloud import bigquery\n",
    "import pandas as pd\n",
    "import pyarrow as pa\n",
    "import polars as pl\n",
    "import os\n",
    "import subprocess\n",
    "import numpy as np, scipy as sps\n",
    "import matplotlib, matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime, date\n",
    "from typing import Dict, List, Optional, Union\n",
    "from jinja2 import Template, Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from omop_unifier import Explorer, Mapper, Unifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This line allows for the plots to be displayed inline in the Jupyter notebook\n",
    "%matplotlib inline\n",
    "\n",
    "sns.set(style=\"whitegrid\",font_scale=0.9)\n",
    "\n",
    "palette = ['#0173b2', '#de8f05', '#8de5a1', '#d55e00', '#029e73', '#cc78bc', '#ece133', \n",
    "           '#56b4e9', '#ca9161', '#fbafe4', '#949494']\n",
    "\n",
    "sns.set_palette(sns.color_palette(palette))\n",
    "sns.color_palette(palette)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show all columns in pandas\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "\n",
    "# show full column width\n",
    "pd.set_option('display.max_colwidth', 100)\n",
    "\n",
    "# Polars string length to 100\n",
    "pl.Config.set_fmt_str_lengths(100)\n",
    "\n",
    "pl.Config.set_tbl_rows(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Class Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "class AouQueries:\n",
    "    def __init__(self, version=None, bucket=None):\n",
    "        \"\"\"\n",
    "        Specialized query builder for common All of Us research patterns.\n",
    "        \n",
    "        \"\"\"\n",
    "        self.version = version or os.getenv('WORKSPACE_CDR')\n",
    "        self.bucket = bucket or os.getenv('WORKSPACE_BUCKET')\n",
    "        self.client = bigquery.Client()\n",
    "        self.query_text = None\n",
    "\n",
    "        # Validate required environment\n",
    "        if not self.version:\n",
    "            raise ValueError(\"CDR version not found. Check WORKSPACE_CDR environment variable if none provided.\")\n",
    "        if not self.bucket:\n",
    "            raise ValueError(\"Workspace bucket not found. Check WORKSPACE_BUCKET environment variable if none provided.\")\n",
    "\n",
    "        print(\"version: \" + self.version)\n",
    "        print(\"bucket: \" + self.bucket)\n",
    "            \n",
    "    def find_diagnosis_codes(self, \n",
    "                            vocabularies: List[str] = None,\n",
    "                            search_terms: List[str] = None, \n",
    "                            exclude_terms: List[str] = None,\n",
    "                            exact_codes: Dict[str, List[str]] = None,\n",
    "                            pattern_codes: Dict[str, List[str]] = None,\n",
    "                            exclude_codes: Dict[str, List[str]] = None,\n",
    "                            person_ids: Union[List[int], str] = None):\n",
    "        \"\"\"\n",
    "        Find diagnosis codes in condition_occurrence and observation tables.\n",
    "        \"\"\"\n",
    "\n",
    "        if not vocabularies:\n",
    "            # Default to standard vocabularies if nothing specified\n",
    "            vocabularies = [\"ICD9CM\", \"ICD10CM\", \"SNOMED\"]\n",
    "\n",
    "        # Add any vocabularies from exact_codes or pattern_codes that aren't already included\n",
    "        vocab_additions = set()\n",
    "        for vocab in list(exact_codes.keys() if exact_codes else []) + list(pattern_codes.keys() if pattern_codes else []):\n",
    "            if vocab not in vocabularies:\n",
    "                vocab_additions.add(vocab)\n",
    "                vocabularies.append(vocab)\n",
    "\n",
    "        # Notify if vocabularies were added\n",
    "        if vocab_additions:\n",
    "            print(f\"Added vocabularies from code specifications: {', '.join(vocab_additions)}\")\n",
    "\n",
    "        # Store query parameters for summary\n",
    "        self.last_query_params = {\n",
    "            \"type\": \"diagnosis_codes\",\n",
    "            \"vocabularies\": vocabularies,\n",
    "            \"search_terms\": search_terms,\n",
    "            \"exclude_terms\": exclude_terms,\n",
    "            \"exact_codes\": exact_codes,\n",
    "            \"pattern_codes\": pattern_codes,\n",
    "            \"exclude_codes\": exclude_codes,\n",
    "            \"person_ids\": person_ids\n",
    "        }\n",
    "        \n",
    "        # Generate query summary text\n",
    "        self.query_summary = self._generate_query_summary()\n",
    "    \n",
    "        # Create Jinja2 environment and add filter\n",
    "        env = Environment()\n",
    "        \n",
    "        # Define and add filter to environment\n",
    "        def join_quotes(items):\n",
    "            return ', '.join(f\"'{item}'\" for item in items)\n",
    "\n",
    "        env.filters['join_quotes'] = join_quotes\n",
    "\n",
    "        template = env.from_string(\"\"\"\n",
    "        WITH filtered_concepts AS (\n",
    "            SELECT DISTINCT concept_id, vocabulary_id, concept_code, concept_name\n",
    "            FROM {{ version }}.concept\n",
    "            WHERE \n",
    "                vocabulary_id IN ({{ vocabularies|join_quotes }})\n",
    "                {%- if exclude_terms %}\n",
    "                AND (\n",
    "                    {%- for term in exclude_terms %}\n",
    "                    {{ \"AND \" if not loop.first else \"\" }}LOWER(concept_name) NOT LIKE '%{{ term|lower }}%'\n",
    "                    {%- endfor %}\n",
    "                )\n",
    "                {%- endif %}\n",
    "                {%- for vocab, codes in exclude_codes.items() %}\n",
    "                {%- if codes %}\n",
    "                AND NOT (\n",
    "                    vocabulary_id = '{{ vocab }}' AND concept_code IN ({{ codes|join_quotes }})\n",
    "                )\n",
    "                {%- endif %}\n",
    "                {%- endfor %}\n",
    "                {%- if search_terms or exact_codes or pattern_codes %}\n",
    "                AND (\n",
    "                    {%- if search_terms %}\n",
    "                    (\n",
    "                        {%- for term in search_terms %}\n",
    "                        {{ \"OR \" if not loop.first else \"\" }}LOWER(concept_name) LIKE '%{{ term|lower }}%'\n",
    "                        {%- endfor %}\n",
    "                    )\n",
    "                    {%- endif %}\n",
    "\n",
    "                    {%- if search_terms and (exact_codes or pattern_codes) %}OR{% endif %}\n",
    "\n",
    "                    {%- if exact_codes %}\n",
    "                    (\n",
    "                        {%- for vocab, codes in exact_codes.items() %}\n",
    "                        {%- if codes %}\n",
    "                        {{ \"OR \" if not loop.first else \"\" }}(vocabulary_id = '{{ vocab }}' AND concept_code IN ({{ codes|join_quotes }}))\n",
    "                        {%- endif %}\n",
    "                        {%- endfor %}\n",
    "                    )\n",
    "                    {%- endif %}\n",
    "\n",
    "                    {%- if (search_terms or exact_codes) and pattern_codes %}OR{% endif %}\n",
    "\n",
    "                    {%- if pattern_codes %}\n",
    "                    (\n",
    "                        {%- for vocab, patterns in pattern_codes.items() %}\n",
    "                        {%- if patterns %}\n",
    "                        {{ \"OR \" if not loop.first else \"\" }}(vocabulary_id = '{{ vocab }}' AND (\n",
    "                            {%- for pattern in patterns %}\n",
    "                            {{ \"OR \" if not loop.first else \"\" }}concept_code LIKE '{{ pattern }}'\n",
    "                            {%- endfor %}\n",
    "                        ))\n",
    "                        {%- endif %}\n",
    "                        {%- endfor %}\n",
    "                    )\n",
    "                    {%- endif %}\n",
    "                )\n",
    "                {%- endif %}\n",
    "        ),\n",
    "        -- Regular events (non-V codes)\n",
    "        regular_codes AS (\n",
    "            -- Get codes from condition_occurrence via source_value (non-V codes)\n",
    "            SELECT\n",
    "                co.person_id,\n",
    "                co.condition_source_value AS concept_code,\n",
    "                fc.vocabulary_id,\n",
    "                fc.concept_name,\n",
    "                'condition' AS domain\n",
    "            FROM {{ version }}.condition_occurrence co\n",
    "            JOIN filtered_concepts fc \n",
    "                ON co.condition_source_value = fc.concept_code\n",
    "            WHERE NOT co.condition_source_value LIKE 'V%'\n",
    "            {%- if person_ids %}\n",
    "            AND co.person_id IN ({{ person_ids }})\n",
    "            {%- endif %}\n",
    "\n",
    "            UNION ALL\n",
    "\n",
    "            -- Get codes from condition_occurrence via source_concept_id (non-V codes)\n",
    "            SELECT\n",
    "                co.person_id,\n",
    "                fc.concept_code,\n",
    "                fc.vocabulary_id,\n",
    "                fc.concept_name,\n",
    "                'condition' AS domain\n",
    "            FROM {{ version }}.condition_occurrence co\n",
    "            JOIN filtered_concepts fc \n",
    "                ON co.condition_source_concept_id = fc.concept_id\n",
    "            WHERE NOT fc.concept_code LIKE 'V%'\n",
    "            {%- if person_ids %}\n",
    "            AND co.person_id IN ({{ person_ids }})\n",
    "            {%- endif %}\n",
    "\n",
    "            UNION ALL\n",
    "\n",
    "            -- Get codes from observation via source_value (non-V codes)\n",
    "            SELECT\n",
    "                o.person_id,\n",
    "                o.observation_source_value AS concept_code,\n",
    "                fc.vocabulary_id,\n",
    "                fc.concept_name,\n",
    "                'observation' AS domain\n",
    "            FROM {{ version }}.observation o\n",
    "            JOIN filtered_concepts fc \n",
    "                ON o.observation_source_value = fc.concept_code\n",
    "            WHERE NOT o.observation_source_value LIKE 'V%'\n",
    "            {%- if person_ids %}\n",
    "            AND o.person_id IN ({{ person_ids }})\n",
    "            {%- endif %}\n",
    "\n",
    "            UNION ALL\n",
    "\n",
    "            -- Get codes from observation via source_concept_id (non-V codes)\n",
    "            SELECT\n",
    "                o.person_id,\n",
    "                fc.concept_code,\n",
    "                fc.vocabulary_id,\n",
    "                fc.concept_name,\n",
    "                'observation' AS domain\n",
    "            FROM {{ version }}.observation o\n",
    "            JOIN filtered_concepts fc \n",
    "                ON o.observation_source_concept_id = fc.concept_id\n",
    "            WHERE NOT fc.concept_code LIKE 'V%'\n",
    "            {%- if person_ids %}\n",
    "            AND o.person_id IN ({{ person_ids }})\n",
    "            {%- endif %}\n",
    "        ),\n",
    "\n",
    "        -- V code events from condition_occurrence with special handling\n",
    "        v_codes AS (\n",
    "            -- source_value path\n",
    "            SELECT\n",
    "                co.person_id,\n",
    "                co.condition_source_value AS concept_code,\n",
    "                co.condition_concept_id AS concept_id,\n",
    "                'condition' AS domain\n",
    "            FROM {{ version }}.condition_occurrence co\n",
    "            JOIN filtered_concepts fc \n",
    "                ON co.condition_source_value = fc.concept_code\n",
    "            WHERE co.condition_source_value LIKE 'V%'\n",
    "            {%- if person_ids %}\n",
    "            AND co.person_id IN ({{ person_ids }})\n",
    "            {%- endif %}\n",
    "\n",
    "            UNION ALL\n",
    "\n",
    "            -- source_concept_id path\n",
    "            SELECT\n",
    "                co.person_id,\n",
    "                fc.concept_code,\n",
    "                co.condition_concept_id AS concept_id,\n",
    "                'condition' AS domain\n",
    "            FROM {{ version }}.condition_occurrence co\n",
    "            JOIN filtered_concepts fc \n",
    "                ON co.condition_source_concept_id = fc.concept_id\n",
    "            WHERE fc.concept_code LIKE 'V%'\n",
    "            {%- if person_ids %}\n",
    "            AND co.person_id IN ({{ person_ids }})\n",
    "            {%- endif %}\n",
    "            \n",
    "            UNION ALL\n",
    "\n",
    "            -- source_value path\n",
    "            SELECT\n",
    "                o.person_id,\n",
    "                o.observation_source_value AS concept_code,\n",
    "                o.observation_concept_id AS concept_id,\n",
    "                'observation' AS domain\n",
    "            FROM {{ version }}.observation o\n",
    "            JOIN filtered_concepts fc \n",
    "                ON o.observation_source_value = fc.concept_code\n",
    "            WHERE o.observation_source_value LIKE 'V%'\n",
    "            {%- if person_ids %}\n",
    "            AND o.person_id IN ({{ person_ids }})\n",
    "            {%- endif %}\n",
    "\n",
    "            UNION ALL\n",
    "\n",
    "            -- source_concept_id path\n",
    "            SELECT\n",
    "                o.person_id,\n",
    "                fc.concept_code,\n",
    "                o.observation_concept_id AS concept_id,\n",
    "                'observation' AS domain\n",
    "            FROM {{ version }}.observation o\n",
    "            JOIN filtered_concepts fc \n",
    "                ON o.observation_source_concept_id = fc.concept_id\n",
    "            WHERE fc.concept_code LIKE 'V%'\n",
    "            {%- if person_ids %}\n",
    "            AND o.person_id IN ({{ person_ids }})\n",
    "            {%- endif %}\n",
    "        ),\n",
    "\n",
    "        -- Apply correct vocabulary attribution for V codes\n",
    "        v_codes_corrected AS (\n",
    "            SELECT\n",
    "                v.person_id,\n",
    "                v.concept_code,\n",
    "                c.vocabulary_id,\n",
    "                c.concept_name,\n",
    "                v.domain\n",
    "            FROM v_codes v\n",
    "            JOIN {{ version }}.concept_relationship cr\n",
    "                ON v.concept_id = cr.concept_id_1\n",
    "            JOIN {{ version }}.concept c\n",
    "                ON cr.concept_id_2 = c.concept_id\n",
    "            WHERE c.vocabulary_id IN ({{ vocabularies|join_quotes }})\n",
    "            AND v.concept_code = c.concept_code\n",
    "        ),\n",
    "\n",
    "        -- Combine regular events with corrected V code events\n",
    "        all_events AS (\n",
    "            SELECT * FROM regular_codes\n",
    "            UNION ALL\n",
    "            SELECT * FROM v_codes_corrected\n",
    "        )\n",
    "\n",
    "        -- Final output with counts\n",
    "        SELECT\n",
    "            vocabulary_id,\n",
    "            concept_code,\n",
    "            concept_name,\n",
    "            COUNT(DISTINCT person_id) AS unique_persons,\n",
    "            COUNT(*) AS total_events,\n",
    "        FROM all_events\n",
    "        GROUP BY vocabulary_id, concept_code, concept_name\n",
    "        ORDER BY vocabulary_id ASC, concept_code ASC\n",
    "        \"\"\")       \n",
    "        \n",
    "        # Format person_ids if it's a list\n",
    "        if isinstance(person_ids, list):\n",
    "            person_ids = ', '.join(str(pid) for pid in person_ids)\n",
    "            \n",
    "        # Initialize dictionaries\n",
    "        exact_codes = exact_codes or {}\n",
    "        pattern_codes = pattern_codes or {}\n",
    "        exclude_codes = exclude_codes or {}\n",
    "        \n",
    "        # Render the template\n",
    "        self.query_text = template.render(\n",
    "            version=self.version,\n",
    "            vocabularies=vocabularies,\n",
    "            search_terms=search_terms,\n",
    "            exclude_terms=exclude_terms,\n",
    "            exact_codes=exact_codes,\n",
    "            pattern_codes=pattern_codes,\n",
    "            exclude_codes=exclude_codes,\n",
    "            person_ids=person_ids\n",
    "        )\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def person_code_df(self,\n",
    "                       name: str,\n",
    "                       vocabularies: List[str] = None,\n",
    "                       search_terms: List[str] = None, \n",
    "                       exclude_terms: List[str] = None,\n",
    "                       exact_codes: Dict[str, List[str]] = None,\n",
    "                       pattern_codes: Dict[str, List[str]] = None,\n",
    "                       exclude_codes: Dict[str, List[str]] = None,\n",
    "                       person_ids: Union[List[int], str] = None,\n",
    "                       dates: bool = False):\n",
    "        \"\"\"\n",
    "        Creates a person-level dataframe with diagnosis information.\n",
    "\n",
    "        Args:\n",
    "            name: String to use as column name prefix (e.g., 'htn')\n",
    "            vocabularies: List of vocabulary IDs to search\n",
    "            search_terms: List of terms to search in concept names\n",
    "            exclude_terms: List of terms to exclude from concept names\n",
    "            exact_codes: Dictionary mapping vocabularies to lists of exact codes\n",
    "            pattern_codes: Dictionary mapping vocabularies to lists of code patterns\n",
    "            exclude_codes: Dictionary mapping vocabularies to lists of codes to exclude\n",
    "            person_ids: List of person IDs to filter to, or a string expression\n",
    "            dates: Whether to include date information (first, second, last)\n",
    "\n",
    "        Returns:\n",
    "            Polars DataFrame with person_id, {name}_n, vocab, and date columns if requested\n",
    "        \"\"\"\n",
    "\n",
    "        if not vocabularies:\n",
    "            # Default to standard vocabularies if nothing specified\n",
    "            vocabularies = [\"ICD9CM\", \"ICD10CM\", \"SNOMED\"]\n",
    "\n",
    "        # Add any vocabularies from exact_codes or pattern_codes that aren't already included\n",
    "        vocab_additions = set()\n",
    "        for vocab in list(exact_codes.keys() if exact_codes else []) + list(pattern_codes.keys() if pattern_codes else []):\n",
    "            if vocab not in vocabularies:\n",
    "                vocab_additions.add(vocab)\n",
    "                vocabularies.append(vocab)\n",
    "\n",
    "        # Notify if vocabularies were added\n",
    "        if vocab_additions:\n",
    "            print(f\"Added vocabularies from code specifications: {', '.join(vocab_additions)}\")\n",
    "\n",
    "        # Store query parameters for summary\n",
    "        self.last_query_params = {\n",
    "            \"type\": \"person_diagnosis\",\n",
    "            \"name\": name,\n",
    "            \"vocabularies\": vocabularies,\n",
    "            \"search_terms\": search_terms,\n",
    "            \"exclude_terms\": exclude_terms,\n",
    "            \"exact_codes\": exact_codes,\n",
    "            \"pattern_codes\": pattern_codes,\n",
    "            \"exclude_codes\": exclude_codes,\n",
    "            \"person_ids\": person_ids,\n",
    "            \"dates\": dates\n",
    "        }\n",
    "\n",
    "        # Generate query summary text\n",
    "        self.query_summary = self._generate_query_summary()\n",
    "\n",
    "        # Create Jinja2 environment and add filter\n",
    "        env = Environment()\n",
    "\n",
    "        # Define and add filter to environment\n",
    "        def join_quotes(items):\n",
    "            return ', '.join(f\"'{item}'\" for item in items)\n",
    "\n",
    "        env.filters['join_quotes'] = join_quotes\n",
    "\n",
    "        template = env.from_string(\"\"\"\n",
    "        WITH filtered_concepts AS (\n",
    "            SELECT DISTINCT concept_id, vocabulary_id, concept_code, concept_name\n",
    "            FROM {{ version }}.concept\n",
    "            WHERE \n",
    "                vocabulary_id IN ({{ vocabularies|join_quotes }})\n",
    "                {%- if exclude_terms %}\n",
    "                AND (\n",
    "                    {%- for term in exclude_terms %}\n",
    "                    {{ \"AND \" if not loop.first else \"\" }}LOWER(concept_name) NOT LIKE '%{{ term|lower }}%'\n",
    "                    {%- endfor %}\n",
    "                )\n",
    "                {%- endif %}\n",
    "                {%- for vocab, codes in exclude_codes.items() %}\n",
    "                {%- if codes %}\n",
    "                AND NOT (\n",
    "                    vocabulary_id = '{{ vocab }}' AND concept_code IN ({{ codes|join_quotes }})\n",
    "                )\n",
    "                {%- endif %}\n",
    "                {%- endfor %}\n",
    "                {%- if search_terms or exact_codes or pattern_codes %}\n",
    "                AND (\n",
    "                    {%- if search_terms %}\n",
    "                    (\n",
    "                        {%- for term in search_terms %}\n",
    "                        {{ \"OR \" if not loop.first else \"\" }}LOWER(concept_name) LIKE '%{{ term|lower }}%'\n",
    "                        {%- endfor %}\n",
    "                    )\n",
    "                    {%- endif %}\n",
    "\n",
    "                    {%- if search_terms and (exact_codes or pattern_codes) %}OR{% endif %}\n",
    "\n",
    "                    {%- if exact_codes %}\n",
    "                    (\n",
    "                        {%- for vocab, codes in exact_codes.items() %}\n",
    "                        {%- if codes %}\n",
    "                        {{ \"OR \" if not loop.first else \"\" }}(vocabulary_id = '{{ vocab }}' AND concept_code IN ({{ codes|join_quotes }}))\n",
    "                        {%- endif %}\n",
    "                        {%- endfor %}\n",
    "                    )\n",
    "                    {%- endif %}\n",
    "\n",
    "                    {%- if (search_terms or exact_codes) and pattern_codes %}OR{% endif %}\n",
    "\n",
    "                    {%- if pattern_codes %}\n",
    "                    (\n",
    "                        {%- for vocab, patterns in pattern_codes.items() %}\n",
    "                        {%- if patterns %}\n",
    "                        {{ \"OR \" if not loop.first else \"\" }}(vocabulary_id = '{{ vocab }}' AND (\n",
    "                            {%- for pattern in patterns %}\n",
    "                            {{ \"OR \" if not loop.first else \"\" }}concept_code LIKE '{{ pattern }}'\n",
    "                            {%- endfor %}\n",
    "                        ))\n",
    "                        {%- endif %}\n",
    "                        {%- endfor %}\n",
    "                    )\n",
    "                    {%- endif %}\n",
    "                )\n",
    "                {%- endif %}\n",
    "        ),\n",
    "        -- Regular events (non-V codes)\n",
    "        regular_events AS (\n",
    "            -- Get codes from condition_occurrence via source_value (non-V codes)\n",
    "            SELECT\n",
    "                co.person_id,\n",
    "                co.condition_source_value AS concept_code,\n",
    "                fc.vocabulary_id,\n",
    "                fc.concept_name,\n",
    "                'condition' AS domain,\n",
    "                co.condition_start_date AS event_date\n",
    "            FROM {{ version }}.condition_occurrence co\n",
    "            JOIN filtered_concepts fc \n",
    "                ON co.condition_source_value = fc.concept_code\n",
    "            WHERE NOT co.condition_source_value LIKE 'V%'\n",
    "            {%- if person_ids %}\n",
    "            AND co.person_id IN ({{ person_ids }})\n",
    "            {%- endif %}\n",
    "\n",
    "            UNION ALL\n",
    "\n",
    "            -- Get codes from condition_occurrence via source_concept_id (non-V codes)\n",
    "            SELECT\n",
    "                co.person_id,\n",
    "                fc.concept_code,\n",
    "                fc.vocabulary_id,\n",
    "                fc.concept_name,\n",
    "                'condition' AS domain,\n",
    "                co.condition_start_date AS event_date\n",
    "            FROM {{ version }}.condition_occurrence co\n",
    "            JOIN filtered_concepts fc \n",
    "                ON co.condition_source_concept_id = fc.concept_id\n",
    "            WHERE NOT fc.concept_code LIKE 'V%'\n",
    "            {%- if person_ids %}\n",
    "            AND co.person_id IN ({{ person_ids }})\n",
    "            {%- endif %}\n",
    "\n",
    "            UNION ALL\n",
    "\n",
    "            -- Get codes from observation via source_value (non-V codes)\n",
    "            SELECT\n",
    "                o.person_id,\n",
    "                o.observation_source_value AS concept_code,\n",
    "                fc.vocabulary_id,\n",
    "                fc.concept_name,\n",
    "                'observation' AS domain,\n",
    "                o.observation_date AS event_date\n",
    "            FROM {{ version }}.observation o\n",
    "            JOIN filtered_concepts fc \n",
    "                ON o.observation_source_value = fc.concept_code\n",
    "            WHERE NOT o.observation_source_value LIKE 'V%'\n",
    "            {%- if person_ids %}\n",
    "            AND o.person_id IN ({{ person_ids }})\n",
    "            {%- endif %}\n",
    "\n",
    "            UNION ALL\n",
    "\n",
    "            -- Get codes from observation via source_concept_id (non-V codes)\n",
    "            SELECT\n",
    "                o.person_id,\n",
    "                fc.concept_code,\n",
    "                fc.vocabulary_id,\n",
    "                fc.concept_name,\n",
    "                'observation' AS domain,\n",
    "                o.observation_date AS event_date\n",
    "            FROM {{ version }}.observation o\n",
    "            JOIN filtered_concepts fc \n",
    "                ON o.observation_source_concept_id = fc.concept_id\n",
    "            WHERE NOT fc.concept_code LIKE 'V%'\n",
    "            {%- if person_ids %}\n",
    "            AND o.person_id IN ({{ person_ids }})\n",
    "            {%- endif %}\n",
    "        ),\n",
    "\n",
    "        -- V code events from condition_occurrence with special handling\n",
    "        v_events AS (\n",
    "            -- source_value path\n",
    "            SELECT\n",
    "                co.person_id,\n",
    "                co.condition_source_value AS concept_code,\n",
    "                co.condition_concept_id AS concept_id,\n",
    "                'condition' AS domain,\n",
    "                co.condition_start_date AS event_date\n",
    "            FROM {{ version }}.condition_occurrence co\n",
    "            JOIN filtered_concepts fc \n",
    "                ON co.condition_source_value = fc.concept_code\n",
    "            WHERE co.condition_source_value LIKE 'V%'\n",
    "            {%- if person_ids %}\n",
    "            AND co.person_id IN ({{ person_ids }})\n",
    "            {%- endif %}\n",
    "\n",
    "            UNION ALL\n",
    "\n",
    "            -- source_concept_id path\n",
    "            SELECT\n",
    "                co.person_id,\n",
    "                fc.concept_code,\n",
    "                co.condition_concept_id AS concept_id,\n",
    "                'condition' AS domain,\n",
    "                co.condition_start_date AS event_date\n",
    "            FROM {{ version }}.condition_occurrence co\n",
    "            JOIN filtered_concepts fc \n",
    "                ON co.condition_source_concept_id = fc.concept_id\n",
    "            WHERE fc.concept_code LIKE 'V%'\n",
    "            {%- if person_ids %}\n",
    "            AND co.person_id IN ({{ person_ids }})\n",
    "            {%- endif %}\n",
    "\n",
    "            UNION ALL\n",
    "\n",
    "            -- source_value path\n",
    "            SELECT\n",
    "                o.person_id,\n",
    "                o.observation_source_value AS concept_code,\n",
    "                o.observation_concept_id AS concept_id,\n",
    "                'observation' AS domain,\n",
    "                o.observation_date AS event_date\n",
    "            FROM {{ version }}.observation o\n",
    "            JOIN filtered_concepts fc \n",
    "                ON o.observation_source_value = fc.concept_code\n",
    "            WHERE o.observation_source_value LIKE 'V%'\n",
    "            {%- if person_ids %}\n",
    "            AND o.person_id IN ({{ person_ids }})\n",
    "            {%- endif %}\n",
    "\n",
    "            UNION ALL\n",
    "\n",
    "            -- source_concept_id path\n",
    "            SELECT\n",
    "                o.person_id,\n",
    "                fc.concept_code,\n",
    "                o.observation_concept_id AS concept_id,\n",
    "                'observation' AS domain,\n",
    "                o.observation_date AS event_date\n",
    "            FROM {{ version }}.observation o\n",
    "            JOIN filtered_concepts fc \n",
    "                ON o.observation_source_concept_id = fc.concept_id\n",
    "            WHERE fc.concept_code LIKE 'V%'\n",
    "            {%- if person_ids %}\n",
    "            AND o.person_id IN ({{ person_ids }})\n",
    "            {%- endif %}\n",
    "        ),\n",
    "\n",
    "        -- Apply correct vocabulary attribution for V codes\n",
    "        v_events_corrected AS (\n",
    "            SELECT\n",
    "                v.person_id,\n",
    "                v.concept_code,\n",
    "                c.vocabulary_id,\n",
    "                c.concept_name,\n",
    "                v.domain,\n",
    "                v.event_date\n",
    "            FROM v_events v\n",
    "            JOIN {{ version }}.concept_relationship cr\n",
    "                ON v.concept_id = cr.concept_id_1\n",
    "            JOIN {{ version }}.concept c\n",
    "                ON cr.concept_id_2 = c.concept_id\n",
    "            WHERE c.vocabulary_id IN ({{ vocabularies|join_quotes }})\n",
    "            AND v.concept_code = c.concept_code\n",
    "        ),\n",
    "\n",
    "        -- Combine regular events with corrected V code events\n",
    "        all_events AS (\n",
    "            SELECT * FROM regular_events\n",
    "            UNION ALL\n",
    "            SELECT * FROM v_events_corrected\n",
    "        ),\n",
    "\n",
    "        -- Get distinct dates per person\n",
    "        distinct_dates AS (\n",
    "            SELECT \n",
    "                person_id,\n",
    "                vocabulary_id,\n",
    "                event_date\n",
    "            FROM all_events\n",
    "            GROUP BY person_id, vocabulary_id, event_date\n",
    "        ),\n",
    "\n",
    "        -- Calculate vocabulary summary per person\n",
    "        vocab_summary AS (\n",
    "            SELECT\n",
    "                person_id,\n",
    "                STRING_AGG(CASE \n",
    "                    WHEN vocabulary_id = 'ICD9CM' THEN '9'\n",
    "                    WHEN vocabulary_id = 'ICD10CM' THEN '10'\n",
    "                    WHEN vocabulary_id = 'SNOMED' THEN 'SNO'\n",
    "                    ELSE SUBSTR(vocabulary_id, 1, 3)\n",
    "                END, ' ' ORDER BY vocabulary_id) AS vocab\n",
    "            FROM (\n",
    "                SELECT DISTINCT person_id, vocabulary_id\n",
    "                FROM all_events\n",
    "            )\n",
    "            GROUP BY person_id\n",
    "        ),\n",
    "\n",
    "        -- Count distinct dates per person\n",
    "        date_counts AS (\n",
    "            SELECT\n",
    "                person_id,\n",
    "                COUNT(DISTINCT event_date) AS {{ name }}_n\n",
    "            FROM all_events\n",
    "            GROUP BY person_id\n",
    "        ){% if dates %},\n",
    "\n",
    "        -- Get ordered dates per person\n",
    "        ordered_dates AS (\n",
    "            SELECT\n",
    "                person_id,\n",
    "                event_date,\n",
    "                ROW_NUMBER() OVER (PARTITION BY person_id ORDER BY event_date ASC) AS date_order,\n",
    "                ROW_NUMBER() OVER (PARTITION BY person_id ORDER BY event_date DESC) AS rev_date_order\n",
    "            FROM (\n",
    "                SELECT DISTINCT person_id, event_date\n",
    "                FROM all_events\n",
    "            )\n",
    "        ),\n",
    "\n",
    "        -- Get first, second, and last dates\n",
    "        key_dates AS (\n",
    "            SELECT\n",
    "                person_id,\n",
    "                MAX(CASE WHEN date_order = 1 THEN event_date END) AS {{ name }}_1,\n",
    "                MAX(CASE WHEN date_order = 2 THEN event_date END) AS {{ name }}_2,\n",
    "                MAX(CASE WHEN rev_date_order = 1 THEN event_date END) AS {{ name }}_last\n",
    "            FROM ordered_dates\n",
    "            GROUP BY person_id\n",
    "        ){% endif %}\n",
    "\n",
    "        -- Final person-level output\n",
    "        SELECT\n",
    "            dc.person_id,\n",
    "            dc.{{ name }}_n,\n",
    "            vs.vocab{% if dates %},\n",
    "            kd.{{ name }}_1,\n",
    "            kd.{{ name }}_2,\n",
    "            kd.{{ name }}_last{% endif %}\n",
    "        FROM date_counts dc\n",
    "        JOIN vocab_summary vs ON dc.person_id = vs.person_id\n",
    "        {% if dates %}JOIN key_dates kd ON dc.person_id = kd.person_id{% endif %}\n",
    "        ORDER BY dc.person_id\n",
    "        \"\"\")       \n",
    "\n",
    "        # Format person_ids if it's a list\n",
    "        if isinstance(person_ids, list):\n",
    "            person_ids = ', '.join(str(pid) for pid in person_ids)\n",
    "\n",
    "        # Initialize dictionaries\n",
    "        exact_codes = exact_codes or {}\n",
    "        pattern_codes = pattern_codes or {}\n",
    "        exclude_codes = exclude_codes or {}\n",
    "\n",
    "        # Render the template\n",
    "        self.query_text = template.render(\n",
    "            version=self.version,\n",
    "            name=name,\n",
    "            vocabularies=vocabularies,\n",
    "            search_terms=search_terms,\n",
    "            exclude_terms=exclude_terms,\n",
    "            exact_codes=exact_codes,\n",
    "            pattern_codes=pattern_codes,\n",
    "            exclude_codes=exclude_codes,\n",
    "            person_ids=person_ids,\n",
    "            dates=dates\n",
    "        )\n",
    "\n",
    "        return self\n",
    "    \n",
    "    def find_procedure_codes(self, \n",
    "                            search_tables: List[str] = None,\n",
    "                            vocabularies: List[str] = None,\n",
    "                            concept_classes: List[str] = None,\n",
    "                            search_terms: List[str] = None, \n",
    "                            exclude_terms: List[str] = None,\n",
    "                            exact_codes: Dict[str, List[str]] = None,\n",
    "                            pattern_codes: Dict[str, List[str]] = None,\n",
    "                            exclude_codes: Dict[str, List[str]] = None,\n",
    "                            person_ids: Union[List[int], str] = None):\n",
    "        \"\"\"\n",
    "        Find procedure codes in procedure_occurrence and/or observation tables.\n",
    "\n",
    "        Args:\n",
    "            search_tables: Tables to search. Options: ['procedure_occurrence', 'observation']\n",
    "                          Default: ['procedure_occurrence', 'observation'] \n",
    "            vocabularies: Procedure vocabularies to search \n",
    "                         Default: [\"CPT4\", \"HCPCS\", \"ICD10PCS\", \"ICD9Proc\", \"LOINC\", \"SNOMED\"]\n",
    "            concept_classes: List of concept classes to filter to (optional)\n",
    "                            Default: None (no filtering - returns all concept classes)\n",
    "            search_terms: List of terms to search in concept names\n",
    "            exclude_terms: List of terms to exclude from concept names  \n",
    "            exact_codes: Dictionary mapping vocabularies to lists of exact codes\n",
    "            pattern_codes: Dictionary mapping vocabularies to lists of code patterns (use % wildcards)\n",
    "            exclude_codes: Dictionary mapping vocabularies to lists of codes to exclude\n",
    "            person_ids: List of person IDs to filter to, or a string expression\n",
    "\n",
    "        Returns:\n",
    "            Self (for method chaining), call execute_gbq() to run the query\n",
    "        \"\"\"\n",
    "\n",
    "        if not search_tables:\n",
    "            search_tables = ['procedure_occurrence', 'observation']\n",
    "\n",
    "        if not vocabularies:\n",
    "            vocabularies = [\"CPT4\", \"HCPCS\", \"ICD10PCS\", \"ICD9Proc\", \"Nebraska Lexicon\", \"LOINC\", \"SNOMED\"]\n",
    "\n",
    "        # concept_classes are not included by default, but these are the recommended classes for vocabularies\n",
    "        # CPT4: \"CPT4\", \"CPT4 Hierarchy\"\n",
    "        # HCPCS: \"HCPCS\"\n",
    "        # ICD10: \"ICD10PCS\", \"ICD10PCS Hierarchy\",\n",
    "        # ICD9: \"2-dig nonbill code\", \"3-dig billing code\", \"3-dig nonbill code\", \"4-dig billing code\", \"Procedure\"\n",
    "        # LOINC, Nebraska Lexicon, SNOMED: \"Procedure\"\n",
    "            \n",
    "        # Add any vocabularies from exact_codes or pattern_codes that aren't already included\n",
    "        vocab_additions = set()\n",
    "        for vocab in list(exact_codes.keys() if exact_codes else []) + list(pattern_codes.keys() if pattern_codes else []):\n",
    "            if vocab not in vocabularies:\n",
    "                vocab_additions.add(vocab)\n",
    "                vocabularies.append(vocab)\n",
    "\n",
    "        # Notify if vocabularies were added\n",
    "        if vocab_additions:\n",
    "            print(f\"Added vocabularies from code specifications: {', '.join(vocab_additions)}\")\n",
    "\n",
    "        # Store query parameters for summary\n",
    "        self.last_query_params = {\n",
    "            \"type\": \"procedure_codes\",\n",
    "            \"search_tables\": search_tables,\n",
    "            \"vocabularies\": vocabularies,\n",
    "            \"concept_classes\": concept_classes,\n",
    "            \"search_terms\": search_terms,\n",
    "            \"exclude_terms\": exclude_terms,\n",
    "            \"exact_codes\": exact_codes,\n",
    "            \"pattern_codes\": pattern_codes,\n",
    "            \"exclude_codes\": exclude_codes,\n",
    "            \"person_ids\": person_ids\n",
    "        }\n",
    "\n",
    "        # Generate query summary text\n",
    "        self.query_summary = self._generate_query_summary()\n",
    "\n",
    "        # Create Jinja2 environment and add filter\n",
    "        env = Environment()\n",
    "\n",
    "        # Define and add filter to environment\n",
    "        def join_quotes(items):\n",
    "            return ', '.join(f\"'{item}'\" for item in items)\n",
    "\n",
    "        env.filters['join_quotes'] = join_quotes\n",
    "\n",
    "        template = env.from_string(\"\"\"\n",
    "        WITH filtered_concepts AS (\n",
    "            SELECT DISTINCT concept_id, vocabulary_id, concept_class_id, concept_code, concept_name\n",
    "            FROM {{ version }}.concept\n",
    "            WHERE \n",
    "                vocabulary_id IN ({{ vocabularies|join_quotes }})\n",
    "                {%- if concept_classes %}\n",
    "                AND concept_class_id IN ({{ concept_classes|join_quotes}})\n",
    "                {%- endif %}\n",
    "                {%- if exclude_terms %}\n",
    "                AND (\n",
    "                    {%- for term in exclude_terms %}\n",
    "                    {{ \"AND \" if not loop.first else \"\" }}LOWER(concept_name) NOT LIKE '%{{ term|lower }}%'\n",
    "                    {%- endfor %}\n",
    "                )\n",
    "                {%- endif %}\n",
    "                {%- for vocab, codes in exclude_codes.items() %}\n",
    "                {%- if codes %}\n",
    "                AND NOT (\n",
    "                    vocabulary_id = '{{ vocab }}' AND concept_code IN ({{ codes|join_quotes }})\n",
    "                )\n",
    "                {%- endif %}\n",
    "                {%- endfor %}\n",
    "                {%- if search_terms or exact_codes or pattern_codes %}\n",
    "                AND (\n",
    "                    {%- if search_terms %}\n",
    "                    (\n",
    "                        {%- for term in search_terms %}\n",
    "                        {{ \"OR \" if not loop.first else \"\" }}LOWER(concept_name) LIKE '%{{ term|lower }}%'\n",
    "                        {%- endfor %}\n",
    "                    )\n",
    "                    {%- endif %}\n",
    "\n",
    "                    {%- if search_terms and (exact_codes or pattern_codes) %}OR{% endif %}\n",
    "\n",
    "                    {%- if exact_codes %}\n",
    "                    (\n",
    "                        {%- for vocab, codes in exact_codes.items() %}\n",
    "                        {%- if codes %}\n",
    "                        {{ \"OR \" if not loop.first else \"\" }}(vocabulary_id = '{{ vocab }}' AND concept_code IN ({{ codes|join_quotes }}))\n",
    "                        {%- endif %}\n",
    "                        {%- endfor %}\n",
    "                    )\n",
    "                    {%- endif %}\n",
    "\n",
    "                    {%- if (search_terms or exact_codes) and pattern_codes %}OR{% endif %}\n",
    "\n",
    "                    {%- if pattern_codes %}\n",
    "                    (\n",
    "                        {%- for vocab, patterns in pattern_codes.items() %}\n",
    "                        {%- if patterns %}\n",
    "                        {{ \"OR \" if not loop.first else \"\" }}(vocabulary_id = '{{ vocab }}' AND (\n",
    "                            {%- for pattern in patterns %}\n",
    "                            {{ \"OR \" if not loop.first else \"\" }}concept_code LIKE '{{ pattern }}'\n",
    "                            {%- endfor %}\n",
    "                        ))\n",
    "                        {%- endif %}\n",
    "                        {%- endfor %}\n",
    "                    )\n",
    "                    {%- endif %}\n",
    "                )\n",
    "                {%- endif %}\n",
    "        ),\n",
    "\n",
    "        -- Procedure events from procedure_occurrence\n",
    "        {% if 'procedure_occurrence' in search_tables %}\n",
    "        procedure_table_codes AS (\n",
    "            -- Procedures via source_value\n",
    "            SELECT\n",
    "                po.person_id,\n",
    "                po.procedure_source_value AS concept_code,\n",
    "                fc.vocabulary_id,\n",
    "                fc.concept_class_id,\n",
    "                fc.concept_name,\n",
    "                'procedure_occurrence' AS source_table\n",
    "            FROM {{ version }}.procedure_occurrence po\n",
    "            JOIN filtered_concepts fc \n",
    "                ON po.procedure_source_value = fc.concept_code\n",
    "            {%- if person_ids %}\n",
    "            WHERE po.person_id IN ({{ person_ids }})\n",
    "            {%- endif %}\n",
    "\n",
    "            UNION ALL\n",
    "\n",
    "            -- Procedures via source_concept_id\n",
    "            SELECT\n",
    "                po.person_id,\n",
    "                fc.concept_code,\n",
    "                fc.vocabulary_id,\n",
    "                fc.concept_class_id,\n",
    "                fc.concept_name,\n",
    "                'procedure_occurrence' AS source_table\n",
    "            FROM {{ version }}.procedure_occurrence po\n",
    "            JOIN filtered_concepts fc \n",
    "                ON po.procedure_source_concept_id = fc.concept_id\n",
    "            {%- if person_ids %}\n",
    "            WHERE po.person_id IN ({{ person_ids }})\n",
    "            {%- endif %}\n",
    "        ),\n",
    "        {% endif %}\n",
    "\n",
    "        -- Procedure events from observation\n",
    "        {% if 'observation' in search_tables %}\n",
    "        observation_procedure_codes AS (\n",
    "            -- Procedures from observation via source_value\n",
    "            SELECT\n",
    "                o.person_id,\n",
    "                o.observation_source_value AS concept_code,\n",
    "                fc.vocabulary_id,\n",
    "                fc.concept_class_id,\n",
    "                fc.concept_name,\n",
    "                'observation' AS source_table\n",
    "            FROM {{ version }}.observation o\n",
    "            JOIN filtered_concepts fc \n",
    "                ON o.observation_source_value = fc.concept_code\n",
    "            {%- if person_ids %}\n",
    "            WHERE o.person_id IN ({{ person_ids }})\n",
    "            {%- endif %}\n",
    "\n",
    "            UNION ALL\n",
    "\n",
    "            -- Procedures from observation via source_concept_id\n",
    "            SELECT\n",
    "                o.person_id,\n",
    "                fc.concept_code,\n",
    "                fc.vocabulary_id,\n",
    "                fc.concept_class_id,\n",
    "                fc.concept_name,\n",
    "                'observation' AS source_table\n",
    "            FROM {{ version }}.observation o\n",
    "            JOIN filtered_concepts fc \n",
    "                ON o.observation_source_concept_id = fc.concept_id\n",
    "            {%- if person_ids %}\n",
    "            WHERE o.person_id IN ({{ person_ids }})\n",
    "            {%- endif %}\n",
    "        ),\n",
    "        {% endif %}\n",
    "\n",
    "        -- Combine results from all searched tables\n",
    "        all_procedure_events AS (\n",
    "            {% if 'procedure_occurrence' in search_tables %}\n",
    "            SELECT * FROM procedure_table_codes\n",
    "            {% endif %}\n",
    "            {% if 'observation' in search_tables %}\n",
    "            {% if 'procedure_occurrence' in search_tables %}UNION ALL{% endif %}\n",
    "            SELECT * FROM observation_procedure_codes\n",
    "            {% endif %}\n",
    "        )\n",
    "\n",
    "        -- Final output with counts\n",
    "        SELECT\n",
    "            vocabulary_id,\n",
    "            concept_class_id,\n",
    "            concept_code,\n",
    "            concept_name,\n",
    "            source_table,\n",
    "            COUNT(DISTINCT person_id) AS unique_persons,\n",
    "            COUNT(*) AS total_events\n",
    "        FROM all_procedure_events\n",
    "        GROUP BY vocabulary_id, concept_class_id, concept_code, concept_name, source_table\n",
    "        ORDER BY vocabulary_id ASC, concept_class_id ASC, concept_code ASC, source_table ASC\n",
    "        \"\"\")       \n",
    "\n",
    "        # Format person_ids if it's a list\n",
    "        if isinstance(person_ids, list):\n",
    "            person_ids = ', '.join(str(pid) for pid in person_ids)\n",
    "\n",
    "        # Initialize dictionaries\n",
    "        exact_codes = exact_codes or {}\n",
    "        pattern_codes = pattern_codes or {}\n",
    "        exclude_codes = exclude_codes or {}\n",
    "\n",
    "        # Render the template\n",
    "        self.query_text = template.render(\n",
    "            version=self.version,\n",
    "            search_tables=search_tables,\n",
    "            vocabularies=vocabularies,\n",
    "            concept_classes=concept_classes,\n",
    "            search_terms=search_terms,\n",
    "            exclude_terms=exclude_terms,\n",
    "            exact_codes=exact_codes,\n",
    "            pattern_codes=pattern_codes,\n",
    "            exclude_codes=exclude_codes,\n",
    "            person_ids=person_ids\n",
    "        )\n",
    "\n",
    "        return self\n",
    "    \n",
    "    def person_procedure_df(self,\n",
    "                            name: str,\n",
    "                            search_tables: List[str] = None,\n",
    "                            vocabularies: List[str] = None,\n",
    "                            concept_classes: List[str] = None,\n",
    "                            search_terms: List[str] = None, \n",
    "                            exclude_terms: List[str] = None,\n",
    "                            exact_codes: Dict[str, List[str]] = None,\n",
    "                            pattern_codes: Dict[str, List[str]] = None,\n",
    "                            exclude_codes: Dict[str, List[str]] = None,\n",
    "                            person_ids: Union[List[int], str] = None,\n",
    "                            dates: bool = False):\n",
    "        \"\"\"\n",
    "        Creates a person-level dataframe with procedure information.\n",
    "\n",
    "        Args:\n",
    "            name: String to use as column name prefix (e.g., 'surgery')\n",
    "            search_tables: Tables to search. Options: ['procedure_occurrence', 'observation']\n",
    "                          Default: ['procedure_occurrence', 'observation'] \n",
    "            vocabularies: Procedure vocabularies to search \n",
    "                         Default: [\"CPT4\", \"HCPCS\", \"ICD10PCS\", \"ICD9Proc\", \"Nebraska Lexicon\", \"LOINC\", \"SNOMED\"]\n",
    "            concept_classes: List of concept classes to filter to (optional)\n",
    "                            Default: None (no filtering - returns all concept classes)\n",
    "            search_terms: List of terms to search in concept names\n",
    "            exclude_terms: List of terms to exclude from concept names  \n",
    "            exact_codes: Dictionary mapping vocabularies to lists of exact codes\n",
    "            pattern_codes: Dictionary mapping vocabularies to lists of code patterns (use % wildcards)\n",
    "            exclude_codes: Dictionary mapping vocabularies to lists of codes to exclude\n",
    "            person_ids: List of person IDs to filter to, or a string expression\n",
    "            dates: Whether to include date information (first, second, last)\n",
    "\n",
    "        Returns:\n",
    "            Polars DataFrame with person_id, {name}_n, vocab, and date columns if requested\n",
    "        \"\"\"\n",
    "\n",
    "        if not search_tables:\n",
    "            search_tables = ['procedure_occurrence', 'observation']\n",
    "\n",
    "        if not vocabularies:\n",
    "            vocabularies = [\"CPT4\", \"HCPCS\", \"ICD10PCS\", \"ICD9Proc\", \"Nebraska Lexicon\", \"LOINC\", \"SNOMED\"]\n",
    "\n",
    "        # Add any vocabularies from exact_codes or pattern_codes that aren't already included\n",
    "        vocab_additions = set()\n",
    "        for vocab in list(exact_codes.keys() if exact_codes else []) + list(pattern_codes.keys() if pattern_codes else []):\n",
    "            if vocab not in vocabularies:\n",
    "                vocab_additions.add(vocab)\n",
    "                vocabularies.append(vocab)\n",
    "\n",
    "        # Notify if vocabularies were added\n",
    "        if vocab_additions:\n",
    "            print(f\"Added vocabularies from code specifications: {', '.join(vocab_additions)}\")\n",
    "\n",
    "        # Store query parameters for summary\n",
    "        self.last_query_params = {\n",
    "            \"type\": \"person_procedure\",\n",
    "            \"name\": name,\n",
    "            \"search_tables\": search_tables,\n",
    "            \"vocabularies\": vocabularies,\n",
    "            \"concept_classes\": concept_classes,\n",
    "            \"search_terms\": search_terms,\n",
    "            \"exclude_terms\": exclude_terms,\n",
    "            \"exact_codes\": exact_codes,\n",
    "            \"pattern_codes\": pattern_codes,\n",
    "            \"exclude_codes\": exclude_codes,\n",
    "            \"person_ids\": person_ids,\n",
    "            \"dates\": dates\n",
    "        }\n",
    "\n",
    "        # Generate query summary text\n",
    "        self.query_summary = self._generate_query_summary()\n",
    "\n",
    "        # Create Jinja2 environment and add filter\n",
    "        env = Environment()\n",
    "\n",
    "        # Define and add filter to environment\n",
    "        def join_quotes(items):\n",
    "            return ', '.join(f\"'{item}'\" for item in items)\n",
    "\n",
    "        env.filters['join_quotes'] = join_quotes\n",
    "\n",
    "        template = env.from_string(\"\"\"\n",
    "        WITH filtered_concepts AS (\n",
    "            SELECT DISTINCT concept_id, vocabulary_id, concept_class_id, concept_code, concept_name\n",
    "            FROM {{ version }}.concept\n",
    "            WHERE \n",
    "                vocabulary_id IN ({{ vocabularies|join_quotes }})\n",
    "                {%- if concept_classes %}\n",
    "                AND concept_class_id IN ({{ concept_classes|join_quotes}})\n",
    "                {%- endif %}\n",
    "                {%- if exclude_terms %}\n",
    "                AND (\n",
    "                    {%- for term in exclude_terms %}\n",
    "                    {{ \"AND \" if not loop.first else \"\" }}LOWER(concept_name) NOT LIKE '%{{ term|lower }}%'\n",
    "                    {%- endfor %}\n",
    "                )\n",
    "                {%- endif %}\n",
    "                {%- for vocab, codes in exclude_codes.items() %}\n",
    "                {%- if codes %}\n",
    "                AND NOT (\n",
    "                    vocabulary_id = '{{ vocab }}' AND concept_code IN ({{ codes|join_quotes }})\n",
    "                )\n",
    "                {%- endif %}\n",
    "                {%- endfor %}\n",
    "                {%- if search_terms or exact_codes or pattern_codes %}\n",
    "                AND (\n",
    "                    {%- if search_terms %}\n",
    "                    (\n",
    "                        {%- for term in search_terms %}\n",
    "                        {{ \"OR \" if not loop.first else \"\" }}LOWER(concept_name) LIKE '%{{ term|lower }}%'\n",
    "                        {%- endfor %}\n",
    "                    )\n",
    "                    {%- endif %}\n",
    "\n",
    "                    {%- if search_terms and (exact_codes or pattern_codes) %}OR{% endif %}\n",
    "\n",
    "                    {%- if exact_codes %}\n",
    "                    (\n",
    "                        {%- for vocab, codes in exact_codes.items() %}\n",
    "                        {%- if codes %}\n",
    "                        {{ \"OR \" if not loop.first else \"\" }}(vocabulary_id = '{{ vocab }}' AND concept_code IN ({{ codes|join_quotes }}))\n",
    "                        {%- endif %}\n",
    "                        {%- endfor %}\n",
    "                    )\n",
    "                    {%- endif %}\n",
    "\n",
    "                    {%- if (search_terms or exact_codes) and pattern_codes %}OR{% endif %}\n",
    "\n",
    "                    {%- if pattern_codes %}\n",
    "                    (\n",
    "                        {%- for vocab, patterns in pattern_codes.items() %}\n",
    "                        {%- if patterns %}\n",
    "                        {{ \"OR \" if not loop.first else \"\" }}(vocabulary_id = '{{ vocab }}' AND (\n",
    "                            {%- for pattern in patterns %}\n",
    "                            {{ \"OR \" if not loop.first else \"\" }}concept_code LIKE '{{ pattern }}'\n",
    "                            {%- endfor %}\n",
    "                        ))\n",
    "                        {%- endif %}\n",
    "                        {%- endfor %}\n",
    "                    )\n",
    "                    {%- endif %}\n",
    "                )\n",
    "                {%- endif %}\n",
    "        ),\n",
    "\n",
    "        -- Procedure events from procedure_occurrence\n",
    "        {% if 'procedure_occurrence' in search_tables %}\n",
    "        procedure_table_events AS (\n",
    "            -- Procedures via source_value\n",
    "            SELECT\n",
    "                po.person_id,\n",
    "                po.procedure_source_value AS concept_code,\n",
    "                fc.vocabulary_id,\n",
    "                fc.concept_class_id,\n",
    "                fc.concept_name,\n",
    "                'procedure_occurrence' AS source_table,\n",
    "                po.procedure_date AS event_date\n",
    "            FROM {{ version }}.procedure_occurrence po\n",
    "            JOIN filtered_concepts fc \n",
    "                ON po.procedure_source_value = fc.concept_code\n",
    "            {%- if person_ids %}\n",
    "            WHERE po.person_id IN ({{ person_ids }})\n",
    "            {%- endif %}\n",
    "\n",
    "            UNION ALL\n",
    "\n",
    "            -- Procedures via source_concept_id\n",
    "            SELECT\n",
    "                po.person_id,\n",
    "                fc.concept_code,\n",
    "                fc.vocabulary_id,\n",
    "                fc.concept_class_id,\n",
    "                fc.concept_name,\n",
    "                'procedure_occurrence' AS source_table,\n",
    "                po.procedure_date AS event_date\n",
    "            FROM {{ version }}.procedure_occurrence po\n",
    "            JOIN filtered_concepts fc \n",
    "                ON po.procedure_source_concept_id = fc.concept_id\n",
    "            {%- if person_ids %}\n",
    "            WHERE po.person_id IN ({{ person_ids }})\n",
    "            {%- endif %}\n",
    "        ),\n",
    "        {% endif %}\n",
    "\n",
    "        -- Procedure events from observation\n",
    "        {% if 'observation' in search_tables %}\n",
    "        observation_procedure_events AS (\n",
    "            -- Procedures from observation via source_value\n",
    "            SELECT\n",
    "                o.person_id,\n",
    "                o.observation_source_value AS concept_code,\n",
    "                fc.vocabulary_id,\n",
    "                fc.concept_class_id,\n",
    "                fc.concept_name,\n",
    "                'observation' AS source_table,\n",
    "                o.observation_date AS event_date\n",
    "            FROM {{ version }}.observation o\n",
    "            JOIN filtered_concepts fc \n",
    "                ON o.observation_source_value = fc.concept_code\n",
    "            {%- if person_ids %}\n",
    "            WHERE o.person_id IN ({{ person_ids }})\n",
    "            {%- endif %}\n",
    "\n",
    "            UNION ALL\n",
    "\n",
    "            -- Procedures from observation via source_concept_id\n",
    "            SELECT\n",
    "                o.person_id,\n",
    "                fc.concept_code,\n",
    "                fc.vocabulary_id,\n",
    "                fc.concept_class_id,\n",
    "                fc.concept_name,\n",
    "                'observation' AS source_table,\n",
    "                o.observation_date AS event_date\n",
    "            FROM {{ version }}.observation o\n",
    "            JOIN filtered_concepts fc \n",
    "                ON o.observation_source_concept_id = fc.concept_id\n",
    "            {%- if person_ids %}\n",
    "            WHERE o.person_id IN ({{ person_ids }})\n",
    "            {%- endif %}\n",
    "        ),\n",
    "        {% endif %}\n",
    "\n",
    "        -- Combine results from all searched tables\n",
    "        all_procedure_events AS (\n",
    "            {% if 'procedure_occurrence' in search_tables %}\n",
    "            SELECT * FROM procedure_table_events\n",
    "            {% endif %}\n",
    "            {% if 'observation' in search_tables %}\n",
    "            {% if 'procedure_occurrence' in search_tables %}UNION ALL{% endif %}\n",
    "            SELECT * FROM observation_procedure_events\n",
    "            {% endif %}\n",
    "        ),\n",
    "\n",
    "        -- Get distinct dates per person\n",
    "        distinct_dates AS (\n",
    "            SELECT \n",
    "                person_id,\n",
    "                vocabulary_id,\n",
    "                event_date\n",
    "            FROM all_procedure_events\n",
    "            GROUP BY person_id, vocabulary_id, event_date\n",
    "        ),\n",
    "\n",
    "        -- Calculate vocabulary summary per person\n",
    "        vocab_summary AS (\n",
    "            SELECT\n",
    "                person_id,\n",
    "                STRING_AGG(CASE \n",
    "                    WHEN vocabulary_id = 'CPT4' THEN 'CPT'\n",
    "                    WHEN vocabulary_id = 'HCPCS' THEN 'HC'\n",
    "                    WHEN vocabulary_id = 'ICD10PCS' THEN '10P'\n",
    "                    WHEN vocabulary_id = 'ICD9Proc' THEN '9P'\n",
    "                    WHEN vocabulary_id = 'LOINC' THEN 'LN'\n",
    "                    WHEN vocabulary_id = 'SNOMED' THEN 'SNO'\n",
    "                    ELSE SUBSTR(vocabulary_id, 1, 3)\n",
    "                END, ' ' ORDER BY vocabulary_id) AS vocab\n",
    "            FROM (\n",
    "                SELECT DISTINCT person_id, vocabulary_id\n",
    "                FROM all_procedure_events\n",
    "            )\n",
    "            GROUP BY person_id\n",
    "        ),\n",
    "\n",
    "        -- Count distinct dates per person\n",
    "        date_counts AS (\n",
    "            SELECT\n",
    "                person_id,\n",
    "                COUNT(DISTINCT event_date) AS {{ name }}_n\n",
    "            FROM all_procedure_events\n",
    "            GROUP BY person_id\n",
    "        ){% if dates %},\n",
    "\n",
    "        -- Get ordered dates per person\n",
    "        ordered_dates AS (\n",
    "            SELECT\n",
    "                person_id,\n",
    "                event_date,\n",
    "                ROW_NUMBER() OVER (PARTITION BY person_id ORDER BY event_date ASC) AS date_order,\n",
    "                ROW_NUMBER() OVER (PARTITION BY person_id ORDER BY event_date DESC) AS rev_date_order\n",
    "            FROM (\n",
    "                SELECT DISTINCT person_id, event_date\n",
    "                FROM all_procedure_events\n",
    "            )\n",
    "        ),\n",
    "\n",
    "        -- Get first, second, and last dates\n",
    "        key_dates AS (\n",
    "            SELECT\n",
    "                person_id,\n",
    "                MAX(CASE WHEN date_order = 1 THEN event_date END) AS {{ name }}_1,\n",
    "                MAX(CASE WHEN date_order = 2 THEN event_date END) AS {{ name }}_2,\n",
    "                MAX(CASE WHEN rev_date_order = 1 THEN event_date END) AS {{ name }}_last\n",
    "            FROM ordered_dates\n",
    "            GROUP BY person_id\n",
    "        ){% endif %}\n",
    "\n",
    "        -- Final person-level output\n",
    "        SELECT\n",
    "            dc.person_id,\n",
    "            dc.{{ name }}_n,\n",
    "            vs.vocab{% if dates %},\n",
    "            kd.{{ name }}_1,\n",
    "            kd.{{ name }}_2,\n",
    "            kd.{{ name }}_last{% endif %}\n",
    "        FROM date_counts dc\n",
    "        JOIN vocab_summary vs ON dc.person_id = vs.person_id\n",
    "        {% if dates %}JOIN key_dates kd ON dc.person_id = kd.person_id{% endif %}\n",
    "        ORDER BY dc.person_id\n",
    "        \"\"\")       \n",
    "\n",
    "        # Format person_ids if it's a list\n",
    "        if isinstance(person_ids, list):\n",
    "            person_ids = ', '.join(str(pid) for pid in person_ids)\n",
    "\n",
    "        # Initialize dictionaries\n",
    "        exact_codes = exact_codes or {}\n",
    "        pattern_codes = pattern_codes or {}\n",
    "        exclude_codes = exclude_codes or {}\n",
    "\n",
    "        # Render the template\n",
    "        self.query_text = template.render(\n",
    "            version=self.version,\n",
    "            name=name,\n",
    "            search_tables=search_tables,\n",
    "            vocabularies=vocabularies,\n",
    "            concept_classes=concept_classes,\n",
    "            search_terms=search_terms,\n",
    "            exclude_terms=exclude_terms,\n",
    "            exact_codes=exact_codes,\n",
    "            pattern_codes=pattern_codes,\n",
    "            exclude_codes=exclude_codes,\n",
    "            person_ids=person_ids,\n",
    "            dates=dates\n",
    "        )\n",
    "\n",
    "        return self\n",
    " \n",
    "    def count_participants_with_data(self,\n",
    "                                     include_icd_codes: bool = True,\n",
    "                                     include_snomed_codes: bool = True,\n",
    "                                     include_loinc: bool = True,\n",
    "                                     include_drugs: bool = True,\n",
    "                                     include_procedures: bool = False,\n",
    "                                     measurement_registration_exclusion: bool = True,\n",
    "                                     custom_conditions: Dict[str, str] = None):\n",
    "        \"\"\"\n",
    "        Count unique persons with data in specified domains.\n",
    "\n",
    "        Args:\n",
    "            include_icd_codes: Include ICD9/ICD10 codes from condition_occurrence and observation source fields\n",
    "            include_snomed_codes: Include SNOMED codes from condition_occurrence and observation source fields\n",
    "            include_loinc: Include LOINC codes from measurement\n",
    "            include_drugs: Include drug exposures with domain_id = \"Drug\"\n",
    "            include_procedures: Include procedures from procedure_occurrence and observation\n",
    "                           Uses default vocabularies: CPT4, HCPCS, ICD10PCS, ICD9Proc, LOINC, SNOMED\n",
    "            measurement_registration_exclusion: Exclude All of Us registration vitals from measurement count \n",
    "                (i.e. look for EHR measurements, not registration measurements)\n",
    "            custom_conditions: Dictionary of {table_name: WHERE clause} for custom filtering\n",
    "\n",
    "        Returns:\n",
    "            The query object, call execute_gbq() to run the query and get the count\n",
    "        \"\"\"\n",
    "        # Default vitals exclusions\n",
    "        default_vitals_exclusion = [3022318, 3027018, 3031203, 40759207, 40765148, 3036277, \n",
    "                                    3025315, 3012888, 3004249, 3038553, 3022281]\n",
    "        \n",
    "        # Set string for measurement exclusion\n",
    "        if measurement_registration_exclusion:\n",
    "            exclude_concept_ids_str = ', '.join(map(str, default_vitals_exclusion))\n",
    "            excluded_vitals = default_vitals_exclusion\n",
    "        else:\n",
    "            exclude_concept_ids_str = \"\"\n",
    "            excluded_vitals = []\n",
    "\n",
    "        custom_conditions = custom_conditions or {}\n",
    "\n",
    "        # Determine which vocabularies to include\n",
    "        condition_list = []\n",
    "        if include_icd_codes:\n",
    "            condition_list.extend(['ICD9CM', 'ICD10CM'])\n",
    "        if include_snomed_codes:\n",
    "            condition_list.append('SNOMED')\n",
    "\n",
    "        # Default procedure vocabularies\n",
    "        procedure_list = [\"CPT4\", \"HCPCS\", \"ICD10PCS\", \"ICD9Proc\", \"LOINC\", \"SNOMED\"] if include_procedures else []\n",
    "\n",
    "        # Store query parameters for summary\n",
    "        self.last_query_params = {\n",
    "            \"type\": \"person_count\",\n",
    "            \"include_icd_codes\": include_icd_codes,\n",
    "            \"include_snomed_codes\": include_snomed_codes,\n",
    "            \"include_loinc\": include_loinc,\n",
    "            \"include_drugs\": include_drugs,\n",
    "            \"include_procedures\": include_procedures,\n",
    "            \"procedure_vocabularies\": procedure_list,\n",
    "            \"excluded_vitals\": excluded_vitals\n",
    "        }\n",
    "\n",
    "        # Generate query summary text\n",
    "        self.query_summary = self._generate_query_summary()\n",
    "\n",
    "        # Create Jinja2 environment\n",
    "        env = Environment()\n",
    "\n",
    "        # Define and add filter to environment\n",
    "        def join_quotes(items):\n",
    "            return ', '.join(f\"'{item}'\" for item in items)\n",
    "\n",
    "        env.filters['join_quotes'] = join_quotes\n",
    "       \n",
    "        template = env.from_string(\"\"\"\n",
    "        WITH combined AS (\n",
    "            {% if condition_list %}\n",
    "            -- Codes from observation (source_value)\n",
    "            SELECT o.person_id\n",
    "            FROM {{ version }}.observation AS o\n",
    "            JOIN {{ version }}.concept AS c ON o.observation_source_value = c.concept_code\n",
    "            WHERE c.vocabulary_id IN ({{ condition_list|join_quotes }})\n",
    "\n",
    "            UNION ALL\n",
    "\n",
    "            -- Codes from observation (source_concept_id)\n",
    "            SELECT o.person_id\n",
    "            FROM {{ version }}.observation AS o\n",
    "            JOIN {{ version }}.concept AS c ON o.observation_source_concept_id = c.concept_id\n",
    "            WHERE c.vocabulary_id IN ({{ condition_list|join_quotes }})\n",
    "\n",
    "            UNION ALL\n",
    "\n",
    "            -- Codes from condition_occurrence (source_value)\n",
    "            SELECT co.person_id\n",
    "            FROM {{ version }}.condition_occurrence AS co\n",
    "            JOIN {{ version }}.concept AS c ON co.condition_source_value = c.concept_code\n",
    "            WHERE c.vocabulary_id IN ({{ condition_list|join_quotes }})\n",
    "\n",
    "            UNION ALL\n",
    "\n",
    "            -- Codes from condition_occurrence (source_concept_id)\n",
    "            SELECT co.person_id\n",
    "            FROM {{ version }}.condition_occurrence AS co\n",
    "            JOIN {{ version }}.concept AS c ON co.condition_source_concept_id = c.concept_id\n",
    "            WHERE c.vocabulary_id IN ({{ condition_list|join_quotes }})\n",
    "            {% endif %}\n",
    "\n",
    "            {% if include_loinc %}\n",
    "            {% if condition_list %}UNION ALL{% endif %}\n",
    "            -- LOINC codes from measurement\n",
    "            SELECT m.person_id\n",
    "            FROM {{ version }}.measurement AS m\n",
    "            JOIN {{ version }}.concept AS c ON m.measurement_concept_id = c.concept_id\n",
    "            WHERE c.vocabulary_id = 'LOINC'\n",
    "            {% if measurement_registration_exclusion %}\n",
    "                AND c.concept_id NOT IN ({{ exclude_concept_ids_str }})\n",
    "            {% endif %}\n",
    "            {% endif %}\n",
    "    \n",
    "            {% if include_drugs %}\n",
    "            {% if condition_list or include_loinc %}UNION ALL{% endif %}\n",
    "            -- Drug exposures\n",
    "            SELECT de.person_id\n",
    "            FROM {{ version }}.drug_exposure AS de\n",
    "            JOIN {{ version }}.concept AS c ON de.drug_concept_id = c.concept_id\n",
    "            WHERE c.domain_id = 'Drug'\n",
    "            {% endif %}\n",
    "            \n",
    "            {% if include_procedures %}\n",
    "            {% if condition_list or include_loinc or include_drugs %}UNION ALL{% endif %}\n",
    "            -- Procedures from procedure_occurrence (source_value)\n",
    "            SELECT po.person_id\n",
    "            FROM {{ version }}.procedure_occurrence AS po\n",
    "            JOIN {{ version }}.concept AS c ON po.procedure_source_value = c.concept_code\n",
    "            WHERE c.vocabulary_id IN ({{ procedure_list|join_quotes }})\n",
    "\n",
    "            UNION ALL\n",
    "\n",
    "            -- Procedures from procedure_occurrence (source_concept_id)\n",
    "            SELECT po.person_id\n",
    "            FROM {{ version }}.procedure_occurrence AS po\n",
    "            JOIN {{ version }}.concept AS c ON po.procedure_source_concept_id = c.concept_id\n",
    "            WHERE c.vocabulary_id IN ({{ procedure_list|join_quotes }})\n",
    "\n",
    "            UNION ALL\n",
    "\n",
    "            -- Procedures from observation (source_value)\n",
    "            SELECT o.person_id\n",
    "            FROM {{ version }}.observation AS o\n",
    "            JOIN {{ version }}.concept AS c ON o.observation_source_value = c.concept_code\n",
    "            WHERE c.vocabulary_id IN ({{ procedure_list|join_quotes }})\n",
    "\n",
    "            UNION ALL\n",
    "\n",
    "            -- Procedures from observation (source_concept_id)\n",
    "            SELECT o.person_id\n",
    "            FROM {{ version }}.observation AS o\n",
    "            JOIN {{ version }}.concept AS c ON o.observation_source_concept_id = c.concept_id\n",
    "            WHERE c.vocabulary_id IN ({{ procedure_list|join_quotes }})\n",
    "            {% endif %}\n",
    "\n",
    "        )\n",
    "\n",
    "        SELECT COUNT(DISTINCT person_id) AS person_count\n",
    "        FROM combined\n",
    "        \"\"\")\n",
    "\n",
    "        # Render the template\n",
    "        self.query_text = template.render(\n",
    "            version=self.version,\n",
    "            condition_list=condition_list,\n",
    "            procedure_list=procedure_list,\n",
    "            include_icd_codes=include_icd_codes,\n",
    "            include_snomed_codes=include_snomed_codes,\n",
    "            include_loinc=include_loinc,\n",
    "            include_drugs=include_drugs,\n",
    "            include_procedures=include_procedures,\n",
    "            measurement_registration_exclusion=measurement_registration_exclusion,\n",
    "            exclude_concept_ids_str=exclude_concept_ids_str,\n",
    "            custom_conditions=custom_conditions\n",
    "        )\n",
    "        \n",
    "        return self\n",
    "\n",
    "    def print_query(self):\n",
    "        \"\"\"Print the current query for inspection\"\"\"\n",
    "        if not self.query_text:\n",
    "            print(\"No query built yet\")\n",
    "            return self\n",
    "            \n",
    "        print(self.query_text)\n",
    "        return self\n",
    "\n",
    "    def query_to_variable(self, var_name):\n",
    "        \"\"\"Set a variable to the current query text\"\"\"\n",
    "        if not self.query_text:\n",
    "            raise ValueError(\"No query has been built yet\")\n",
    "        \n",
    "        globals()[var_name] = self.query_text\n",
    "        print(f\"Query saved to variable '{var_name}'\")\n",
    "        return self\n",
    "\n",
    "    def _generate_query_summary(self):\n",
    "        \"\"\"Generate a human-readable summary of the last query parameters\"\"\"\n",
    "        if not hasattr(self, 'last_query_params'):\n",
    "            return \"No query parameters available\"\n",
    "\n",
    "        params = self.last_query_params\n",
    "        query_type = params.get(\"type\", \"unknown\")\n",
    "\n",
    "        if query_type == \"diagnosis_codes\":\n",
    "            summary = []\n",
    "\n",
    "            # Describe data sources\n",
    "            summary.append(f\"Query Type: Diagnosis Codes\")\n",
    "\n",
    "            # Describe vocabularies\n",
    "            vocabs = params.get(\"vocabularies\")\n",
    "            if vocabs:\n",
    "                summary.append(f\"Vocabularies: {', '.join(vocabs)}\")\n",
    "\n",
    "            # Describe tables\n",
    "            summary.append(\"Tables: condition_occurrence, observation\")\n",
    "            summary.append(\"Fields: Using both source_value and source_concept_id paths\")\n",
    "\n",
    "            # Describe search criteria\n",
    "            search_terms = params.get(\"search_terms\")\n",
    "            if search_terms:\n",
    "                terms_with_quotes = [f'\"{term}\"' for term in search_terms]\n",
    "                terms_joined = ', '.join(terms_with_quotes)\n",
    "                summary.append(f\"Search Terms: {terms_joined}\")\n",
    "\n",
    "            exclude_terms = params.get(\"exclude_terms\")\n",
    "            if exclude_terms:\n",
    "                terms_with_quotes = [f'\"{term}\"' for term in exclude_terms]\n",
    "                terms_joined = ', '.join(terms_with_quotes)\n",
    "                summary.append(f\"Exclude Terms: {terms_joined}\")\n",
    "\n",
    "            # Describe code criteria\n",
    "            exact_codes = params.get(\"exact_codes\")\n",
    "            if exact_codes:\n",
    "                code_lists = []\n",
    "                for vocab, codes in exact_codes.items():\n",
    "                    if codes:\n",
    "                        sorted_codes = sorted(codes)  \n",
    "                        code_lists.append(f\"\\n  {vocab}: {', '.join(sorted_codes)}\")\n",
    "                if code_lists:\n",
    "                    summary.append(f\"Exact Codes: {' '.join(code_lists)}\")\n",
    "\n",
    "            pattern_codes = params.get(\"pattern_codes\")\n",
    "            if pattern_codes:\n",
    "                pattern_lists = []\n",
    "                for vocab, patterns in pattern_codes.items():\n",
    "                    if patterns:\n",
    "                        sorted_patterns = sorted(patterns)\n",
    "                        pattern_lists.append(f\"\\n  {vocab}: {', '.join(sorted_patterns)}\")\n",
    "                if pattern_lists:\n",
    "                    summary.append(f\"Pattern Codes: {' '.join(pattern_lists)}\")\n",
    "\n",
    "            exclude_codes = params.get(\"exclude_codes\")\n",
    "            if exclude_codes:\n",
    "                exclude_lists = []\n",
    "                for vocab, codes in exclude_codes.items():\n",
    "                    if codes:\n",
    "                        sorted_codes = sorted(codes) \n",
    "                        exclude_lists.append(f\"\\n  {vocab}: {', '.join(sorted_codes)}\")\n",
    "                if exclude_lists:\n",
    "                    summary.append(f\"Exclude Codes: {' '.join(exclude_lists)}\")\n",
    "\n",
    "            # Describe person filtering\n",
    "            person_ids = params.get(\"person_ids\")\n",
    "            if person_ids:\n",
    "                if isinstance(person_ids, list):\n",
    "                    summary.append(f\"Filtered to {len(person_ids)} specific person IDs\")\n",
    "                else:\n",
    "                    summary.append(f\"Filtered to specific person IDs\")\n",
    "\n",
    "            # V code handling\n",
    "            summary.append(\"Special handling for V codes to ensure correct vocabulary attribution\")\n",
    "\n",
    "            return \"\\n\".join(summary)\n",
    "        \n",
    "        elif query_type == \"person_diagnosis\":\n",
    "\n",
    "            summary = []\n",
    "\n",
    "            # Describe data sources\n",
    "            summary.append(f\"Query Type: Person-Level Diagnosis Data\")\n",
    "            summary.append(f\"Column Name Prefix: {params.get('name', 'unknown')}\")\n",
    "\n",
    "            # Describe vocabularies\n",
    "            vocabs = params.get(\"vocabularies\")\n",
    "            if vocabs:\n",
    "                summary.append(f\"Vocabularies: {', '.join(vocabs)}\")\n",
    "\n",
    "            # Describe tables\n",
    "            summary.append(\"Tables: condition_occurrence, observation\")\n",
    "            summary.append(\"Fields: Using both source_value and source_concept_id paths\")\n",
    "\n",
    "            # Describe search criteria\n",
    "            search_terms = params.get(\"search_terms\")\n",
    "            if search_terms:\n",
    "                terms_with_quotes = [f'\"{term}\"' for term in search_terms]\n",
    "                terms_joined = ', '.join(terms_with_quotes)\n",
    "                summary.append(f\"Search Terms: {terms_joined}\")\n",
    "\n",
    "            exclude_terms = params.get(\"exclude_terms\")\n",
    "            if exclude_terms:\n",
    "                terms_with_quotes = [f'\"{term}\"' for term in exclude_terms]\n",
    "                terms_joined = ', '.join(terms_with_quotes)\n",
    "                summary.append(f\"Exclude Terms: {terms_joined}\")\n",
    "\n",
    "            # Describe code criteria\n",
    "            exact_codes = params.get(\"exact_codes\")\n",
    "            if exact_codes:\n",
    "                code_lists = []\n",
    "                for vocab, codes in exact_codes.items():\n",
    "                    if codes:\n",
    "                        sorted_codes = sorted(codes)  \n",
    "                        code_lists.append(f\"\\n  {vocab}: {', '.join(sorted_codes)}\")\n",
    "                if code_lists:\n",
    "                    summary.append(f\"Exact Codes: {' '.join(code_lists)}\")\n",
    "\n",
    "            pattern_codes = params.get(\"pattern_codes\")\n",
    "            if pattern_codes:\n",
    "                pattern_lists = []\n",
    "                for vocab, patterns in pattern_codes.items():\n",
    "                    if patterns:\n",
    "                        sorted_patterns = sorted(patterns)\n",
    "                        pattern_lists.append(f\"\\n  {vocab}: {', '.join(sorted_patterns)}\")\n",
    "                if pattern_lists:\n",
    "                    summary.append(f\"Pattern Codes: {' '.join(pattern_lists)}\")\n",
    "\n",
    "            exclude_codes = params.get(\"exclude_codes\")\n",
    "            if exclude_codes:\n",
    "                exclude_lists = []\n",
    "                for vocab, codes in exclude_codes.items():\n",
    "                    if codes:\n",
    "                        sorted_codes = sorted(codes) \n",
    "                        exclude_lists.append(f\"\\n  {vocab}: {', '.join(sorted_codes)}\")\n",
    "                if exclude_lists:\n",
    "                    summary.append(f\"Exclude Codes: {' '.join(exclude_lists)}\")\n",
    "\n",
    "            # Describe person filtering\n",
    "            person_ids = params.get(\"person_ids\")\n",
    "            if person_ids:\n",
    "                if isinstance(person_ids, list):\n",
    "                    summary.append(f\"Filtered to {len(person_ids)} specific person IDs\")\n",
    "                else:\n",
    "                    summary.append(f\"Filtered to specific person IDs\")\n",
    "\n",
    "            # Date columns\n",
    "            dates = params.get(\"dates\")\n",
    "            if dates:\n",
    "                summary.append(f\"Including date columns: first, second, and last occurrences\")\n",
    "\n",
    "            # V code handling\n",
    "            summary.append(\"Special handling for V codes to ensure correct vocabulary attribution\")\n",
    "\n",
    "            return \"\\n\".join(summary)\n",
    "\n",
    "        elif query_type == \"procedure_codes\":\n",
    "            summary = []\n",
    "\n",
    "            # Describe data sources\n",
    "            summary.append(f\"Query Type: Procedure Codes\")\n",
    "\n",
    "            # Describe search tables\n",
    "            search_tables = params.get(\"search_tables\")\n",
    "            if search_tables:\n",
    "                summary.append(f\"Tables: {', '.join(search_tables)}\")\n",
    "\n",
    "            summary.append(\"Fields: Using both source_value and source_concept_id paths\")\n",
    "\n",
    "            # Describe vocabularies\n",
    "            vocabs = params.get(\"vocabularies\")\n",
    "            if vocabs:\n",
    "                summary.append(f\"Vocabularies: {', '.join(vocabs)}\")\n",
    "\n",
    "            # Describe concept classes\n",
    "            concept_classes = params.get(\"concept_classes\")\n",
    "            if concept_classes:\n",
    "                summary.append(f\"Concept Classes: {', '.join(concept_classes)}\")\n",
    "\n",
    "            # Describe search criteria\n",
    "            search_terms = params.get(\"search_terms\")\n",
    "            if search_terms:\n",
    "                terms_with_quotes = [f'\"{term}\"' for term in search_terms]\n",
    "                terms_joined = ', '.join(terms_with_quotes)\n",
    "                summary.append(f\"Search Terms: {terms_joined}\")\n",
    "\n",
    "            exclude_terms = params.get(\"exclude_terms\")\n",
    "            if exclude_terms:\n",
    "                terms_with_quotes = [f'\"{term}\"' for term in exclude_terms]\n",
    "                terms_joined = ', '.join(terms_with_quotes)\n",
    "                summary.append(f\"Exclude Terms: {terms_joined}\")\n",
    "\n",
    "            # Describe code criteria\n",
    "            exact_codes = params.get(\"exact_codes\")\n",
    "            if exact_codes:\n",
    "                code_lists = []\n",
    "                for vocab, codes in exact_codes.items():\n",
    "                    if codes:\n",
    "                        sorted_codes = sorted(codes)  \n",
    "                        code_lists.append(f\"\\n  {vocab}: {', '.join(sorted_codes)}\")\n",
    "                if code_lists:\n",
    "                    summary.append(f\"Exact Codes: {' '.join(code_lists)}\")\n",
    "\n",
    "            pattern_codes = params.get(\"pattern_codes\")\n",
    "            if pattern_codes:\n",
    "                pattern_lists = []\n",
    "                for vocab, patterns in pattern_codes.items():\n",
    "                    if patterns:\n",
    "                        sorted_patterns = sorted(patterns)\n",
    "                        pattern_lists.append(f\"\\n  {vocab}: {', '.join(sorted_patterns)}\")\n",
    "                if pattern_lists:\n",
    "                    summary.append(f\"Pattern Codes: {' '.join(pattern_lists)}\")\n",
    "\n",
    "            exclude_codes = params.get(\"exclude_codes\")\n",
    "            if exclude_codes:\n",
    "                exclude_lists = []\n",
    "                for vocab, codes in exclude_codes.items():\n",
    "                    if codes:\n",
    "                        sorted_codes = sorted(codes) \n",
    "                        exclude_lists.append(f\"\\n  {vocab}: {', '.join(sorted_codes)}\")\n",
    "                if exclude_lists:\n",
    "                    summary.append(f\"Exclude Codes: {' '.join(exclude_lists)}\")\n",
    "\n",
    "            # Describe person filtering\n",
    "            person_ids = params.get(\"person_ids\")\n",
    "            if person_ids:\n",
    "                if isinstance(person_ids, list):\n",
    "                    summary.append(f\"Filtered to {len(person_ids)} specific person IDs\")\n",
    "                else:\n",
    "                    summary.append(f\"Filtered to specific person IDs\")\n",
    "\n",
    "            return \"\\n\".join(summary)\n",
    "\n",
    "        elif query_type == \"person_procedure\":\n",
    "            summary = []\n",
    "\n",
    "            # Describe data sources\n",
    "            summary.append(f\"Query Type: Person-Level Procedure Data\")\n",
    "            summary.append(f\"Column Name Prefix: {params.get('name', 'unknown')}\")\n",
    "\n",
    "            # Describe search tables\n",
    "            search_tables = params.get(\"search_tables\")\n",
    "            if search_tables:\n",
    "                summary.append(f\"Tables: {', '.join(search_tables)}\")\n",
    "\n",
    "            summary.append(\"Fields: Using both source_value and source_concept_id paths\")\n",
    "\n",
    "            # Describe vocabularies\n",
    "            vocabs = params.get(\"vocabularies\")\n",
    "            if vocabs:\n",
    "                summary.append(f\"Vocabularies: {', '.join(vocabs)}\")\n",
    "\n",
    "            # Describe concept classes\n",
    "            concept_classes = params.get(\"concept_classes\")\n",
    "            if concept_classes:\n",
    "                summary.append(f\"Concept Classes: {', '.join(concept_classes)}\")\n",
    "\n",
    "            # Describe search criteria\n",
    "            search_terms = params.get(\"search_terms\")\n",
    "            if search_terms:\n",
    "                terms_with_quotes = [f'\"{term}\"' for term in search_terms]\n",
    "                terms_joined = ', '.join(terms_with_quotes)\n",
    "                summary.append(f\"Search Terms: {terms_joined}\")\n",
    "\n",
    "            exclude_terms = params.get(\"exclude_terms\")\n",
    "            if exclude_terms:\n",
    "                terms_with_quotes = [f'\"{term}\"' for term in exclude_terms]\n",
    "                terms_joined = ', '.join(terms_with_quotes)\n",
    "                summary.append(f\"Exclude Terms: {terms_joined}\")\n",
    "\n",
    "            # Describe code criteria\n",
    "            exact_codes = params.get(\"exact_codes\")\n",
    "            if exact_codes:\n",
    "                code_lists = []\n",
    "                for vocab, codes in exact_codes.items():\n",
    "                    if codes:\n",
    "                        sorted_codes = sorted(codes)  \n",
    "                        code_lists.append(f\"\\n  {vocab}: {', '.join(sorted_codes)}\")\n",
    "                if code_lists:\n",
    "                    summary.append(f\"Exact Codes: {' '.join(code_lists)}\")\n",
    "\n",
    "            pattern_codes = params.get(\"pattern_codes\")\n",
    "            if pattern_codes:\n",
    "                pattern_lists = []\n",
    "                for vocab, patterns in pattern_codes.items():\n",
    "                    if patterns:\n",
    "                        sorted_patterns = sorted(patterns)\n",
    "                        pattern_lists.append(f\"\\n  {vocab}: {', '.join(sorted_patterns)}\")\n",
    "                if pattern_lists:\n",
    "                    summary.append(f\"Pattern Codes: {' '.join(pattern_lists)}\")\n",
    "\n",
    "            exclude_codes = params.get(\"exclude_codes\")\n",
    "            if exclude_codes:\n",
    "                exclude_lists = []\n",
    "                for vocab, codes in exclude_codes.items():\n",
    "                    if codes:\n",
    "                        sorted_codes = sorted(codes) \n",
    "                        exclude_lists.append(f\"\\n  {vocab}: {', '.join(sorted_codes)}\")\n",
    "                if exclude_lists:\n",
    "                    summary.append(f\"Exclude Codes: {' '.join(exclude_lists)}\")\n",
    "\n",
    "            # Describe person filtering\n",
    "            person_ids = params.get(\"person_ids\")\n",
    "            if person_ids:\n",
    "                if isinstance(person_ids, list):\n",
    "                    summary.append(f\"Filtered to {len(person_ids)} specific person IDs\")\n",
    "                else:\n",
    "                    summary.append(f\"Filtered to specific person IDs\")\n",
    "\n",
    "            # Date columns\n",
    "            dates = params.get(\"dates\")\n",
    "            if dates:\n",
    "                summary.append(f\"Including date columns: first, second, and last occurrences\")\n",
    "\n",
    "            return \"\\n\".join(summary)\n",
    "\n",
    "        elif query_type == \"person_count\":\n",
    "            \n",
    "            summary = []\n",
    "\n",
    "            # Describe query type\n",
    "            summary.append(\"Query Type: Participant Count\")\n",
    "\n",
    "            # Describe included data types\n",
    "            data_types = []\n",
    "            if params.get(\"include_icd_codes\"):\n",
    "                data_types.append(\"ICD codes (ICD9CM, ICD10CM)\")\n",
    "            if params.get(\"include_snomed_codes\"):\n",
    "                data_types.append(\"SNOMED codes\")\n",
    "            if params.get(\"include_loinc\"):\n",
    "                data_types.append(\"LOINC measurements\")\n",
    "            if params.get(\"include_drugs\"):\n",
    "                data_types.append(\"Drug exposures\")\n",
    "            if params.get(\"include_procedures\"):\n",
    "                procedure_vocabs = params.get(\"procedure_vocabularies\", [])\n",
    "                if procedure_vocabs:\n",
    "                    summary.append(f\"Procedure codes ({', '.join(procedure_vocabs)})\")\n",
    "                else:\n",
    "                    data_types.append(\"Procedure codes\")\n",
    "\n",
    "            if data_types:\n",
    "                summary.append(f\"Included Data: {', '.join(data_types)}\")\n",
    "\n",
    "            # Describe procedure tables if procedures included\n",
    "            if params.get(\"include_procedures\"):\n",
    "                summary.append(\"Procedure Tables: procedure_occurrence, observation\")\n",
    "\n",
    "            # Describe excluded concepts\n",
    "            excluded_vitals = params.get(\"excluded_vitals\", [])\n",
    "\n",
    "            if params.get(\"include_loinc\") and excluded_vitals:\n",
    "                summary.append(f\"{len(excluded_vitals)} common vitals concept IDs (from All of Us registration) excluded from measurement\")\n",
    "\n",
    "            return \"\\n\".join(summary)\n",
    "            \n",
    "        else:\n",
    "            return \"Unknown query type\"\n",
    "\n",
    "    def print_summary(self):\n",
    "        \"\"\"Print a summary of the last query\"\"\"\n",
    "        if hasattr(self, 'query_summary'):\n",
    "            print(self.query_summary)\n",
    "        else:\n",
    "            print(\"No query summary available\")\n",
    "        return self\n",
    "\n",
    "    def execute_gbq(self, quiet=False):\n",
    "        \"\"\"Execute the query and return a Polars DataFrame\"\"\"\n",
    "        if not self.query_text:\n",
    "            raise ValueError(\"No query has been built yet\")\n",
    "                \n",
    "        if not quiet and hasattr(self, 'query_summary'):\n",
    "            print(self.query_summary)\n",
    "\n",
    "        # Execute query\n",
    "        query_job = self.client.query(self.query_text)\n",
    "\n",
    "        # Get results and convert to polars\n",
    "        rows = query_job.result()\n",
    "        df = pl.from_arrow(rows.to_arrow())\n",
    "\n",
    "        return df\n",
    "\n",
    "    def results_to_code_dict(self, df):\n",
    "        \"\"\"\n",
    "        Convert a diagnosis codes dataframe to an exact_codes dictionary for use in find_diagnosis_codes.\n",
    "\n",
    "        Args:\n",
    "            df: Polars DataFrame with vocabulary_id and concept_code columns\n",
    "\n",
    "        Returns:\n",
    "            Dict mapping vocabularies to lists of concept codes\n",
    "        \"\"\"\n",
    "        if not {'vocabulary_id', 'concept_code'}.issubset(df.columns):\n",
    "            raise ValueError(\"DataFrame must contain 'vocabulary_id' and 'concept_code' columns\")\n",
    "\n",
    "        result = {}\n",
    "\n",
    "        # Group by vocabulary_id and collect concept_codes\n",
    "        for vocab in df['vocabulary_id'].unique():\n",
    "            codes = df.filter(pl.col('vocabulary_id') == vocab)['concept_code'].to_list()\n",
    "            result[vocab] = codes\n",
    "\n",
    "        return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def polars_gbq(query):\n",
    "    \"\"\"\n",
    "    Execute a BigQuery SQL query and return results as a polars dataframe\n",
    "    :param query: BigQuery SQL query\n",
    "    :return: polars.DataFrame\n",
    "    \"\"\"\n",
    "    client = bigquery.Client()\n",
    "    query_job = client.query(query)\n",
    "    rows = query_job.result()\n",
    "    df = pl.from_arrow(rows.to_arrow())\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_icd_dict_from_phecodes(phecodex_map, phecodes):\n",
    "    # Convert single phecode to list if needed\n",
    "    if isinstance(phecodes, str):\n",
    "        phecodes = [phecodes]\n",
    "    \n",
    "    # Filter the DataFrame to only include rows with phecodes in the list\n",
    "    filtered_df = phecodex_map.filter(pl.col(\"phecode\").is_in(phecodes))\n",
    "    \n",
    "    # Group by vocabulary_id and aggregate unique ICD codes into lists\n",
    "    result = (filtered_df\n",
    "              .group_by(\"vocabulary_id\")\n",
    "              .agg(pl.col(\"ICD\").unique().alias(\"icd_codes\"))\n",
    "              .to_dict(as_series=False))\n",
    "    \n",
    "    # Convert to the desired dictionary format\n",
    "    icd_dict = {vocab: codes for vocab, codes in zip(result[\"vocabulary_id\"], result[\"icd_codes\"])}\n",
    "    \n",
    "    return icd_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phecodex_map = pl.read_csv('phecodeX_unrolled_ICD_CM.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AouQueries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize\n",
    "aou = AouQueries()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "version = 'fc-aou-cdr-prod-ct.C2024Q3R5'\n",
    "bucket = '{bucket or my_bucket}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Environment Variables\n",
    "# bucket = os.getenv(\"WORKSPACE_BUCKET\")\n",
    "dataset = os.getenv('WORKSPACE_CDR')\n",
    "\n",
    "# Global Variables\n",
    "cohort = \"allofus\"\n",
    "version = dataset.split('.')[1]\n",
    "file_type = \"parquet\" # csv also possible\n",
    "file_path = f\"{bucket}/data/{cohort}/{version}\""
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "prostate_dict = create_icd_dict_from_phecodes(phecodex_map, [\"CA_107.2\"])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Find sarcoid diagnoses\n",
    "prostate_codes_df = (aou.find_diagnosis_codes(\n",
    "    vocabularies=[\"ICD9CM\", \"ICD10CM\", \"SNOMED\"],\n",
    "    exact_codes=prostate_dict, \n",
    "    exclude_terms=[\"family\"]\n",
    ").execute_gbq())"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "prostate_codes_df"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "prostate_df = (aou.person_code_df(\n",
    "    name=\"sarcoid\",\n",
    "    vocabularies=[\"ICD9CM\", \"ICD10CM\", \"SNOMED\"],\n",
    "    exact_codes=prostate_dict, \n",
    "    exclude_terms=[\"family\"],\n",
    "    dates=True\n",
    ").execute_gbq())"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "prostate_df = prostate_df.join(\n",
    "    demographics_df.select('person_id', 'dob'),\n",
    "    on='person_id',\n",
    "    how='left'\n",
    ")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "prostate_df = prostate_df.with_columns(\n",
    "    ((pl.col(\"sarcoid_1\") - pl.col(\"dob\")).dt.total_days() / 365.25).floor().alias(\"age_at_sarcoid_dx\")\n",
    ")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "sns.histplot(prostate_df.filter(pl.col('sarcoid_n')>1)['age_at_sarcoid_dx'])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "prostate_df.filter((pl.col('sarcoid_n')>1) & (pl.col('age_at_sarcoid_dx')<50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here, end_of_study_age is age at death, or age at end of study period ()\n",
    "demographics_q = f\"\"\"\n",
    "{distinct_participants_cte}\n",
    "SELECT DISTINCT\n",
    "    p.person_id,\n",
    "    CAST(p.birth_datetime AS DATE) AS dob,\n",
    "    p_race_concept.concept_name as race,\n",
    "    p_ethnicity_concept.concept_name as ethnicity,\n",
    "    p_sex_at_birth_concept.concept_name as sex_at_birth,\n",
    "    p_gender_concept.concept_name as gender,\n",
    "    DATETIME_DIFF(\n",
    "                IF(DATETIME(death_datetime) IS NULL, DATETIME('2023-10-01'), DATETIME(death_datetime)), \n",
    "                DATETIME(birth_datetime), \n",
    "                DAY\n",
    "            )/365.2425 AS end_of_study_age\n",
    "FROM\n",
    "    {dataset}.person p\n",
    "LEFT JOIN\n",
    "    {dataset}.concept p_gender_concept \n",
    "        ON p.gender_concept_id = p_gender_concept.concept_id \n",
    "LEFT JOIN\n",
    "    {dataset}.concept p_race_concept \n",
    "        ON p.race_concept_id = p_race_concept.concept_id \n",
    "LEFT JOIN\n",
    "    {dataset}.concept p_ethnicity_concept \n",
    "        ON p.ethnicity_concept_id = p_ethnicity_concept.concept_id \n",
    "LEFT JOIN\n",
    "    {dataset}.concept p_sex_at_birth_concept \n",
    "        ON p.sex_at_birth_concept_id = p_sex_at_birth_concept.concept_id  \n",
    "LEFT JOIN\n",
    "    {dataset}.death d\n",
    "        ON p.person_id = d.person_id\n",
    "WHERE\n",
    "    p.person_id IN (SELECT person_id FROM distinct_participants)\n",
    "\"\"\"\n",
    "\n",
    "demographics_df = polars_gbq(demographics_q)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Identify Sarcoid Codes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find sarcoid diagnoses\n",
    "sarcoid_codes_df = (aou.find_diagnosis_codes(\n",
    "    vocabularies=[\"ICD9CM\", \"ICD10CM\", \"SNOMED\"],\n",
    "    search_terms=[\"sarcoid\"], \n",
    "    exclude_terms=[\"history\"]\n",
    ").print_query())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find sarcoid diagnoses\n",
    "sarcoid_codes_df = (aou.find_diagnosis_codes(\n",
    "    vocabularies=[\"ICD9CM\", \"ICD10CM\", \"SNOMED\"],\n",
    "    search_terms=[\"sarcoid\"], \n",
    "    exclude_terms=[\"family\"]\n",
    ").execute_gbq())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sarcoid_codes_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sarcoid_df = (aou.person_code_df(\n",
    "    name=\"sarcoid\",\n",
    "    vocabularies=[\"ICD9CM\", \"ICD10CM\", \"SNOMED\"],\n",
    "    search_terms=[\"sarcoid\"], \n",
    "    exclude_terms=[\"family\"],\n",
    "    dates=True\n",
    ").execute_gbq())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Participants with 1 code: {sarcoid_df.filter(pl.col('sarcoid_n')==1).height}\")\n",
    "print(f\"Participants with  2 codes: {sarcoid_df.filter(pl.col('sarcoid_n')>1).height}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(aou.count_participants_with_data(\n",
    "    include_icd_codes=True,\n",
    "    include_snomed_codes=True,\n",
    "    include_loinc=False,\n",
    "    include_drugs=False,\n",
    ").execute_gbq())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(aou.count_participants_with_data(\n",
    "    include_icd_codes=False,\n",
    "    include_snomed_codes=False,\n",
    "    include_loinc=False,\n",
    "    include_drugs=False,\n",
    "    include_procedures=True\n",
    ").execute_gbq())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sarcoid_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Identify Exclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TB\n",
    "This excludes nonspecific reaction to TB skin test codes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find TB diagnoses by string\n",
    "tb_codes_string_df = (aou.find_diagnosis_codes(\n",
    "    vocabularies=[\"ICD9CM\", \"ICD10CM\", \"SNOMED\"],\n",
    "    search_terms=[\"tuberculous\", \"tuberculosis\", \"tuberculoma\"],\n",
    "    exclude_terms=['encounter for screening', 'screening status', 'testing', 'contact', \n",
    "                   'without mention of effusion or current tuberculosis', 'other than tuberculosis',\n",
    "                   'exposure to', 'bcg', 'vaccine', 'pleural effusion, except tuberculous',\n",
    "                   'nonspecific reaction to'\n",
    "                  ]\n",
    ").execute_gbq())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tb_dict = create_icd_dict_from_phecodes(phecodex_map, [\"ID_005.1\", \"RE_460.3\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find sarcoid diagnoses by phecodes\n",
    "tb_codes_phecode_df = (aou.find_diagnosis_codes(\n",
    "    exact_codes=tb_dict\n",
    ").execute_gbq())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a combined dataframe with source labels\n",
    "phecode_df = tb_codes_phecode_df.unique(subset=[\"vocabulary_id\", \"concept_code\"]).with_columns(pl.lit(\"phecode\").alias(\"source\"))\n",
    "string_df = tb_codes_string_df.unique(subset=[\"vocabulary_id\", \"concept_code\"]).with_columns(pl.lit(\"string\").alias(\"source\"))\n",
    "\n",
    "# Find rows in phecode_df not in string_df\n",
    "unique_to_phecode = phecode_df.join(\n",
    "    string_df.select([\"vocabulary_id\", \"concept_code\"]),\n",
    "    on=[\"vocabulary_id\", \"concept_code\"],\n",
    "    how=\"anti\"\n",
    ")\n",
    "\n",
    "# Find rows in string_df not in phecode_df\n",
    "unique_to_string = string_df.join(\n",
    "    phecode_df.select([\"vocabulary_id\", \"concept_code\"]),\n",
    "    on=[\"vocabulary_id\", \"concept_code\"],\n",
    "    how=\"anti\"\n",
    ")\n",
    "\n",
    "# Concatenate the unique rows\n",
    "unique_rows_df = pl.concat([unique_to_phecode, unique_to_string])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_rows_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tb_code_df = (aou.person_code_df(\n",
    "    name=\"tb\",\n",
    "    vocabularies=[\"ICD9CM\", \"ICD10CM\", \"SNOMED\"],\n",
    "    search_terms=[\"tuberculous\", \"tuberculosis\", \"tuberculoma\"],\n",
    "    exclude_terms=['encounter for screening', 'screening status', 'testing', 'contact', \n",
    "                   'without mention of effusion or current tuberculosis', 'other than tuberculosis',\n",
    "                   'exposure to', 'bcg', 'vaccine', 'pleural effusion, except tuberculous',\n",
    "                   'nonspecific reaction to'\n",
    "                  ],\n",
    "    dates=True\n",
    ").execute_gbq())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Abnormal TB Skin Test\n",
    "\"ICD10CM\"\t\"R76.11\"\t\"Nonspecific reaction to tuberculin skin test without active tuberculosis\"\t3900\t36006<br>\n",
    "\"ICD10CM\"\t\"R76.12\"\t\"Nonspecific reaction to cell mediated immunity measurement of gamma interferon antigen response with\t1215\t10858<br>\n",
    "\"ICD9CM\"\t\"795.5\"\t\"Nonspecific reaction to tuberculin skin test without active tuberculosis\"\t2753\t20920<br>\n",
    "\"ICD9CM\"\t\"795.51\"\t\"Nonspecific reaction to tuberculin skin test without active tuberculosis\"\t2817\t25598<br>\n",
    "\"ICD9CM\"\t\"795.52\"\t\"Nonspecific reaction to cell mediated immunity measurement of gamma interferon antigen response with\t426\t4204<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tb_skin_dict = {\n",
    "    \"ICD10CM\": [\"R76.1%\"],\n",
    "    \"ICD9CM\": [\"795.5%\"],\n",
    "}\n",
    "\n",
    "# Find TB skin test diagnoses\n",
    "tb_skin_codes_df = (aou.find_diagnosis_codes(\n",
    "    vocabularies=[\"ICD9CM\", \"ICD10CM\", \"SNOMED\"],\n",
    "    pattern_codes=tb_skin_dict\n",
    ").execute_gbq())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tb_skin_codes_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tb_skin_code_df = (aou.person_code_df(\n",
    "    name=\"tb_skin\",\n",
    "    vocabularies=[\"ICD9CM\", \"ICD10CM\", \"SNOMED\"],\n",
    "    pattern_codes=tb_skin_dict,\n",
    "    dates=True\n",
    ").execute_gbq())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other Mycobacterial Infections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ntm_dict = {\n",
    "    \"ICD10CM\": [\"A30%\", \"A31%\"],\n",
    "    \"ICD9CM\": [\"V74.2\", \"030%\", \"031%\"],\n",
    "}\n",
    "\n",
    "# Find NTM diagnoses by string\n",
    "ntm_codes_icd_df = (aou.find_diagnosis_codes(\n",
    "    vocabularies=[\"ICD9CM\", \"ICD10CM\", \"SNOMED\"],\n",
    "    pattern_codes=ntm_dict,\n",
    ").execute_gbq())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ntm_codes_icd_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find NTM diagnoses by string\n",
    "ntm_codes_string_df = (aou.find_diagnosis_codes(\n",
    "    vocabularies=[\"ICD9CM\", \"ICD10CM\", \"SNOMED\"],\n",
    "    search_terms=[\"nontuberculous\", \"non-tuberculous\", \"avium-intracellulare\", \"abscessus\", \"chelonae\", \n",
    "                  \"fortuitum\", \"gordonae\", \"malmoense\", \"marinum\", \"ulcerans\", \"xenopi\", \"kansasii\",\n",
    "                 \"nonchromogenicum\", \"avium complex\", \"genavense\", \"haemophilum\", \"leprosy\", \"mycobacteria\"],\n",
    ").execute_gbq())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ntm_code_df = (aou.person_code_df(\n",
    "    name=\"ntm\",\n",
    "    vocabularies=[\"ICD9CM\", \"ICD10CM\", \"SNOMED\"],\n",
    "    search_terms=[\"nontuberculous\", \"non-tuberculous\", \"avium-intracellulare\", \"abscessus\", \"chelonae\", \n",
    "                  \"fortuitum\", \"gordonae\", \"malmoense\", \"marinum\", \"ulcerans\", \"xenopi\", \"kansasii\",\n",
    "                 \"nonchromogenicum\", \"avium complex\", \"genavense\", \"haemophilum\", \"leprosy\", \"mycobacteria\"],\n",
    "    dates=True\n",
    ").execute_gbq())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Histo, Blasto, Cocci"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dimorphic_dict = create_icd_dict_from_phecodes(phecodex_map, [\"ID_071\", \"ID_072\", \"ID_073\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find sarcoid diagnoses by phecodes\n",
    "dimorphic_codes_phecode_df = (aou.find_diagnosis_codes(\n",
    "    exact_codes=dimorphic_dict\n",
    ").execute_gbq())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dimorphic_dict = {\n",
    "    \"ICD9CM\": [\"114%\", \"115%\", \"116%\"],\n",
    "    \"ICD10CM\": [\"B38%\", \"B39%\", \"B40\"],\n",
    "}\n",
    "\n",
    "# Find dimorphics diagnoses by code\n",
    "dimorphic_codes_icd_df = (aou.find_diagnosis_codes(\n",
    "    vocabularies=[\"ICD9CM\", \"ICD10CM\", \"SNOMED\"],\n",
    "    pattern_codes=dimorphic_dict,\n",
    ").execute_gbq())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find dimorphic diagnoses by string\n",
    "dimorphic_codes_string_df = (aou.find_diagnosis_codes(\n",
    "    vocabularies=[\"ICD9CM\", \"ICD10CM\", \"SNOMED\"],\n",
    "    search_terms=[\"histoplas\", \"blastomy\", \"coccidio\"]\n",
    ").execute_gbq())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a combined dataframe with source labels\n",
    "phecode_df = dimorphic_codes_phecode_df.unique(subset=[\"vocabulary_id\", \"concept_code\"]).with_columns(pl.lit(\"phecode\").alias(\"source\"))\n",
    "icd_df = dimorphic_codes_icd_df.unique(subset=[\"vocabulary_id\", \"concept_code\"]).with_columns(pl.lit(\"phecode\").alias(\"source\"))\n",
    "string_df = dimorphic_codes_string_df.unique(subset=[\"vocabulary_id\", \"concept_code\"]).with_columns(pl.lit(\"string\").alias(\"source\"))\n",
    "\n",
    "# Find rows in phecode_df not in string_df\n",
    "unique_to_phecode = phecode_df.join(\n",
    "    string_df.select([\"vocabulary_id\", \"concept_code\"]),\n",
    "    on=[\"vocabulary_id\", \"concept_code\"],\n",
    "    how=\"anti\"\n",
    ")\n",
    "\n",
    "# Find rows in phecode_df not in string_df\n",
    "unique_to_icd = icd_df.join(\n",
    "    string_df.select([\"vocabulary_id\", \"concept_code\"]),\n",
    "    on=[\"vocabulary_id\", \"concept_code\"],\n",
    "    how=\"anti\"\n",
    ")\n",
    "\n",
    "unique_rows_df = pl.concat([unique_to_phecode, unique_to_icd])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_rows_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dimorphic_codes_string_df.slice(50,50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "histo_code_df = (aou.person_code_df(\n",
    "    name=\"histo\",\n",
    "    vocabularies=[\"ICD9CM\", \"ICD10CM\", \"SNOMED\"],\n",
    "    search_terms=[\"histoplas\"],\n",
    "    dates=True\n",
    ").execute_gbq())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blasto_code_df = (aou.person_code_df(\n",
    "    name=\"blasto\",\n",
    "    vocabularies=[\"ICD9CM\", \"ICD10CM\", \"SNOMED\"],\n",
    "    search_terms=[\"blastomy\"],\n",
    "    dates=True\n",
    ").execute_gbq())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cocci_code_df = (aou.person_code_df(\n",
    "    name=\"cocci\",\n",
    "    vocabularies=[\"ICD9CM\", \"ICD10CM\", \"SNOMED\"],\n",
    "    search_terms=[\"coccidio\"],\n",
    "    dates=True\n",
    ").execute_gbq())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aspergillus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "asp_dict = create_icd_dict_from_phecodes(phecodex_map, [\"ID_074\"]) #RE_475.7 is redundant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "asp_codes_phecode_df = (aou.find_diagnosis_codes(\n",
    "    exact_codes=asp_dict\n",
    ").execute_gbq())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aspergillus_dict = {\n",
    "    \"ICD10CM\": [\"B44%\"],\n",
    "    \"ICD9CM\": [\"117.3%\"],\n",
    "}\n",
    "# All included in above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "asp_codes_phecode_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find Aspergillus diagnoses by string\n",
    "aspergillus_codes_string_df = (aou.find_diagnosis_codes(\n",
    "    vocabularies=[\"ICD9CM\", \"ICD10CM\", \"SNOMED\"],\n",
    "    search_terms=[\"aspergill\"],\n",
    ").execute_gbq())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aspergillus_codes_string_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aspergillus_code_df = (aou.person_code_df(\n",
    "    name=\"asp\",\n",
    "    vocabularies=[\"ICD9CM\", \"ICD10CM\", \"SNOMED\"],\n",
    "    search_terms=[\"aspergill\"],\n",
    "    dates=True\n",
    ").execute_gbq())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ILD (incl. Eosinophilia Pneumoina)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ild_dict = create_icd_dict_from_phecodes(phecodex_map, [\"RE_481\"]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ild_codes_phecode_df = (aou.find_diagnosis_codes(\n",
    "    exact_codes=ild_dict\n",
    ").execute_gbq())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ild_codes_string_df = (aou.find_diagnosis_codes(\n",
    "    vocabularies=[\"ICD9CM\", \"ICD10CM\", \"SNOMED\"],\n",
    "    search_terms=[\"interstitial pneumonia\", \"eosinophilic pneumonia\", \"eosinophilic asthma\",\n",
    "                 \"pulmonary eosinophilia\", \"alveolar proteinosis\", \"alveolar microlithiasis\",\n",
    "                 \"pulmonary hemosiderosis\", \"alveolar and parieto-alveolar\", \"interstitial pulmonary\",\n",
    "                 \"interstitial lung\", \"pulmonary fibrosis\", \"interstitial pneumonitis\", \n",
    "                 \"organizing pneumonia\", \"lymphangioleiomyomatosis\", \"parietoalveolar pneumono\", \n",
    "                  \"neuroendocrine cell hyperplasia of infancy\", \"pulmonary interstitial\", \n",
    "                  \"alveolar and parieto-alveolar\"\n",
    "                 ],\n",
    ").execute_gbq())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a combined dataframe with source labels\n",
    "phecode_df = ild_codes_phecode_df.unique(subset=[\"vocabulary_id\", \"concept_code\"]).with_columns(pl.lit(\"phecode\").alias(\"source\"))\n",
    "string_df = ild_codes_string_df.unique(subset=[\"vocabulary_id\", \"concept_code\"]).with_columns(pl.lit(\"string\").alias(\"source\"))\n",
    "\n",
    "# Find rows in phecode_df not in string_df\n",
    "unique_to_phecode = phecode_df.join(\n",
    "    string_df.select([\"vocabulary_id\", \"concept_code\"]),\n",
    "    on=[\"vocabulary_id\", \"concept_code\"],\n",
    "    how=\"anti\"\n",
    ")\n",
    "\n",
    "# Find rows in string_df not in phecode_df\n",
    "unique_to_string = string_df.join(\n",
    "    phecode_df.select([\"vocabulary_id\", \"concept_code\"]),\n",
    "    on=[\"vocabulary_id\", \"concept_code\"],\n",
    "    how=\"anti\"\n",
    ")\n",
    "\n",
    "# Concatenate the unique rows\n",
    "unique_rows_df = pl.concat([unique_to_phecode, unique_to_string])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if unique_to_phecode.height == 0:\n",
    "    print('No codes unique to phecode')\n",
    "else:\n",
    "    unique_to_phecode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ild_code_df = (aou.person_code_df(\n",
    "    name=\"ild\",\n",
    "    vocabularies=[\"ICD9CM\", \"ICD10CM\", \"SNOMED\"],\n",
    "    search_terms=[\"interstitial pneumonia\", \"eosinophilic pneumonia\", \"eosinophilic asthma\",\n",
    "                 \"pulmonary eosinophilia\", \"alveolar proteinosis\", \"alveolar microlithiasis\",\n",
    "                 \"pulmonary hemosiderosis\", \"alveolar and parieto-alveolar\", \"interstitial pulmonary\",\n",
    "                 \"interstitial lung\", \"pulmonary fibrosis\", \"interstitial pneumonitis\", \n",
    "                 \"organizing pneumonia\", \"lymphangioleiomyomatosis\", \"parietoalveolar pneumono\", \n",
    "                  \"neuroendocrine cell hyperplasia of infancy\", \"pulmonary interstitial\", \n",
    "                  \"alveolar and parieto-alveolar\"\n",
    "                 ],\n",
    "    dates=True\n",
    ").execute_gbq())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hypersensitivity Pneumonitis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hp_dict = create_icd_dict_from_phecodes(phecodex_map, [\"RE_477.2\"]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hp_codes_phecode_df = (aou.find_diagnosis_codes(\n",
    "    exact_codes=hp_dict\n",
    ").execute_gbq())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hp_codes_phecode_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hp_codes_string_df = (aou.find_diagnosis_codes(\n",
    "    vocabularies=[\"ICD9CM\", \"ICD10CM\", \"SNOMED\"],\n",
    "    search_terms=[\"s lung\", \"Farmers\", \"bagassosis\", \"Bird fancier\", \"Bird-fanciers\", \n",
    "                 \"Hypersensitivity pneumonitis\", \"Pneumonitis due to inhalation of oils\", \n",
    "                 \"Pneumonitis due to inhalation of other solids\", \"Suberosis\", \"Mushroom workers\", \n",
    "                 \"Maple bark-strippers\", \"Ventilation pneumonitis\", \"Other specified allergic alveolitis\"\n",
    "                 \"Pneumonitis due to other solids\", \"Pneumonitis due to solids\", \"Pneumonitis due to other solids and liquids\", \n",
    "                  \"Extrinsic allergic alveolitis\", \"\\\"Ventilation\\\" pneumonitis\"],\n",
    "    exact_codes={'ICD9CM': ['495.8', '495.9']},\n",
    ").execute_gbq())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a combined dataframe with source labels\n",
    "phecode_df = hp_codes_phecode_df.unique(subset=[\"vocabulary_id\", \"concept_code\"]).with_columns(pl.lit(\"phecode\").alias(\"source\"))\n",
    "string_df = hp_codes_string_df.unique(subset=[\"vocabulary_id\", \"concept_code\"]).with_columns(pl.lit(\"string\").alias(\"source\"))\n",
    "\n",
    "# Find rows in phecode_df not in string_df\n",
    "unique_to_phecode = phecode_df.join(\n",
    "    string_df.select([\"vocabulary_id\", \"concept_code\"]),\n",
    "    on=[\"vocabulary_id\", \"concept_code\"],\n",
    "    how=\"anti\"\n",
    ")\n",
    "\n",
    "# Find rows in string_df not in phecode_df\n",
    "unique_to_string = string_df.join(\n",
    "    phecode_df.select([\"vocabulary_id\", \"concept_code\"]),\n",
    "    on=[\"vocabulary_id\", \"concept_code\"],\n",
    "    how=\"anti\"\n",
    ")\n",
    "\n",
    "# Concatenate the unique rows\n",
    "unique_rows_df = pl.concat([unique_to_phecode, unique_to_string])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if unique_to_phecode.height == 0:\n",
    "    print('No codes unique to phecode')\n",
    "else:\n",
    "    display(unique_to_phecode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hp_code_df = (aou.person_code_df(\n",
    "    name=\"hp\",\n",
    "    vocabularies=[\"ICD9CM\", \"ICD10CM\", \"SNOMED\"],\n",
    "    search_terms=[\"s lung\", \"Farmers\", \"bagassosis\", \"Bird fancier\", \"Bird-fanciers\", \n",
    "                 \"Hypersensitivity pneumonitis\", \"Pneumonitis due to inhalation of oils\", \n",
    "                 \"Pneumonitis due to inhalation of other solids\", \"Suberosis\", \"Mushroom workers\", \n",
    "                 \"Maple bark-strippers\", \"Ventilation pneumonitis\", \"Other specified allergic alveolitis\"\n",
    "                 \"Pneumonitis due to other solids\", \"Pneumonitis due to solids\", \"Pneumonitis due to other solids and liquids\", \n",
    "                  \"Extrinsic allergic alveolitis\", \"\\\"Ventilation\\\" pneumonitis\"],\n",
    "    exact_codes={'ICD9CM': ['495.8', '495.9']},\n",
    "    dates=True\n",
    ").execute_gbq())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pneumoconiosis (beryllium, titanium, aluminum, zirconium, cobalt, others)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pneumoconiosis_dict = create_icd_dict_from_phecodes(phecodex_map, [\"RE_477.1\"]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pneumoconiosis_codes_phecode_df = (aou.find_diagnosis_codes(\n",
    "    exact_codes=pneumoconiosis_dict\n",
    ").execute_gbq())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Find diagnoses by string\n",
    "pneumoconiosis_codes_string_df = (aou.find_diagnosis_codes(\n",
    "    vocabularies=[\"ICD9CM\", \"ICD10CM\", \"SNOMED\"],\n",
    "    search_terms=[\"pneumoconiosis\", \"Asbestosis\", \"Stannosis\", \"Siderosis\", \"Graphite fibrosis\",\n",
    "                 \"Bauxite fibrosis\"],\n",
    ").execute_gbq())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a combined dataframe with source labels\n",
    "phecode_df = pneumoconiosis_codes_phecode_df.unique(subset=[\"vocabulary_id\", \"concept_code\"]).with_columns(pl.lit(\"phecode\").alias(\"source\"))\n",
    "string_df = pneumoconiosis_codes_string_df.unique(subset=[\"vocabulary_id\", \"concept_code\"]).with_columns(pl.lit(\"string\").alias(\"source\"))\n",
    "\n",
    "# Find rows in phecode_df not in string_df\n",
    "unique_to_phecode = phecode_df.join(\n",
    "    string_df.select([\"vocabulary_id\", \"concept_code\"]),\n",
    "    on=[\"vocabulary_id\", \"concept_code\"],\n",
    "    how=\"anti\"\n",
    ")\n",
    "\n",
    "# Find rows in string_df not in phecode_df\n",
    "unique_to_string = string_df.join(\n",
    "    phecode_df.select([\"vocabulary_id\", \"concept_code\"]),\n",
    "    on=[\"vocabulary_id\", \"concept_code\"],\n",
    "    how=\"anti\"\n",
    ")\n",
    "\n",
    "# Concatenate the unique rows\n",
    "unique_rows_df = pl.concat([unique_to_phecode, unique_to_string])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if unique_to_phecode.height == 0:\n",
    "    print('No codes unique to phecode')\n",
    "else:\n",
    "    display(unique_to_phecode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pneumoconiosis_codes_string_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pneumoconiosis_code_df = (aou.person_code_df(\n",
    "    name=\"pneumoconiosis\",\n",
    "    vocabularies=[\"ICD9CM\", \"ICD10CM\", \"SNOMED\"],\n",
    "    search_terms=[\"pneumoconiosis\", \"Asbestosis\", \"Stannosis\", \"Siderosis\", \"Graphite fibrosis\",\n",
    "                 \"Bauxite fibrosis\"],\n",
    "    dates=True\n",
    ").execute_gbq())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drugs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "drug_exclusion_code_q = f\"\"\"\n",
    "WITH filtered_concepts AS (\n",
    "    SELECT DISTINCT concept_id, concept_code, concept_name\n",
    "    FROM {dataset}.concept c\n",
    "    WHERE vocabulary_id = 'RxNorm'\n",
    "    AND (\n",
    "    LOWER(concept_name) LIKE '%ipilimumab%'\n",
    "    OR LOWER(concept_name) LIKE '%nivolumab%'\n",
    "    OR LOWER(concept_name) LIKE '%pembrolizumab%'\n",
    "    OR LOWER(concept_name) LIKE '%interferon-alpha%'\n",
    "    OR LOWER(concept_name) LIKE '%interferon-beta%'\n",
    "    OR LOWER(concept_name) LIKE '%etanercept%'\n",
    "    OR LOWER(concept_name) LIKE '%adalimumab%'\n",
    "    OR LOWER(concept_name) LIKE '%infliximab%'\n",
    "    OR LOWER(concept_name) LIKE '%vemurafenib%'\n",
    "    OR LOWER(concept_name) LIKE '%dabrafenib%'\n",
    "    OR LOWER(concept_name) LIKE '%trametinib%'\n",
    "    OR LOWER(concept_name) LIKE '%encorafenib%'\n",
    "    )\n",
    "),\n",
    "combined AS (\n",
    "    SELECT person_id, drug_exposure_start_date AS drug_date, \n",
    "        (SELECT concept_name FROM filtered_concepts WHERE concept_id = drug_concept_id) AS drug_name,\n",
    "        (SELECT concept_code FROM filtered_concepts WHERE concept_id = drug_concept_id) AS drug_code,\n",
    "    FROM {dataset}.drug_exposure\n",
    "    WHERE drug_concept_id IN (SELECT concept_id FROM filtered_concepts)\n",
    "),\n",
    "distinct_dates AS (\n",
    "    SELECT DISTINCT person_id, drug_date, drug_code, drug_name\n",
    "    FROM combined\n",
    ")\n",
    "SELECT drug_code, drug_name, COUNT(*) AS count\n",
    "FROM distinct_dates\n",
    "GROUP BY drug_code, drug_name\n",
    "ORDER BY count DESC\n",
    "\"\"\"\n",
    "\n",
    "exclusion_drug_code_df = polars_gbq(drug_exclusion_code_q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drug_exclusion_q = f\"\"\"\n",
    "WITH filtered_concepts AS (\n",
    "    SELECT DISTINCT concept_id, concept_code, concept_name\n",
    "    FROM {dataset}.concept c\n",
    "    WHERE vocabulary_id = 'RxNorm'\n",
    "    AND (\n",
    "    LOWER(concept_name) LIKE '%ipilimumab%'\n",
    "    OR LOWER(concept_name) LIKE '%nivolumab%'\n",
    "    OR LOWER(concept_name) LIKE '%pembrolizumab%'\n",
    "    OR LOWER(concept_name) LIKE '%interferon-alpha%'\n",
    "    OR LOWER(concept_name) LIKE '%interferon-beta%'\n",
    "    OR LOWER(concept_name) LIKE '%etanercept%'\n",
    "    OR LOWER(concept_name) LIKE '%adalimumab%'\n",
    "    OR LOWER(concept_name) LIKE '%infliximab%'\n",
    "    OR LOWER(concept_name) LIKE '%vemurafenib%'\n",
    "    OR LOWER(concept_name) LIKE '%dabrafenib%'\n",
    "    OR LOWER(concept_name) LIKE '%trametinib%'\n",
    "    OR LOWER(concept_name) LIKE '%encorafenib%'\n",
    "    )\n",
    "),\n",
    "combined AS (\n",
    "    SELECT de.person_id, drug_exposure_start_date AS drug_date\n",
    "    FROM {dataset}.drug_exposure de\n",
    "    WHERE drug_concept_id IN (SELECT concept_id FROM filtered_concepts)\n",
    "),\n",
    "distinct_dates AS (\n",
    "    SELECT DISTINCT person_id, drug_date\n",
    "    FROM combined\n",
    ")\n",
    "SELECT \n",
    "    person_id,\n",
    "    MIN(drug_date) AS exclusion_drug\n",
    "FROM distinct_dates\n",
    "GROUP BY person_id\n",
    "\"\"\"\n",
    "\n",
    "exclusion_drug_df = polars_gbq(drug_exclusion_q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exclusion_drug_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ANCA-Associated Vasculitis (GPA, MPA, EGPA) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vasculitis_phecode_dict = create_icd_dict_from_phecodes(phecodex_map, [\"MS_704\"]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vasculitis_codes_phecode_df = (aou.find_diagnosis_codes(\n",
    "    exact_codes=vasculitis_phecode_dict\n",
    ").execute_gbq())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vasculitis_codes_phecode_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vasculitis_dict = {\n",
    "    \"ICD10CM\": [\"I77.6\", \"I77.82\", \"M30.1\", \"M31.3\", \"M31.30\", \"M31.31\", \"M31.7\", \"M31.8\", \"M31.9\"],\n",
    "    \"ICD9CM\": [\"446.21\", \"446.4\", \"446.0\"],\n",
    "}\n",
    "\n",
    "# Find diagnoses by string\n",
    "vasculitis_codes_icd_df = (aou.find_diagnosis_codes(\n",
    "    vocabularies=[\"ICD9CM\", \"ICD10CM\", \"SNOMED\"],\n",
    "    exact_codes=vasculitis_dict,\n",
    "    search_terms=[\"Arteritis, unspecified\", \"unspecified arteritis\", 'ANCA', \n",
    "                  \"Antineutrophilic cytoplasmic\", \"Churg-Strauss\", \"Polyarteritis\", \n",
    "                  \"Wegener\", \"granulomatosis\", \"Microscopic polyangiitis\", \"Necrotizing vasculopathy\",\n",
    "                  \"Goodpasture\"],\n",
    "    exclude_terms=['blanca']\n",
    ").execute_gbq())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a combined dataframe with source labels\n",
    "phecode_df = vasculitis_codes_phecode_df.unique(subset=[\"vocabulary_id\", \"concept_code\"]).with_columns(pl.lit(\"phecode\").alias(\"source\"))\n",
    "string_df = vasculitis_codes_icd_df.unique(subset=[\"vocabulary_id\", \"concept_code\"]).with_columns(pl.lit(\"string\").alias(\"source\"))\n",
    "\n",
    "# Find rows in phecode_df not in string_df\n",
    "unique_to_phecode = phecode_df.join(\n",
    "    string_df.select([\"vocabulary_id\", \"concept_code\"]),\n",
    "    on=[\"vocabulary_id\", \"concept_code\"],\n",
    "    how=\"anti\"\n",
    ")\n",
    "\n",
    "# Find rows in string_df not in phecode_df\n",
    "unique_to_string = string_df.join(\n",
    "    phecode_df.select([\"vocabulary_id\", \"concept_code\"]),\n",
    "    on=[\"vocabulary_id\", \"concept_code\"],\n",
    "    how=\"anti\"\n",
    ")\n",
    "\n",
    "# Concatenate the unique rows\n",
    "unique_rows_df = pl.concat([unique_to_phecode, unique_to_string])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if unique_to_phecode.height == 0:\n",
    "    print('No codes unique to phecode')\n",
    "else:\n",
    "    display(unique_to_phecode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vasculitis_code_df = (aou.person_code_df(\n",
    "    name=\"vasc\",\n",
    "    vocabularies=[\"ICD9CM\", \"ICD10CM\", \"SNOMED\"],\n",
    "    exact_codes=vasculitis_dict,\n",
    "    search_terms=[\"Arteritis, unspecified\", \"unspecified arteritis\", 'ANCA', \n",
    "                  \"Antineutrophilic cytoplasmic\", \"Churg-Strauss\", \"Polyarteritis\", \n",
    "                  \"Wegener\", \"granulomatosis\", \"Microscopic polyangiitis\", \"Necrotizing vasculopathy\",\n",
    "                  \"Goodpasture\"],\n",
    "    exclude_terms=['blanca'],\n",
    "    dates=True\n",
    ").execute_gbq())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cgd_dict = {\n",
    "    \"ICD10CM\": [\"D71%\"],\n",
    "}\n",
    "\n",
    "# Find CGD diagnoses dict\n",
    "cgd_codes_icd_df = (aou.find_diagnosis_codes(\n",
    "    vocabularies=[\"ICD9CM\", \"ICD10CM\", \"SNOMED\"],\n",
    "    pattern_codes=cgd_dict,\n",
    ").execute_gbq())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cgd_codes_icd_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find CGD diagnoses by string\n",
    "cgd_codes_string_df = (aou.find_diagnosis_codes(\n",
    "    vocabularies=[\"ICD9CM\", \"ICD10CM\", \"SNOMED\"],\n",
    "    search_terms=[\"cgd\", \"chronic granulomatous\", \"functional disorders of polymorphonuclear neutrophils\"],\n",
    ").execute_gbq())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cgd_code_df = (aou.person_code_df(\n",
    "    name=\"cgd\",\n",
    "    vocabularies=[\"ICD9CM\", \"ICD10CM\", \"SNOMED\"],\n",
    "    search_terms=[\"cgd\", \"chronic granulomatous\", \"functional disorders of polymorphonuclear neutrophils\"],\n",
    "    dates=True\n",
    ").execute_gbq())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CVID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvid_dict = create_icd_dict_from_phecodes(phecodex_map, [\"BI_179.7\"]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvid_codes_phecode_df = (aou.find_diagnosis_codes(\n",
    "    exact_codes=cvid_dict\n",
    ").execute_gbq())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find cvid diagnoses by phecode\n",
    "cvid_codes_icd_df = (aou.find_diagnosis_codes(\n",
    "    vocabularies=[\"ICD9CM\", \"ICD10CM\", \"SNOMED\"],\n",
    "    exact_codes=cvid_dict,\n",
    ").execute_gbq())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvid_codes_icd_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find cvid diagnoses by string\n",
    "cvid_codes_string_df = (aou.find_diagnosis_codes(\n",
    "    vocabularies=[\"ICD9CM\", \"ICD10CM\", \"SNOMED\"],\n",
    "    search_terms=[\"common variable immunodefici\"],\n",
    ").execute_gbq())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvid_codes_string_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvid_code_df = (aou.person_code_df(\n",
    "    name=\"cvid\",\n",
    "    vocabularies=[\"ICD9CM\", \"ICD10CM\", \"SNOMED\"],\n",
    "    search_terms=[\"common variable immunodefici\"],\n",
    "    dates=True\n",
    ").execute_gbq())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IgG4-Related Disease"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "igg4_dict = {\n",
    "    \"ICD10CM\": [\"D89.84\"],\n",
    "}\n",
    "\n",
    "# Find igg4 diagnoses by string\n",
    "igg4_codes_icd_df = (aou.find_diagnosis_codes(\n",
    "    vocabularies=[\"ICD9CM\", \"ICD10CM\", \"SNOMED\"],\n",
    "    exact_codes=igg4_dict,\n",
    "    search_terms=[\"igg4\"],\n",
    ").execute_gbq())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "igg4_codes_icd_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "igg4_code_df = (aou.person_code_df(\n",
    "    name=\"igg4\",\n",
    "    vocabularies=[\"ICD9CM\", \"ICD10CM\", \"SNOMED\"],\n",
    "    search_terms=[\"igg4\"],\n",
    "    dates=True\n",
    ").execute_gbq())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "igg4_code_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lymphoma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lymphoma_dict = create_icd_dict_from_phecodes(phecodex_map, [\"CA_122\"]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lymphoma_codes_phecode_df = (aou.find_diagnosis_codes(\n",
    "    exact_codes=lymphoma_dict\n",
    ").execute_gbq())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lymphoma_codes_phecode_df.filter(~pl.col('concept_name').str.contains('lymphoma')).slice(100,50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find lymphoma diagnoses by string\n",
    "lymphoma_codes_string_df = (aou.find_diagnosis_codes(\n",
    "    vocabularies=[\"ICD9CM\", \"ICD10CM\", \"SNOMED\"],\n",
    "    search_terms=[\"lymphoma\", \"mycosis fungoides\", \"sezary\", \"t-cell proliferation\", \n",
    "                 \"waldenstrom macroglobulinemia\", \"reticulosarcoma\", \"lymphosarcoma\",\n",
    "                 'hodgkin', \"malignant neoplasms of lymphoid and histiocytic tissue\", \n",
    "                  \"malignant histiocytosis\", \"leukemic reticuloendotheliosis\", \"letterer-siwe disease\",\n",
    "                 \"malignant mast cell tumors\", ],\n",
    ").execute_gbq())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a combined dataframe with source labels\n",
    "phecode_df = lymphoma_codes_phecode_df.unique(subset=[\"vocabulary_id\", \"concept_code\"]).with_columns(pl.lit(\"phecode\").alias(\"source\"))\n",
    "string_df = lymphoma_codes_string_df.unique(subset=[\"vocabulary_id\", \"concept_code\"]).with_columns(pl.lit(\"string\").alias(\"source\"))\n",
    "\n",
    "# Find rows in phecode_df not in string_df\n",
    "unique_to_phecode = phecode_df.join(\n",
    "    string_df.select([\"vocabulary_id\", \"concept_code\"]),\n",
    "    on=[\"vocabulary_id\", \"concept_code\"],\n",
    "    how=\"anti\"\n",
    ")\n",
    "\n",
    "# Find rows in string_df not in phecode_df\n",
    "unique_to_string = string_df.join(\n",
    "    phecode_df.select([\"vocabulary_id\", \"concept_code\"]),\n",
    "    on=[\"vocabulary_id\", \"concept_code\"],\n",
    "    how=\"anti\"\n",
    ")\n",
    "\n",
    "# Concatenate the unique rows\n",
    "unique_rows_df = pl.concat([unique_to_phecode, unique_to_string])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if unique_to_phecode.height == 0:\n",
    "    print('No codes unique to phecode')\n",
    "else:\n",
    "    unique_to_phecode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if unique_to_string.height == 0:\n",
    "    print('No codes unique to phecode')\n",
    "else:\n",
    "    display(unique_to_string.slice(150,50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lymphoma_code_df = (aou.person_code_df(\n",
    "    name=\"lymphoma\",\n",
    "    vocabularies=[\"ICD9CM\", \"ICD10CM\", \"SNOMED\"],\n",
    "    search_terms=[\"lymphoma\", \"mycosis fungoides\", \"sezary\", \"t-cell proliferation\", \n",
    "                 \"waldenstrom macroglobulinemia\", \"reticulosarcoma\", \"lymphosarcoma\",\n",
    "                 'hodgkin', \"malignant neoplasms of lymphoid and histiocytic tissue\", \n",
    "                  \"malignant histiocytosis\", \"leukemic reticuloendotheliosis\", \"letterer-siwe disease\",\n",
    "                 \"malignant mast cell tumors\", ],\n",
    "    exclude_terms=[\"family history\"],\n",
    "    dates=True\n",
    ").execute_gbq())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lymphomatoid granulomatosis\n",
    "C83 already included above (lymphoma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find NTM diagnoses by string\n",
    "lg_codes_string_df = (aou.find_diagnosis_codes(\n",
    "    vocabularies=[\"ICD9CM\", \"ICD10CM\", \"SNOMED\"],\n",
    "    search_terms=[\"lymphomatoid granulomatosis\"],\n",
    ").execute_gbq())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lg_code_df = (aou.person_code_df(\n",
    "    name=\"lg\",\n",
    "    vocabularies=[\"ICD9CM\", \"ICD10CM\", \"SNOMED\"],\n",
    "    search_terms=[\"lymphomatoid granulomatosis\"],\n",
    "    dates=True\n",
    ").execute_gbq())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lung Cancer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lung_ca_dict = create_icd_dict_from_phecodes(phecodex_map, [\"CA_102.1\"]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lung_ca_codes_phecode_df = (aou.find_diagnosis_codes(\n",
    "    exact_codes=lung_ca_dict\n",
    ").execute_gbq())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lung_ca_codes_phecode_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find lung_ca diagnoses by string\n",
    "lung_ca_codes_string_df = (aou.find_diagnosis_codes(\n",
    "    vocabularies=[\"ICD9CM\", \"ICD10CM\", \"SNOMED\"],\n",
    "    search_terms=[\"malignant neoplasm of bronchus\", \"carcinoma in situ of bronchus\", \n",
    "                  \"malignant neoplasm of other parts of bronchus\", \"malignant neoplasm of lower lobe\",\n",
    "                  \"malignant neoplasm of middle lobe\", \"malignant neoplasm of upper lobe\", \n",
    "                  \"malignant neoplasm of main bronchus\", \"malignant neoplasm of trachea, bronchus\", \n",
    "                  \"carcinoma in situ of left bronchus\", \"carcinoma in situ of right bronchus\", \n",
    "                  \"carcinoma in situ of unspecified bronchus\", \"malignant neoplasm of unspecified part of left bronchus\",\n",
    "                 \"malignant neoplasm of unspecified part of right bronchus\", \n",
    "                  \"malignant neoplasm of unspecified part of unspecified bronchus\", \n",
    "                  \"malignant neoplasm of unspecified part of bronchus\", \n",
    "                  \"malignant neoplasm of overlapping sites of left bronchus\", \n",
    "                  \"malignant neoplasm of overlapping sites of right bronchus\", \n",
    "                  \"malignant neoplasm of overlapping sites of unspecified bronchus\",\n",
    "                  \"malignant neoplasm of overlapping sites of bronchus\",\n",
    "                  \"malignant neoplasm of left main bronchus\",\n",
    "                  \"malignant neoplasm of right main bronchus\",\n",
    "                  \"malignant neoplasm of unspecified main bronchus\", \"lung cancer\"],\n",
    ").execute_gbq())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a combined dataframe with source labels\n",
    "phecode_df = lung_ca_codes_phecode_df.unique(subset=[\"vocabulary_id\", \"concept_code\"]).with_columns(pl.lit(\"phecode\").alias(\"source\"))\n",
    "string_df = lung_ca_codes_string_df.unique(subset=[\"vocabulary_id\", \"concept_code\"]).with_columns(pl.lit(\"string\").alias(\"source\"))\n",
    "\n",
    "# Find rows in phecode_df not in string_df\n",
    "unique_to_phecode = phecode_df.join(\n",
    "    string_df.select([\"vocabulary_id\", \"concept_code\"]),\n",
    "    on=[\"vocabulary_id\", \"concept_code\"],\n",
    "    how=\"anti\"\n",
    ")\n",
    "\n",
    "# Find rows in string_df not in phecode_df\n",
    "unique_to_string = string_df.join(\n",
    "    phecode_df.select([\"vocabulary_id\", \"concept_code\"]),\n",
    "    on=[\"vocabulary_id\", \"concept_code\"],\n",
    "    how=\"anti\"\n",
    ")\n",
    "\n",
    "# Concatenate the unique rows\n",
    "unique_rows_df = pl.concat([unique_to_phecode, unique_to_string])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if unique_to_phecode.height == 0:\n",
    "    print('No codes unique to phecode')\n",
    "else:\n",
    "    unique_to_phecode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if unique_to_string.height == 0:\n",
    "    print('No codes unique to phecode')\n",
    "else:\n",
    "    display(unique_to_string.slice(0,50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lung_ca_code_df = (aou.person_code_df(\n",
    "    name=\"lung_ca\",\n",
    "    vocabularies=[\"ICD9CM\", \"ICD10CM\", \"SNOMED\"],\n",
    "    search_terms=[\"malignant neoplasm of bronchus\", \"carcinoma in situ of bronchus\", \n",
    "                  \"malignant neoplasm of other parts of bronchus\", \"malignant neoplasm of lower lobe\",\n",
    "                  \"malignant neoplasm of middle lobe\", \"malignant neoplasm of upper lobe\", \n",
    "                  \"malignant neoplasm of main bronchus\", \"malignant neoplasm of trachea, bronchus\", \n",
    "                  \"carcinoma in situ of left bronchus\", \"carcinoma in situ of right bronchus\", \n",
    "                  \"carcinoma in situ of unspecified bronchus\", \"malignant neoplasm of unspecified part of left bronchus\",\n",
    "                 \"malignant neoplasm of unspecified part of right bronchus\", \n",
    "                  \"malignant neoplasm of unspecified part of unspecified bronchus\", \n",
    "                  \"malignant neoplasm of unspecified part of bronchus\", \n",
    "                  \"malignant neoplasm of overlapping sites of left bronchus\", \n",
    "                  \"malignant neoplasm of overlapping sites of right bronchus\", \n",
    "                  \"malignant neoplasm of overlapping sites of unspecified bronchus\",\n",
    "                  \"malignant neoplasm of overlapping sites of bronchus\",\n",
    "                  \"malignant neoplasm of left main bronchus\",\n",
    "                  \"malignant neoplasm of right main bronchus\",\n",
    "                  \"malignant neoplasm of unspecified main bronchus\", \"lung cancer\"],\n",
    "    exclude_terms=[\"family history\", \"screening declined\", \"suspected\"],\n",
    "    dates=True\n",
    ").execute_gbq())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Germ Cell Tumor\n",
    "No specific ICD, and somewhat covered in lung cancer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Langerhans Cell Histiocytosis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lch_dict = {\n",
    "    \"ICD10CM\": [\"C96.0\", \"C96.5\", \"C96.6\"],\n",
    "    \"ICD9CM\": [\"516.5\"],\n",
    "}\n",
    "\n",
    "# Find lch diagnoses by string\n",
    "lch_codes_icd_df = (aou.find_diagnosis_codes(\n",
    "    vocabularies=[\"ICD9CM\", \"ICD10CM\", \"SNOMED\"],\n",
    "    exact_codes=lch_dict,\n",
    ").execute_gbq())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lch_codes_icd_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find lch diagnoses by string\n",
    "lch_codes_string_df = (aou.find_diagnosis_codes(\n",
    "    vocabularies=[\"ICD9CM\", \"ICD10CM\", \"SNOMED\"],\n",
    "    search_terms=[\"langerhans-cell histiocytosis\", \"langerhans cell histiocytosis\"],\n",
    ").execute_gbq())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lch_codes_string_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lch_code_df = (aou.person_code_df(\n",
    "    name=\"lch\",\n",
    "    vocabularies=[\"ICD9CM\", \"ICD10CM\", \"SNOMED\"],\n",
    "    search_terms=[\"langerhans-cell histiocytosis\", \"langerhans cell histiocytosis\"],\n",
    "    dates=True\n",
    ").execute_gbq())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IBD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ibd_dict = create_icd_dict_from_phecodes(phecodex_map, [\"GI_522.1\"]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ibd_codes_phecode_df = (aou.find_diagnosis_codes(\n",
    "    exact_codes=ibd_dict\n",
    ").execute_gbq())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ibd_codes_phecode_df.slice(50,50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find ibd diagnoses by string\n",
    "ibd_codes_string_df = (aou.find_diagnosis_codes(\n",
    "    vocabularies=[\"ICD9CM\", \"ICD10CM\", \"SNOMED\"],\n",
    "    search_terms=[\"crohn\", \"ulcerative colitis\", \"ulcerative (chronic) pancolitis\", \n",
    "                 \"ulcerative (chronic) proctitis\", \"ulcerative (chronic) rectosigmoiditis\",\n",
    "                 \"inflammatory polyps of colon\", \"left sided colitis\", \"indeterminate colitis\",\n",
    "                 \"collagenous colitis\", \"lymphocytic colitis\", \"microscopic colitis\",\n",
    "                  \"regional enteritis\", \"ulcerative (chronic) enterocolitis\", \"pseudopolyposis of colon\",\n",
    "                  \"ulcerative (chronic) ileocolitis\", \"ulcerative (chronic) colitis\",\n",
    "                  \"ulcerative (chronic) proctosigmoiditis\"],\n",
    ").execute_gbq())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a combined dataframe with source labels\n",
    "phecode_df = ibd_codes_phecode_df.unique(subset=[\"vocabulary_id\", \"concept_code\"]).with_columns(pl.lit(\"phecode\").alias(\"source\"))\n",
    "string_df = ibd_codes_string_df.unique(subset=[\"vocabulary_id\", \"concept_code\"]).with_columns(pl.lit(\"string\").alias(\"source\"))\n",
    "\n",
    "# Find rows in phecode_df not in string_df\n",
    "unique_to_phecode = phecode_df.join(\n",
    "    string_df.select([\"vocabulary_id\", \"concept_code\"]),\n",
    "    on=[\"vocabulary_id\", \"concept_code\"],\n",
    "    how=\"anti\"\n",
    ")\n",
    "\n",
    "# Find rows in string_df not in phecode_df\n",
    "unique_to_string = string_df.join(\n",
    "    phecode_df.select([\"vocabulary_id\", \"concept_code\"]),\n",
    "    on=[\"vocabulary_id\", \"concept_code\"],\n",
    "    how=\"anti\"\n",
    ")\n",
    "\n",
    "# Concatenate the unique rows\n",
    "unique_rows_df = pl.concat([unique_to_phecode, unique_to_string])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if unique_to_phecode.height == 0:\n",
    "    print('No codes unique to phecode')\n",
    "else:\n",
    "    display(unique_to_phecode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if unique_to_string.height == 0:\n",
    "    print('No codes unique to phecode')\n",
    "else:\n",
    "    display(unique_to_string.slice(0,50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ibd_code_df = (aou.person_code_df(\n",
    "    name=\"ibd\",\n",
    "    vocabularies=[\"ICD9CM\", \"ICD10CM\", \"SNOMED\"],\n",
    "    search_terms=[\"crohn\", \"ulcerative colitis\", \"ulcerative (chronic) pancolitis\", \n",
    "                 \"ulcerative (chronic) proctitis\", \"ulcerative (chronic) rectosigmoiditis\",\n",
    "                 \"inflammatory polyps of colon\", \"left sided colitis\", \"indeterminate colitis\",\n",
    "                 \"collagenous colitis\", \"lymphocytic colitis\", \"microscopic colitis\",\n",
    "                  \"regional enteritis\", \"ulcerative (chronic) enterocolitis\", \"pseudopolyposis of colon\",\n",
    "                  \"ulcerative (chronic) ileocolitis\", \"ulcerative (chronic) colitis\",\n",
    "                  \"ulcerative (chronic) proctosigmoiditis\"],\n",
    "    exclude_terms=['fh: ', 'family history'],\n",
    "    dates=True\n",
    ").execute_gbq())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Primary Biliary Cholangitis, Primary Sclerosing Cholangitis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pbc_dict = create_icd_dict_from_phecodes(phecodex_map, [\"GI_542.81\"]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pbc_codes_phecode_df = (aou.find_diagnosis_codes(\n",
    "    exact_codes=pbc_dict\n",
    ").execute_gbq())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pbc_codes_phecode_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pbc_dict = {\n",
    "    \"ICD10CM\": [\"K74.3%\", \"K83.01%\"],\n",
    "    \"ICD9CM\": [\"571.6%\", \"576.1%\"],\n",
    "}\n",
    "\n",
    "# Find PBC/PSC diagnoses\n",
    "pbc_codes_icd_df = (aou.find_diagnosis_codes(\n",
    "    vocabularies=[\"ICD9CM\", \"ICD10CM\", \"SNOMED\"],\n",
    "    pattern_codes=pbc_dict,\n",
    ").execute_gbq())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pbc_codes_icd_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find pbc diagnoses by string\n",
    "pbc_codes_string_df = (aou.find_diagnosis_codes(\n",
    "    vocabularies=[\"ICD9CM\", \"ICD10CM\", \"SNOMED\"],\n",
    "    exact_codes={\"ICD9CM\": [\"576.1\"], \"SNOMED\": [\"82403002\"]},\n",
    "    search_terms=[\"primary biliary cirrhosis\", \"sclerosing cholangitis\", \"biliary cirrhosis\"],\n",
    "    exclude_terms=[\"secondary biliary cirrhosis\", \"cirrhosis, unspecified\", \"igg4\"]\n",
    ").execute_gbq())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pbc_code_df = (aou.person_code_df(\n",
    "    name=\"pbc\",\n",
    "    vocabularies=[\"ICD9CM\", \"ICD10CM\", \"SNOMED\"],\n",
    "    exact_codes={\"ICD9CM\": [\"576.1\"], \"SNOMED\": [\"82403002\"]},\n",
    "    search_terms=[\"primary biliary cirrhosis\", \"sclerosing cholangitis\", \"biliary cirrhosis\"],\n",
    "    exclude_terms=[\"secondary biliary cirrhosis\", \"cirrhosis, unspecified\", \"igg4\"],\n",
    "    dates=True\n",
    ").execute_gbq())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autoimmune Hepatitis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aih_dict = {\n",
    "    \"ICD10CM\": [\"K75.4%\"],\n",
    "    \"ICD9CM\": [\"571.42%\"],\n",
    "}\n",
    "\n",
    "# Find aih diagnoses by string\n",
    "aih_codes_icd_df = (aou.find_diagnosis_codes(\n",
    "    vocabularies=[\"ICD9CM\", \"ICD10CM\", \"SNOMED\"],\n",
    "    pattern_codes=aih_dict,\n",
    ").execute_gbq())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aih_codes_icd_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find aih diagnoses by string\n",
    "aih_codes_string_df = (aou.find_diagnosis_codes(\n",
    "    vocabularies=[\"ICD9CM\", \"ICD10CM\", \"SNOMED\"],\n",
    "    search_terms=[\"autoimmune hepatitis\"],\n",
    ").execute_gbq())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aih_code_df = (aou.person_code_df(\n",
    "    name=\"aih\",\n",
    "    vocabularies=[\"ICD9CM\", \"ICD10CM\", \"SNOMED\"],\n",
    "    search_terms=[\"autoimmune hepatitis\"],\n",
    "    dates=True\n",
    ").execute_gbq())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HIV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hiv_dict = {\n",
    "    'ICD9CM': ['042%', '043%', '044%', '079.53', '795.78', 'V08'],\n",
    "    'ICD10CM': ['B20%', 'B21%', 'B22%', 'B23%', 'B24', 'B97.35', 'Z21', 'O98.7%']\n",
    "}\n",
    "\n",
    "# Find HIV diagnoses\n",
    "hiv_codes_icd_df = (aou.find_diagnosis_codes(\n",
    "    vocabularies=[\"ICD9CM\", \"ICD10CM\", \"SNOMED\"],\n",
    "    pattern_codes=hiv_dict,\n",
    ").execute_gbq())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hiv_codes_icd_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find hiv diagnoses by string\n",
    "hiv_codes_string_df = (aou.find_diagnosis_codes(\n",
    "    vocabularies=[\"ICD9CM\", \"ICD10CM\", \"SNOMED\"],\n",
    "    search_terms=[\"human immunodeficiency virus\"],\n",
    "    exclude_terms=[\"family\", \"inconclusive\", \"encounter for screening\", \"human immunodeficiency virus antibody positive\", \n",
    "                   \"exposure to human immunodeficiency virus\", \"counseling\", \"nonspecific serologic evidence\",]\n",
    ").execute_gbq())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hiv_codes_string_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hiv_code_df = (aou.person_code_df(\n",
    "    name=\"hiv\",\n",
    "    vocabularies=[\"ICD9CM\", \"ICD10CM\", \"SNOMED\"],\n",
    "    search_terms=[\"human immunodeficiency virus\"],\n",
    "    exclude_terms=[\"family\", \"inconclusive\", \"encounter for screening\", \"human immunodeficiency virus antibody positive\", \n",
    "                   \"exposure to human immunodeficiency virus\", \"counseling\", \"nonspecific serologic evidence\"],\n",
    "    dates=True\n",
    ").execute_gbq())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "version = os.getenv('WORKSPACE_CDR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hiv_drug_code_q = f\"\"\"\n",
    "WITH filtered_concepts AS (\n",
    "    SELECT DISTINCT concept_id, concept_code, concept_name\n",
    "    FROM {dataset}.concept c\n",
    "    WHERE vocabulary_id = 'RxNorm'\n",
    "    AND (\n",
    "    LOWER(concept_name) LIKE '%dideoxycytidine%'\n",
    "    OR LOWER(concept_name) LIKE '%zalcitabine%'\n",
    "    OR LOWER(concept_name) LIKE '%zidovudine%'\n",
    "    OR LOWER(concept_name) LIKE '%azidothymidine%'\n",
    "    OR LOWER(concept_name) LIKE '%didanosine%'\n",
    "    OR LOWER(concept_name) LIKE '%dideoxyinosine%'\n",
    "    OR LOWER(concept_name) LIKE '%stavudine%'\n",
    "    OR LOWER(concept_name) LIKE '%abacavir%'\n",
    "    OR LOWER(concept_name) LIKE '%rilpivirine%'\n",
    "    OR LOWER(concept_name) LIKE '%etravirine%'\n",
    "    OR LOWER(concept_name) LIKE '%delaviridine%'\n",
    "    OR LOWER(concept_name) LIKE '%efavirenz%'\n",
    "    OR LOWER(concept_name) LIKE '%nevirapine%'\n",
    "    OR LOWER(concept_name) LIKE '%amprenavir%'\n",
    "    OR LOWER(concept_name) LIKE '%tipranavir%'\n",
    "    OR LOWER(concept_name) LIKE '%indinavir%'\n",
    "    OR LOWER(concept_name) LIKE '%saquinavir%'\n",
    "    OR LOWER(concept_name) LIKE '%fosamprenavir%'\n",
    "    OR LOWER(concept_name) LIKE '%lopinavir%'\n",
    "    OR LOWER(concept_name) LIKE '%darunavir%'\n",
    "    OR LOWER(concept_name) LIKE '%atazanavir%'\n",
    "    OR LOWER(concept_name) LIKE '%nelfinavir%'\n",
    "    OR LOWER(concept_name) LIKE '%enfuvirtide%'\n",
    "    OR LOWER(concept_name) LIKE '%maraviroc%'\n",
    "    OR LOWER(concept_name) LIKE '%raltegravir%'\n",
    "    OR LOWER(concept_name) LIKE '%dolutegravir%'\n",
    "    OR LOWER(concept_name) LIKE '%elvitegravir%'\n",
    "    OR LOWER(concept_name) LIKE '%cobicistat%'\n",
    "    OR LOWER(concept_name) LIKE '%bictegravir%'\n",
    "    OR LOWER(concept_name) LIKE '%ibalizumab%'\n",
    "    OR LOWER(concept_name) LIKE '%fostemsavir%'\n",
    "    OR LOWER(concept_name) LIKE '%lenacapavir%'\n",
    "    OR LOWER(concept_name) LIKE '%hivid%'\n",
    "    OR LOWER(concept_name) LIKE '%retrovir%'\n",
    "    OR LOWER(concept_name) LIKE '%videx%'\n",
    "    OR LOWER(concept_name) LIKE '%zerit%'\n",
    "    OR LOWER(concept_name) LIKE '%ziagen%'\n",
    "    OR LOWER(concept_name) LIKE '%edurant%'\n",
    "    OR LOWER(concept_name) LIKE '%intelence%'\n",
    "    OR LOWER(concept_name) LIKE '%rescriptor%'\n",
    "    OR LOWER(concept_name) LIKE '%sustiva%'\n",
    "    OR LOWER(concept_name) LIKE '%viramune%'\n",
    "    OR LOWER(concept_name) LIKE '%agenerase%'\n",
    "    OR LOWER(concept_name) LIKE '%aptivus%'\n",
    "    OR LOWER(concept_name) LIKE '%crixivan%'\n",
    "    OR LOWER(concept_name) LIKE '%fortovase%'\n",
    "    OR LOWER(concept_name) LIKE '%invirase%'\n",
    "    OR LOWER(concept_name) LIKE '%lexiva%'\n",
    "    OR LOWER(concept_name) LIKE '%prezista%'\n",
    "    OR LOWER(concept_name) LIKE '%reyataz%'\n",
    "    OR LOWER(concept_name) LIKE '%viracept%'\n",
    "    OR LOWER(concept_name) LIKE '%fuzeon%'\n",
    "    OR LOWER(concept_name) LIKE '%selzentry%'\n",
    "    OR LOWER(concept_name) LIKE '%isentress%'\n",
    "    OR LOWER(concept_name) LIKE '%tivicay%'\n",
    "    OR LOWER(concept_name) LIKE '%vitekta%'\n",
    "    OR LOWER(concept_name) LIKE '%tybost%'\n",
    "    OR LOWER(concept_name) LIKE '%atripla%'\n",
    "    OR LOWER(concept_name) LIKE '%complera%'\n",
    "    OR LOWER(concept_name) LIKE '%evotaz%'\n",
    "    OR LOWER(concept_name) LIKE '%prezcobix%'\n",
    "    OR LOWER(concept_name) LIKE '%stribild%'\n",
    "    OR LOWER(concept_name) LIKE '%combivir%'\n",
    "    OR LOWER(concept_name) LIKE '%epzicom%'\n",
    "    OR LOWER(concept_name) LIKE '%trizivir%'\n",
    "    OR LOWER(concept_name) LIKE '%kaletra%'\n",
    "    OR LOWER(concept_name) LIKE '%odefsey%'\n",
    "    OR LOWER(concept_name) LIKE '%genvoya%'\n",
    "    OR LOWER(concept_name) LIKE '%triumeq%'\n",
    "    OR LOWER(concept_name) LIKE '%delstrigo%'\n",
    "    OR LOWER(concept_name) LIKE '%symfi%'\n",
    "    OR LOWER(concept_name) LIKE '%dovato%'\n",
    "    OR LOWER(concept_name) LIKE '%dutrebis%'\n",
    "    OR LOWER(concept_name) LIKE '%symtuza%'\n",
    "    OR LOWER(concept_name) LIKE '%biktarvy%'\n",
    "    OR LOWER(concept_name) LIKE '%juluca%'\n",
    "    OR LOWER(concept_name) LIKE '%cabenuva%'\n",
    "    OR LOWER(concept_name) LIKE '%doravirine%'\n",
    "    OR LOWER(concept_name) LIKE '%pifeltro%'\n",
    "    ) -- not included: emtricitabine, lamivudine, tenofovir, disoproxil, alafenamide, ritonavir\n",
    "      -- norvir, emtriva, epivir, viread, truvada, descovy, vemlidy, apretude, cabotegravir\n",
    "),\n",
    "combined AS (\n",
    "    SELECT person_id, drug_exposure_start_date AS drug_date, \n",
    "        (SELECT concept_name FROM filtered_concepts WHERE concept_id = drug_concept_id) AS drug_name,\n",
    "        (SELECT concept_code FROM filtered_concepts WHERE concept_id = drug_concept_id) AS drug_code,\n",
    "    FROM {dataset}.drug_exposure\n",
    "    WHERE drug_concept_id IN (SELECT concept_id FROM filtered_concepts)\n",
    "),\n",
    "distinct_dates AS (\n",
    "    SELECT DISTINCT person_id, drug_date, drug_code, drug_name\n",
    "    FROM combined\n",
    ")\n",
    "SELECT drug_code, drug_name, COUNT(*) AS count\n",
    "FROM distinct_dates\n",
    "GROUP BY drug_code, drug_name\n",
    "ORDER BY count DESC\n",
    "\"\"\"\n",
    "\n",
    "hiv_drug_code_df = polars_gbq(hiv_drug_code_q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hiv_drug_code_df.slice(0,15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hiv_drug_q = f\"\"\"\n",
    "WITH filtered_concepts AS (\n",
    "    SELECT DISTINCT concept_id, concept_code, concept_name\n",
    "    FROM {dataset}.concept c\n",
    "    WHERE vocabulary_id = 'RxNorm'\n",
    "    AND (\n",
    "    LOWER(concept_name) LIKE '%dideoxycytidine%'\n",
    "    OR LOWER(concept_name) LIKE '%zalcitabine%'\n",
    "    OR LOWER(concept_name) LIKE '%zidovudine%'\n",
    "    OR LOWER(concept_name) LIKE '%azidothymidine%'\n",
    "    OR LOWER(concept_name) LIKE '%didanosine%'\n",
    "    OR LOWER(concept_name) LIKE '%dideoxyinosine%'\n",
    "    OR LOWER(concept_name) LIKE '%stavudine%'\n",
    "    OR LOWER(concept_name) LIKE '%abacavir%'\n",
    "    OR LOWER(concept_name) LIKE '%rilpivirine%'\n",
    "    OR LOWER(concept_name) LIKE '%etravirine%'\n",
    "    OR LOWER(concept_name) LIKE '%delaviridine%'\n",
    "    OR LOWER(concept_name) LIKE '%efavirenz%'\n",
    "    OR LOWER(concept_name) LIKE '%nevirapine%'\n",
    "    OR LOWER(concept_name) LIKE '%amprenavir%'\n",
    "    OR LOWER(concept_name) LIKE '%tipranavir%'\n",
    "    OR LOWER(concept_name) LIKE '%indinavir%'\n",
    "    OR LOWER(concept_name) LIKE '%saquinavir%'\n",
    "    OR LOWER(concept_name) LIKE '%fosamprenavir%'\n",
    "    OR LOWER(concept_name) LIKE '%lopinavir%'\n",
    "    OR LOWER(concept_name) LIKE '%darunavir%'\n",
    "    OR LOWER(concept_name) LIKE '%atazanavir%'\n",
    "    OR LOWER(concept_name) LIKE '%nelfinavir%'\n",
    "    OR LOWER(concept_name) LIKE '%enfuvirtide%'\n",
    "    OR LOWER(concept_name) LIKE '%maraviroc%'\n",
    "    OR LOWER(concept_name) LIKE '%raltegravir%'\n",
    "    OR LOWER(concept_name) LIKE '%dolutegravir%'\n",
    "    OR LOWER(concept_name) LIKE '%elvitegravir%'\n",
    "    OR LOWER(concept_name) LIKE '%cobicistat%'\n",
    "    OR LOWER(concept_name) LIKE '%bictegravir%'\n",
    "    OR LOWER(concept_name) LIKE '%ibalizumab%'\n",
    "    OR LOWER(concept_name) LIKE '%fostemsavir%'\n",
    "    OR LOWER(concept_name) LIKE '%lenacapavir%'\n",
    "    OR LOWER(concept_name) LIKE '%hivid%'\n",
    "    OR LOWER(concept_name) LIKE '%retrovir%'\n",
    "    OR LOWER(concept_name) LIKE '%videx%'\n",
    "    OR LOWER(concept_name) LIKE '%zerit%'\n",
    "    OR LOWER(concept_name) LIKE '%ziagen%'\n",
    "    OR LOWER(concept_name) LIKE '%edurant%'\n",
    "    OR LOWER(concept_name) LIKE '%intelence%'\n",
    "    OR LOWER(concept_name) LIKE '%rescriptor%'\n",
    "    OR LOWER(concept_name) LIKE '%sustiva%'\n",
    "    OR LOWER(concept_name) LIKE '%viramune%'\n",
    "    OR LOWER(concept_name) LIKE '%agenerase%'\n",
    "    OR LOWER(concept_name) LIKE '%aptivus%'\n",
    "    OR LOWER(concept_name) LIKE '%crixivan%'\n",
    "    OR LOWER(concept_name) LIKE '%fortovase%'\n",
    "    OR LOWER(concept_name) LIKE '%invirase%'\n",
    "    OR LOWER(concept_name) LIKE '%lexiva%'\n",
    "    OR LOWER(concept_name) LIKE '%prezista%'\n",
    "    OR LOWER(concept_name) LIKE '%reyataz%'\n",
    "    OR LOWER(concept_name) LIKE '%viracept%'\n",
    "    OR LOWER(concept_name) LIKE '%fuzeon%'\n",
    "    OR LOWER(concept_name) LIKE '%selzentry%'\n",
    "    OR LOWER(concept_name) LIKE '%isentress%'\n",
    "    OR LOWER(concept_name) LIKE '%tivicay%'\n",
    "    OR LOWER(concept_name) LIKE '%vitekta%'\n",
    "    OR LOWER(concept_name) LIKE '%tybost%'\n",
    "    OR LOWER(concept_name) LIKE '%atripla%'\n",
    "    OR LOWER(concept_name) LIKE '%complera%'\n",
    "    OR LOWER(concept_name) LIKE '%evotaz%'\n",
    "    OR LOWER(concept_name) LIKE '%prezcobix%'\n",
    "    OR LOWER(concept_name) LIKE '%stribild%'\n",
    "    OR LOWER(concept_name) LIKE '%combivir%'\n",
    "    OR LOWER(concept_name) LIKE '%epzicom%'\n",
    "    OR LOWER(concept_name) LIKE '%trizivir%'\n",
    "    OR LOWER(concept_name) LIKE '%kaletra%'\n",
    "    OR LOWER(concept_name) LIKE '%odefsey%'\n",
    "    OR LOWER(concept_name) LIKE '%genvoya%'\n",
    "    OR LOWER(concept_name) LIKE '%triumeq%'\n",
    "    OR LOWER(concept_name) LIKE '%delstrigo%'\n",
    "    OR LOWER(concept_name) LIKE '%symfi%'\n",
    "    OR LOWER(concept_name) LIKE '%dovato%'\n",
    "    OR LOWER(concept_name) LIKE '%dutrebis%'\n",
    "    OR LOWER(concept_name) LIKE '%symtuza%'\n",
    "    OR LOWER(concept_name) LIKE '%biktarvy%'\n",
    "    OR LOWER(concept_name) LIKE '%juluca%'\n",
    "    OR LOWER(concept_name) LIKE '%cabenuva%'\n",
    "    OR LOWER(concept_name) LIKE '%doravirine%'\n",
    "    OR LOWER(concept_name) LIKE '%pifeltro%'\n",
    "    ) -- not included: emtricitabine, lamivudine, tenofovir, disoproxil, alafenamide, ritonavir\n",
    "      -- norvir, emtriva, epivir, viread, truvada, descovy, vemlidy, apretude, cabotegravir\n",
    "),\n",
    "combined AS (\n",
    "    SELECT de.person_id, drug_exposure_start_date AS drug_date\n",
    "    FROM {dataset}.drug_exposure de\n",
    "    WHERE drug_concept_id IN (SELECT concept_id FROM filtered_concepts)\n",
    "),\n",
    "distinct_dates AS (\n",
    "    SELECT DISTINCT person_id, drug_date\n",
    "    FROM combined\n",
    ")\n",
    "SELECT \n",
    "    person_id,\n",
    "    MIN(drug_date) AS hiv_drug\n",
    "FROM distinct_dates\n",
    "GROUP BY person_id\n",
    "\"\"\"\n",
    "\n",
    "hiv_drug_df = polars_gbq(hiv_drug_q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hiv_df = hiv_code_df.join(\n",
    "    hiv_drug_df, \n",
    "    on='person_id',\n",
    "    how='full', coalesce=True \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select positive Ab tests using value_as_unit_concept_id\n",
    "hiv_ab_q = f\"\"\"\n",
    "WITH filtered_concepts AS (\n",
    "    SELECT DISTINCT concept_id, concept_code, concept_name\n",
    "    FROM {dataset}.concept c\n",
    "    WHERE (vocabulary_id = 'CPT4' OR vocabulary_id = 'LOINC')\n",
    "    AND concept_code IN ('86701', '86703', '86702', '29327-4', '33866-5', \n",
    "    '41144-7', '35437-3', '7917-8', '14092-1', '29893-5', '5221-7', '86233-4', \n",
    "    '68961-2', '49905-3', '43599-0', '5220-9', '13499-9', '16977-1', '24012-7', \n",
    "    '44531-2', '5222-5', '16976-3', '44607-0', '69668-2', '80203-3', '42768-2', \n",
    "    '89365-1', '9661-0', '14126-7', '9660-2', '35452-2', '9662-8', '40438-4', \n",
    "    '12859-5', '9664-4', '42339-2', '9821-0', '18396-2', '9665-1', '9666-9', \n",
    "    '35564-4', '35565-1', '9667-7', '9668-5', '12856-1', '7918-6', '44873-8', \n",
    "    '44533-8', '31201-7', '80387-4', '43010-8', '42600-7', '49580-4', '22357-8', \n",
    "    '5223-3', '75666-8', '56888-1', '58900-2', '73906-0', '43009-0', '7919-4', \n",
    "    '5225-8', '30361-0', '81641-3', '5224-1', '10902-5', '21338-9', '21339-7', \n",
    "    '11081-7', '87390', '87389', '87391', '87806', '22356-0', '40439-2', '53601-1', \n",
    "    '22358-6', '28004-0', '35450-6', '73905-2', '85380-4', '33806-1', '40732-0')\n",
    "),\n",
    "combined AS (\n",
    "    SELECT person_id, measurement_date AS test_date, \n",
    "    FROM {dataset}.measurement m\n",
    "    WHERE measurement_concept_id IN (SELECT concept_id FROM filtered_concepts) \n",
    "    AND value_as_concept_id IN (36032716, 45878745, 45884084, 36310979, 45876384, 45879438, 45881802, 45877985)\n",
    "        -- Presumptive positive, Abnormal, Positive, HIV-1 Positive, High, Present, Reactive, Detected\n",
    "),\n",
    "distinct_dates AS (\n",
    "    SELECT DISTINCT person_id, test_date\n",
    "    FROM combined\n",
    ")\n",
    "SELECT \n",
    "    person_id,\n",
    "    MIN(test_date) AS hiv_pos_ab\n",
    "FROM distinct_dates\n",
    "GROUP BY person_id\n",
    "\"\"\"\n",
    "\n",
    "hiv_ab_df = polars_gbq(hiv_ab_q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hiv_df = hiv_df.join(\n",
    "    hiv_ab_df, \n",
    "    on='person_id',\n",
    "    how='full', coalesce=True \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select positive VL tests\n",
    "hiv_pos_vl_q = f\"\"\"\n",
    "WITH filtered_concepts AS (\n",
    "    SELECT DISTINCT concept_id, concept_code, concept_name\n",
    "    FROM {dataset}.concept c\n",
    "    WHERE (vocabulary_id = 'CPT4' OR vocabulary_id = 'LOINC')\n",
    "    AND concept_code IN ('49890-7', '41514-1', '41516-6', '41498-7', '70241-5', \n",
    "    '59419-2', '20447-9', '21008-8', '48551-6', '48511-0', '41515-8', '25836-8', \n",
    "    '21333-0', '24013-5', '41497-9', '29539-4', '29541-0', '51780-5', '48510-2', \n",
    "    '5017-9', '25835-0', '47359-5', '23876-6', '62469-2', '10351-5', '69353-1', \n",
    "    '69354-9', '87535', '87534', '87536', '87538', '87537', '48552-4', '41513-3', \n",
    "    '81652-0', '86547-7', '86548-5', '86549-3', '50624-6', '81246-1', '5018-7', \n",
    "    '77369-7', '85361-4', '85368-9', '79379-4', '44871-2', '9837-6', '48023-6', \n",
    "    '34699-9', '9836-8', '25841-8', '25842-6', '73659-5', '73658-7')\n",
    "),\n",
    "combined AS (\n",
    "    SELECT person_id, measurement_date AS test_date, \n",
    "    FROM {dataset}.measurement m\n",
    "    WHERE measurement_concept_id IN (SELECT concept_id FROM filtered_concepts) \n",
    "    AND (\n",
    "        (value_as_concept_id IN (45878745, 45876384, 45877985, 1620615, 1620405, 36303220, 1620483, \n",
    "        36308305, 45884084, 45884759, 45880601, 45878162))\n",
    "            -- Abnormal, High, Detected, 50, 60, 100, 90, 101, Positive, 3000, 575, 450\n",
    "        OR \n",
    "        (value_as_number > 20 AND unit_concept_id IN (8799, 0, 45756935, 8784, 4211671, 8510))\n",
    "            --copies per milliliter, no matching concept, no value, cells per microliter, cpy/mL, unit\n",
    "        OR \n",
    "        (value_as_number > log10(20) AND unit_concept_id IN (8873, 9348, 9084, 8492, 4302813, 45757552))\n",
    "            --log copies per milliliter, log10 unit per milliliter, log international unit per milliliter\n",
    "            --Log, log10, Log copies/mL\n",
    "    )\n",
    "),\n",
    "distinct_dates AS (\n",
    "    SELECT DISTINCT person_id, test_date\n",
    "    FROM combined\n",
    ")\n",
    "SELECT \n",
    "    person_id,\n",
    "    MIN(test_date) AS hiv_pos_vl\n",
    "FROM distinct_dates\n",
    "GROUP BY person_id\n",
    "\"\"\"\n",
    "\n",
    "hiv_pos_vl_df = polars_gbq(hiv_pos_vl_q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hiv_df = hiv_df.join(\n",
    "    hiv_pos_vl_df, \n",
    "    on='person_id',\n",
    "    how='full', coalesce=True \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hiv_vl_perf_q = f\"\"\"\n",
    "WITH filtered_concepts AS (\n",
    "    SELECT DISTINCT concept_id, concept_code, concept_name\n",
    "    FROM {dataset}.concept c\n",
    "    WHERE (vocabulary_id = 'CPT4' OR vocabulary_id = 'LOINC')\n",
    "    AND concept_code IN ('49890-7', '41514-1', '41516-6', '41498-7', '70241-5', \n",
    "    '59419-2', '20447-9', '21008-8', '48551-6', '48511-0', '41515-8', '25836-8', \n",
    "    '21333-0', '24013-5', '41497-9', '29539-4', '29541-0', '51780-5', '48510-2', \n",
    "    '5017-9', '25835-0', '47359-5', '23876-6', '62469-2', '10351-5', '69353-1', \n",
    "    '69354-9', '87535', '87534', '87536', '87538', '87537', '48552-4', '41513-3', \n",
    "    '81652-0', '86547-7', '86548-5', '86549-3', '50624-6', '81246-1', '5018-7', \n",
    "    '77369-7', '85361-4', '85368-9', '79379-4', '44871-2', '9837-6', '48023-6', \n",
    "    '34699-9', '9836-8', '25841-8', '25842-6', '73659-5', '73658-7')\n",
    "),\n",
    "combined AS (\n",
    "    SELECT person_id, measurement_date AS test_date, \n",
    "    FROM {dataset}.measurement m\n",
    "    WHERE measurement_concept_id IN (SELECT concept_id FROM filtered_concepts)\n",
    "    AND value_as_concept_id NOT IN (45884091, 45877494, 45878602, 45878680, 45880107, 45884199, 45884087)\n",
    "    -- Indeterminate, DNR, Not tested, Refused, N/A, Test not performed, Equivocal\n",
    "    -- reduces repeats within 5 days from 221 to 68\n",
    "    AND NOT (value_as_concept_id = 0 AND value_as_number IS NULL)\n",
    "    -- reduces repeats within 5 days from 68 to 22\n",
    "),\n",
    "distinct_dates AS (\n",
    "    SELECT DISTINCT person_id, test_date\n",
    "    FROM combined\n",
    "),\n",
    "ranked AS (\n",
    "    SELECT \n",
    "        person_id, \n",
    "        test_date,\n",
    "        ROW_NUMBER() OVER(PARTITION BY person_id ORDER BY test_date) AS rn\n",
    "    FROM distinct_dates\n",
    ")\n",
    "SELECT\n",
    "    person_id, \n",
    "    MAX(CASE WHEN rn = 1 THEN test_date ELSE NULL END) AS hiv_1_vl,\n",
    "    MAX(CASE WHEN rn = 2 THEN test_date ELSE NULL END) AS hiv_2_vl\n",
    "FROM ranked\n",
    "GROUP BY person_id\n",
    "\"\"\"\n",
    "\n",
    "hiv_vl_perf_df = polars_gbq(hiv_vl_perf_q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hiv_df = hiv_df.join(\n",
    "    hiv_vl_perf_df, \n",
    "    on='person_id',\n",
    "    how='full', coalesce=True \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hiv_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hiv_df = hiv_df.with_columns([\n",
    "    pl.when(pl.col(\"hiv_pos_ab\").is_null())\n",
    "      .then(pl.col(\"hiv_pos_vl\"))\n",
    "      .when(pl.col(\"hiv_pos_vl\").is_null())\n",
    "      .then(pl.col(\"hiv_pos_ab\"))\n",
    "      .otherwise(pl.when((pl.col(\"hiv_pos_ab\") - pl.col(\"hiv_pos_vl\")) > pl.duration(days=0))\n",
    "                .then(pl.col(\"hiv_pos_vl\"))\n",
    "                .otherwise(pl.col(\"hiv_pos_ab\")))\n",
    "      .alias(\"cond_1\"),\n",
    "\n",
    "    pl.when(pl.col(\"hiv_1_vl\").is_not_null() & pl.col(\"hiv_drug\").is_not_null())\n",
    "      .then(\n",
    "          pl.when((pl.col(\"hiv_1_vl\") - pl.col(\"hiv_drug\")).dt.total_days() > 0)\n",
    "            .then(pl.col(\"hiv_1_vl\"))\n",
    "            .otherwise(pl.col(\"hiv_drug\"))\n",
    "      )\n",
    "      .otherwise(pl.lit(None))\n",
    "      .alias(\"cond_2\"),\n",
    "    \n",
    "    pl.when(pl.col(\"hiv_1\").is_not_null() & pl.col(\"hiv_drug\").is_not_null())\n",
    "      .then(\n",
    "          pl.when((pl.col(\"hiv_1\") - pl.col(\"hiv_drug\")).dt.total_days() > 0)\n",
    "            .then(pl.col(\"hiv_1\"))\n",
    "            .otherwise(pl.col(\"hiv_drug\"))\n",
    "      )\n",
    "      .otherwise(pl.lit(None))\n",
    "      .alias(\"cond_3\"),\n",
    "    \n",
    "    pl.when(pl.col(\"hiv_1\").is_not_null() & pl.col(\"hiv_2_vl\").is_not_null())\n",
    "      .then(\n",
    "          pl.when((pl.col(\"hiv_1\") - pl.col(\"hiv_2_vl\")).dt.total_days() > 0)\n",
    "            .then(pl.col(\"hiv_1\"))\n",
    "            .otherwise(pl.col(\"hiv_2_vl\"))\n",
    "      )\n",
    "      .otherwise(pl.lit(None))\n",
    "      .alias(\"cond_4\"),\n",
    "    \n",
    "    pl.when(pl.col(\"hiv_2\").is_not_null())\n",
    "      .then(pl.col(\"hiv_2\"))\n",
    "      .otherwise(pl.lit(None))\n",
    "      .alias(\"cond_5\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hiv_pd_df = hiv_df.select('person_id', 'cond_1', 'cond_2', 'cond_3', 'cond_4', 'cond_5').to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hiv_pd_df['hiv_2'] = hiv_pd_df[['cond_1', 'cond_2', 'cond_3', 'cond_4', 'cond_5']].min(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hiv_final = pl.from_pandas(hiv_pd_df)\n",
    "hiv_final = hiv_final.drop('cond_1', 'cond_2', 'cond_3', 'cond_4', 'cond_5')\n",
    "hiv_final = hiv_final.with_columns(\n",
    "    hiv_final['hiv_2'].cast(pl.Date)\n",
    ")\n",
    "hiv_final = hiv_final.with_columns(\n",
    "    pl.lit(\"1990-01-01\").str.strptime(pl.Date, \"%Y-%m-%d\").alias(\"hiv_1\")\n",
    ").select(['person_id', 'hiv_1', 'hiv_2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "venn_df = pl.from_pandas(hiv_pd_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_cond_1 = set(venn_df.filter(pl.col(\"cond_1\").is_not_null())[\"person_id\"].to_numpy())\n",
    "set_cond_2 = set(venn_df.filter(pl.col(\"cond_2\").is_not_null())[\"person_id\"].to_numpy())\n",
    "set_cond_3 = set(venn_df.filter(pl.col(\"cond_3\").is_not_null())[\"person_id\"].to_numpy())\n",
    "set_cond_4 = set(venn_df.filter(pl.col(\"cond_4\").is_not_null())[\"person_id\"].to_numpy())\n",
    "set_cond_5 = set(venn_df.filter(pl.col(\"cond_5\").is_not_null())[\"person_id\"].to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from venny4py.venny4py import *\n",
    "\n",
    "sets = {\n",
    "    '+Ab or +VL': set_cond_1,\n",
    "    'VL done and Tx': set_cond_2,\n",
    "    'ICD and Tx': set_cond_3,\n",
    "#     'ICD and two VL done': set_cond_4,\n",
    "    'two ICD': set_cond_5,\n",
    "}\n",
    "\n",
    "venny4py(sets=sets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df = hiv_df.filter(pl.col('person_id').is_in(hiv_final.filter(pl.col('hiv_2').is_null())['person_id']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# counts for those who don't meed conditions\n",
    "filtered_df = filtered_df.with_columns([\n",
    "    (pl.when(pl.col('hiv_1').is_not_null()).then(pl.lit('hiv_1')).otherwise(pl.lit('')).cast(pl.Utf8) + '_' +\n",
    "     pl.when(pl.col('hiv_2').is_not_null()).then(pl.lit('hiv_2')).otherwise(pl.lit('')).cast(pl.Utf8) + '_' +\n",
    "     pl.when(pl.col('hiv_drug').is_not_null()).then(pl.lit('hiv_drug')).otherwise(pl.lit('')).cast(pl.Utf8) + '_' +\n",
    "     pl.when(pl.col('hiv_pos_ab').is_not_null()).then(pl.lit('hiv_pos_ab')).otherwise(pl.lit('')).cast(pl.Utf8) + '_' +\n",
    "     pl.when(pl.col('hiv_pos_vl').is_not_null()).then(pl.lit('hiv_pos_vl')).otherwise(pl.lit('')).cast(pl.Utf8) + '_' +\n",
    "     pl.when(pl.col('hiv_1_vl').is_not_null()).then(pl.lit('hiv_1_vl')).otherwise(pl.lit('')).cast(pl.Utf8) + '_' +\n",
    "     pl.when(pl.col('hiv_2_vl').is_not_null()).then(pl.lit('hiv_2_vl')).otherwise(pl.lit('')).cast(pl.Utf8)).alias('non_null_combination')\n",
    "])\n",
    "\n",
    "filtered_df.group_by('non_null_combination').agg(pl.len().alias('counts')).sort('counts', descending=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to select only person_id and columns ending with '_2'\n",
    "def select_columns(df):\n",
    "    # Get all columns that end with '_2'\n",
    "    cols_ending_with_2 = [col for col in df.columns if col.endswith('_2')]\n",
    "    # Return dataframe with only person_id and those columns\n",
    "    if cols_ending_with_2:\n",
    "        return df.select(['person_id'] + cols_ending_with_2)\n",
    "    else:\n",
    "        return df.select('person_id')\n",
    "\n",
    "# Apply the function to each dataframe before merging\n",
    "tb_code_filtered = select_columns(tb_code_df)\n",
    "\n",
    "# List of all dataframes to merge (filtered)\n",
    "dfs_to_merge_filtered = [\n",
    "    select_columns(tb_skin_code_df),\n",
    "    select_columns(ntm_code_df),\n",
    "    select_columns(histo_code_df),\n",
    "    select_columns(blasto_code_df),\n",
    "    select_columns(cocci_code_df),\n",
    "    select_columns(aspergillus_code_df),\n",
    "    select_columns(ild_code_df),\n",
    "    select_columns(hp_code_df),\n",
    "    select_columns(pneumoconiosis_code_df),\n",
    "    select_columns(vasculitis_code_df),\n",
    "    select_columns(cvid_code_df),\n",
    "    select_columns(igg4_code_df),\n",
    "    select_columns(lymphoma_code_df),\n",
    "    select_columns(lg_code_df),\n",
    "    select_columns(lung_ca_code_df),\n",
    "    select_columns(lch_code_df),\n",
    "    select_columns(ibd_code_df),\n",
    "    select_columns(pbc_code_df),\n",
    "    select_columns(aih_code_df),\n",
    "    select_columns(hiv_final)\n",
    "]\n",
    "\n",
    "# Start with the first filtered dataframe\n",
    "exclude_df = tb_code_filtered\n",
    "\n",
    "# Merge each filtered dataframe one by one\n",
    "for df in dfs_to_merge_filtered:\n",
    "    exclude_df = exclude_df.join(df, on='person_id', how='full', coalesce=True)\n",
    "    \n",
    "exclude_df = exclude_df.join(exclusion_drug_df, on='person_id', how='full', coalesce=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exclude_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Labs and Procedures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CXR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find CXRs\n",
    "cxr_procedures_df = (aou.find_procedure_codes(\n",
    "    search_terms=[\"chest\"]\n",
    ").execute_gbq())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find CXRs\n",
    "cxr_procedures_df = (aou.find_procedure_codes(\n",
    "    search_terms=[\"chest x-ray\", \"radiologic examination, chest\", \"radiography of chest\", \"xr chest\"],\n",
    "    exclude_terms=['of the following', 'special views']\n",
    ").execute_gbq())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cxr_df = (aou.person_procedure_df(\n",
    "    name=\"cxr\",\n",
    "    search_terms=[\"chest x-ray\", \"radiologic examination, chest\", \"radiography of chest\", \"xr chest\"],\n",
    "    exclude_terms=['of the following', 'special views'],\n",
    "    dates=True\n",
    ").execute_gbq())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Participants with 1 procedure: {cxr_df.filter(pl.col('cxr_n')==1).height}\")\n",
    "print(f\"Participants with  2 procedures: {cxr_df.filter(pl.col('cxr_n')>1).height}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cxr_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CT Chest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find sarcoid diagnoses\n",
    "ct_chest_procedures_df = (aou.find_procedure_codes(\n",
    "    search_terms=[\"ct chest\", \"computed tomography of chest\", \"(ct scan) of chest\",\n",
    "                \"ct of chest\", \"computed tomography, thorax\", \"(ct scan) of thorax\"], #computed tomographic angiography, chest\n",
    "    exclude_terms=[\"low dose for lung cancer screening\", \"abdomen\"]\n",
    ").execute_gbq())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct_chest_df = (aou.person_procedure_df(\n",
    "    name=\"ct_chest\",\n",
    "    search_terms=[\"ct chest\", \"computed tomography of chest\", \"(ct scan) of chest\",\n",
    "                \"ct of chest\", \"computed tomography, thorax\", \"(ct scan) of thorax\"],\n",
    "    # computed tomographic angiography, chest NOT included\n",
    "    # no high-resolution CT found\n",
    "    exclude_terms=[\"low dose for lung cancer screening\", \"abdomen\"],\n",
    "    dates=True\n",
    ").execute_gbq())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Participants with 1 procedure: {ct_chest_df.filter(pl.col('ct_chest_n')==1).height}\")\n",
    "print(f\"Participants with  2 procedures: {ct_chest_df.filter(pl.col('ct_chest_n')>1).height}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct_chest_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Biopsy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find * procedures\n",
    "biopsy_procedures_df = (aou.find_procedure_codes(\n",
    "    search_terms=[\"biopsy\"],\n",
    "    exclude_terms = [\n",
    "    # Reproductive/Gynecological\n",
    "    \"cervix\", \"cervical\", \"endocervical\", \"uterus\", \"uterine\", \"endometrium\", \"endometrial\",\n",
    "    \"ovary\", \"ovarian\", \"fallopian\", \"vagina\", \"vaginal\", \"vulva\", \"vulval\", \n",
    "    \"prostate\", \"testis\", \"penis\", \"penile\",\n",
    "    \n",
    "    # Breast\n",
    "    \"breast\", \"mammary\", \"mammogram\",\n",
    "        \n",
    "    # GI\n",
    "    \"biliary\", \"cholangiography\", \"pancreas\", \"pancreatic\", \"exploratory laparotomy\", \n",
    "    \"exploration, retroperitoneal\", \"abdominal or retroperitoneal mass\", \n",
    "    \"laparoscopy, surgical\", \"perirectal\", \"perianal\", \"anus\", \"abdominal wall\", \n",
    "    \"peritoneum\", \"intra-abdominal mass\", \"cul-de-sac\",\n",
    "        \n",
    "    # Genitourinary (except kidney)\n",
    "    \"bladder\", \"ureter\", \"urethra\", \"periurethral\", \"cystourethroscopy\",\n",
    "    \n",
    "    # Head/Neck (except salivary glands)\n",
    "    \"tongue\", \"lip\", \"palate\", \"uvula\", \"pharynx\", \"larynx\", \"trachea\",\n",
    "    \"thyroid\", \"parathyroid\", \"adrenal\", \"pituitary\", \"pineal\",\n",
    "    \"nasal\", \"sinus\", \"ear\", \"auditory\", \"laryngoscopy\", \"of mouth\",\n",
    "    \"salivary gland\", \"oral tissue\", \"nose\", \"gum\", \"salivary\", \"tonsils\", \"mouth\",\n",
    "    \"pharyngeal\", \"vocal cord\", \n",
    "    \n",
    "    # Extremities/Joints\n",
    "    \"joint\", \"arthro\", \"metacarpo\", \"metatarsal\", \"phalang\", \"carpal\",\n",
    "    \"shoulder\", \"elbow\", \"wrist\", \"hip\", \"knee\", \"ankle\", \"foot\", \"toe\",\n",
    "    \"clavicle\", \"scapula\", \"sternum\", \"rib\",\n",
    "    \n",
    "    # MSK (except bone marrow)\n",
    "    \"bone biopsy\", \"bone\", \"vertebral\", \"femur\", \"tibia\", \"fibula\",\n",
    "    \"humerus\", \"radius\", \"ulna\", \"skull\", \"facial bone\", \"muscle\",\n",
    "    \"soft tissue\", \"chest wall\", \"blood vessel\", \"lymphatic structure\",\n",
    "    \"subcutaneous tissue\",\n",
    "    \n",
    "    # Anesthesia procedures\n",
    "    \"anesthesia for\",\n",
    "    \n",
    "    # Fetal/Obstetric\n",
    "    \"fetal\", \"embryo\", \"oocyte\", \"polar body\", \"blastomere\",\n",
    "    \n",
    "    # Transplant\n",
    "    \"transplantation medicine\",\n",
    "        \n",
    "    # Other\n",
    "    \"nail unit\", \"transcatheter biopsy\", \"temporal artery\", \"fluoroscopy, physician\",\n",
    "    \"fluoroscopic guidance\", \"radiological supervision\", \"guidance for \", \"tumor\",\n",
    "    \"cancer\", \"carcinoma\", \"Biopsy results not reviewed\", \"previous biopsy\",\n",
    "    \"sentinel\", \"biopsy results reviewed\", \"biopsy results were not reviewed\",\n",
    "    \"specimen narrative\", \"tomography guidance\", \"hysteroscopy\", \n",
    "    \"fine needle aspiration biopsy - action\", \"ct guidance\",\n",
    "        \n",
    "    # CNS\n",
    "    \"brain\", \"intracranial\", \"spinal cord\", \"intraspinal neoplasm\", \"nerve\",\n",
    "    \"cornea\", \"extraocular muscle\", \"orbitotomy\", \"cerebral meninges\", \"iris\"\n",
    "]\n",
    ").execute_gbq())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find * procedures\n",
    "pulmonary_biopsy_procedures_df = (aou.find_procedure_codes(\n",
    "    search_terms=['endobronchial biopsy', 'transbronchial lung biopsy', \n",
    "                  'transbronchial needle aspiration', 'bronchial brush biopsy', \n",
    "                  'biopsy of lung', 'biopsy(ies) of lung' 'biopsy(ies) of pleura',\n",
    "                  'biopsy, pleura', 'biopsy, lung or mediastinum',\n",
    "                  'pleural space, with biopsy', 'pericardial sac, with biopsy',\n",
    "                  'mediastinal space, with biopsy', 'mediastinoscopy, includes biopsy(ies)',\n",
    "                  'mediastinotomy with exploration, drainage, removal of foreign body, or biopsy',\n",
    "                  'mediastinoscopy; includes biopsy(ies)', 'transbronchial biopsy', \n",
    "                  'mediastinoscopy; with lymph node biopsy(ies)', 'thoracoscopic lung biopsy',\n",
    "                  'biopsy of bronchus', 'pleural biopsy', 'biopsy of mediastinum',\n",
    "                  'mediastinal biopsy', 'mediastinoscopy with biopsy', \n",
    "                  'endoscopy of bronchus with biopsy', 'bronchoscopy with biopsy'],\n",
    "    exclude_terms=['fluoroscopy, physician']\n",
    ").execute_gbq())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pulmonary_biopsy_df = (aou.person_procedure_df(\n",
    "    name=\"pulm_bx\",\n",
    "    search_terms=['endobronchial biopsy', 'transbronchial lung biopsy', \n",
    "                  'transbronchial needle aspiration', 'bronchial brush biopsy', \n",
    "                  'biopsy of lung', 'biopsy(ies) of lung' 'biopsy(ies) of pleura',\n",
    "                  'biopsy, pleura', 'biopsy, lung or mediastinum',\n",
    "                  'pleural space, with biopsy', 'pericardial sac, with biopsy',\n",
    "                  'mediastinal space, with biopsy', 'mediastinoscopy, includes biopsy(ies)',\n",
    "                  'mediastinotomy with exploration, drainage, removal of foreign body, or biopsy',\n",
    "                  'mediastinoscopy; includes biopsy(ies)', 'transbronchial biopsy', \n",
    "                  'mediastinoscopy; with lymph node biopsy(ies)', 'thoracoscopic lung biopsy',\n",
    "                  'biopsy of bronchus', 'pleural biopsy', 'biopsy of mediastinum',\n",
    "                  'mediastinal biopsy', 'mediastinoscopy with biopsy', \n",
    "                  'endoscopy of bronchus with biopsy', 'bronchoscopy with biopsy'],\n",
    "    exclude_terms=['fluoroscopy, physician'],\n",
    "    dates=True\n",
    ").execute_gbq())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Participants with 1 procedure: {pulmonary_biopsy_df.filter(pl.col('pulm_bx_n')==1).height}\")\n",
    "print(f\"Participants with  2 procedures: {pulmonary_biopsy_df.filter(pl.col('pulm_bx_n')>1).height}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pulmonary_biopsy_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find * procedures\n",
    "non_pulmonary_biopsy_procedures_df = (aou.find_procedure_codes(\n",
    "    search_terms=[\n",
    "        # GI\n",
    "        'esophageal biopsy', 'transoral; with biopsy', 'biopsy of stomach',\n",
    "        'anoscopy, high resolution (hra) (with magnification and chemical agent enhancement); with biopsy(ies)',\n",
    "        'esophagoscopy, flexible, transoral; with transendoscopic ultrasound-guided intramural or transmural fine needle aspiration/biopsy(s)',\n",
    "        'esophagogastroduodenoscopy, flexible, transoral; with transendoscopic ultrasound-guided intramural or transmural fine needle aspiration/biopsy(s)',\n",
    "        '(ErCP); with biopsy', 'duodenotomy, for exploration, biopsy', 'small intestine, other than duodenum; for exploration, biopsy',\n",
    "        'colotomy, for exploration, biopsy', 'biopsy of intestine by capsule', 'ileum; with biopsy', \n",
    "        'through stoma; with biopsy', 'ileal reservoir [s or j]); with biopsy',\n",
    "        'transendoscopic ultrasound guided intramural or transmural fine needle aspiration/biopsy',\n",
    "        'proctosigmoidoscopy, rigid; with biopsy', 'sigmoidoscopy, flexible; with biopsy',\n",
    "        'colonoscopy, flexible; with biopsy', 'anoscopy; with biopsy', 'anoscopy; with high-resolution magnification (hra) (eg, colposcope, operating microscope) and chemical agent enhancement, with biopsy',\n",
    "        'anoscopy, high resolution (hra) (with magnification and chemical agent enhancement); with biopsy(ies)',\n",
    "        'biopsy of spleen', 'biopsy of esophagus', 'biopsy of stomach', 'biopsy of small intestine', \n",
    "        '[egd] with closed biopsy', 'biopsy of large intestine', 'intestinal biopsy', 'biopsy of rectum', \n",
    "        'biopsy of liver', 'liver biopsy', 'endoscopy and biopsy', 'sigmoidoscopy with biopsy', 'biopsy of colon',\n",
    "        'endoscopic biopsy',\n",
    "        \n",
    "        # General\n",
    "        'fine needle aspiration biopsy',\n",
    "        \n",
    "        # Skin\n",
    "        'biopsy of skin', 'biopsy of lesion of skin',\n",
    "        \n",
    "        # Bone Marrow\n",
    "        'bone marrow; biopsy', 'bone marrow biopsy',\n",
    "        \n",
    "        # LN\n",
    "        'biopsy or excision of lymph node', 'lymph node sampling', 'biopsy of lymph node',\n",
    "        'biopsy of axillary lymph node', 'biopsy of abdominal lymph node', 'biopsy of inguinal lymph node',\n",
    "\n",
    "        # renal\n",
    "        'renal biopsy', 'biopsy of kidney', 'renal needle biopsy', 'kidney biopsy',\n",
    "\n",
    "        # Ocular\n",
    "        'eyelid skin', 'biopsy of conjunctiva', 'biopsy of eye', 'biopsy of lacrimal gland',\n",
    "        'biopsy of lacrimal sac', \n",
    "\n",
    "        # Cardiac\n",
    "        'endomyocardial biopsy', 'biopsy of pericardium',\n",
    "    ],\n",
    "    exclude_terms=['anesthesia for', 'hysterectomy', 'vaginectomy', 'trachelectomy'],\n",
    ").execute_gbq())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_pulmonary_biopsy_df = (aou.person_procedure_df(\n",
    "    name=\"non_pulm_bx\",\n",
    "    search_terms=[\n",
    "        # GI\n",
    "        'esophageal biopsy', 'transoral; with biopsy', 'biopsy of stomach',\n",
    "        'anoscopy, high resolution (hra) (with magnification and chemical agent enhancement); with biopsy(ies)',\n",
    "        'esophagoscopy, flexible, transoral; with transendoscopic ultrasound-guided intramural or transmural fine needle aspiration/biopsy(s)',\n",
    "        'esophagogastroduodenoscopy, flexible, transoral; with transendoscopic ultrasound-guided intramural or transmural fine needle aspiration/biopsy(s)',\n",
    "        '(ErCP); with biopsy', 'duodenotomy, for exploration, biopsy', 'small intestine, other than duodenum; for exploration, biopsy',\n",
    "        'colotomy, for exploration, biopsy', 'biopsy of intestine by capsule', 'ileum; with biopsy', \n",
    "        'through stoma; with biopsy', 'ileal reservoir [s or j]); with biopsy',\n",
    "        'transendoscopic ultrasound guided intramural or transmural fine needle aspiration/biopsy',\n",
    "        'proctosigmoidoscopy, rigid; with biopsy', 'sigmoidoscopy, flexible; with biopsy',\n",
    "        'colonoscopy, flexible; with biopsy', 'anoscopy; with biopsy', 'anoscopy; with high-resolution magnification (hra) (eg, colposcope, operating microscope) and chemical agent enhancement, with biopsy',\n",
    "        'anoscopy, high resolution (hra) (with magnification and chemical agent enhancement); with biopsy(ies)',\n",
    "        'biopsy of spleen', 'biopsy of esophagus', 'biopsy of stomach', 'biopsy of small intestine', \n",
    "        '[egd] with closed biopsy', 'biopsy of large intestine', 'intestinal biopsy', 'biopsy of rectum', \n",
    "        'biopsy of liver', 'liver biopsy', 'endoscopy and biopsy', 'sigmoidoscopy with biopsy', 'biopsy of colon',\n",
    "        'endoscopic biopsy',\n",
    "        \n",
    "        # General\n",
    "        'fine needle aspiration biopsy',\n",
    "        \n",
    "        # Skin\n",
    "        'biopsy of skin', 'biopsy of lesion of skin',\n",
    "        \n",
    "        # Bone Marrow\n",
    "        'bone marrow; biopsy', 'bone marrow biopsy',\n",
    "        \n",
    "        # LN\n",
    "        'biopsy or excision of lymph node', 'lymph node sampling', 'biopsy of lymph node',\n",
    "        'biopsy of axillary lymph node', 'biopsy of abdominal lymph node', 'biopsy of inguinal lymph node',\n",
    "\n",
    "        # renal\n",
    "        'renal biopsy', 'biopsy of kidney', 'renal needle biopsy', 'kidney biopsy',\n",
    "\n",
    "        # Ocular\n",
    "        'eyelid skin', 'biopsy of conjunctiva', 'biopsy of eye', 'biopsy of lacrimal gland',\n",
    "        'biopsy of lacrimal sac', \n",
    "\n",
    "        # Cardiac\n",
    "        'endomyocardial biopsy', 'biopsy of pericardium',\n",
    "    ],\n",
    "    exclude_terms=['anesthesia for', 'hysterectomy', 'vaginectomy', 'trachelectomy'],\n",
    "    dates=True\n",
    ").execute_gbq())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Participants with 1 procedure: {non_pulmonary_biopsy_df.filter(pl.col('non_pulm_bx_n')==1).height}\")\n",
    "print(f\"Participants with  2 procedures: {non_pulmonary_biopsy_df.filter(pl.col('non_pulm_bx_n')>1).height}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_pulmonary_biopsy_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PFTs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find * procedures\n",
    "pft_procedures_df = (aou.find_procedure_codes(\n",
    "    search_terms=[\"pulmonary function\", \"spirometry\"],\n",
    "    exclude_terms=['(copd)', 'copd symptoms', 'prior to surgery', '(als)', 'exercise', '6-minute walk test']    \n",
    ").execute_gbq())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pft_procedures_df['vocabulary_id', 'concept_name', 'unique_persons', 'total_events']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pft_df = (aou.person_procedure_df(\n",
    "    name=\"pft\",\n",
    "    search_terms=[\"pulmonary function\", \"spirometry\"],\n",
    "    exclude_terms=['(copd)', 'copd symptoms', 'prior to surgery', '(als)', 'exercise', '6-minute walk test'],    \n",
    "    dates=True\n",
    ").execute_gbq())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Participants with 1 procedure: {pft_df.filter(pl.col('pft_n')==1).height}\")\n",
    "print(f\"Participants with  2 procedures: {pft_df.filter(pl.col('pft_n')>1).height}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pft_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ECG Procedures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find * procedures\n",
    "ecg_procedures_df = (aou.find_procedure_codes(\n",
    "    search_terms=[\"electrocardiogram\", 'electrokardiogram', 'ecg', 'ekg'],\n",
    "    exclude_terms=[\"coronary artery obstruction\", \"telephonic transmission\",\n",
    "                  \"mobile cardiovascular telemetry\", \"signal-averaged electrocardiography\",\n",
    "                   \"tilt table evaluation\", \"loop recorder\", \"wearable cardioverter\", \n",
    "                   \"cardiac rehabilitation\", \"sleep\", \"clinical data stored in computers\",\n",
    "                   \"blood pressure\", \"pump with oxygenator\", \"initial preventive\", \"not performed\",\n",
    "                   \"portable ekg to facility\", \"fetal\", \"phonocardiogram\", \"carotid pulse tracing\",\n",
    "                   \"benzoyl\"]\n",
    ").execute_gbq())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ecg_procedures_df[\n",
    "    'vocabulary_id',\n",
    "    'concept_name',\n",
    "    'unique_persons',\n",
    "    'total_events'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ecg_df = (aou.person_procedure_df(\n",
    "    name=\"ecg\",\n",
    "    search_terms=[\"electrocardiogram\", 'electrokardiogram', 'ecg', 'ekg'],\n",
    "    exclude_terms=[\"coronary artery obstruction\", \"telephonic transmission\",\n",
    "                  \"mobile cardiovascular telemetry\", \"signal-averaged electrocardiography\",\n",
    "                   \"tilt table evaluation\", \"loop recorder\", \"wearable cardioverter\", \n",
    "                   \"cardiac rehabilitation\", \"sleep\", \"clinical data stored in computers\",\n",
    "                   \"blood pressure\", \"pump with oxygenator\", \"initial preventive\", \"not performed\",\n",
    "                   \"portable ekg to facility\", \"fetal\", \"phonocardiogram\", \"carotid pulse tracing\",\n",
    "                   \"benzoyl\"],\n",
    "    dates=True\n",
    ").execute_gbq())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Participants with 1 procedure: {ecg_df.filter(pl.col('ecg_n')==1).height}\")\n",
    "print(f\"Participants with  2 procedures: {ecg_df.filter(pl.col('ecg_n')>1).height}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ecg_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ECG Abnormalities (AV block, PVCs, SVT [AF, flutter, AT])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find * procedures\n",
    "*_procedures_df = (aou.find_procedure_codes(\n",
    "    search_terms=[\"\"]\n",
    ").execute_gbq())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find * procedures\n",
    "*_procedures_df = (aou.find_procedure_codes(\n",
    "    search_terms=[],\n",
    ").execute_gbq())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "*_df = (aou.person_procedure_df(\n",
    "    name=\"*\",\n",
    "    search_terms=[],\n",
    "    dates=True\n",
    ").execute_gbq())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "*_df = (aou.person_procedure_df(\n",
    "    name=\"*\",\n",
    "    search_terms=[],\n",
    "    dates=True\n",
    ").execute_gbq())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Participants with 1 procedure: {*_df.filter(pl.col('*_n')==1).height}\")\n",
    "print(f\"Participants with  2 procedures: {*_df.filter(pl.col('*_n')>1).height}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "*_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CBC\n",
    "Leukopenia (5 to 10 percent) [69], eosinophilia (3 percent) [70], and thrombocytopenia (rare) can be seen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the explorer object \n",
    "explorer = Explorer(variable_type = \"measurements\", cohort = cohort, version = version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display annotated variables\n",
    "metadata = explorer.variables()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WBC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata.filter(pl.col('measurement_name').str.contains('leukoc'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the unifier object\n",
    "measurement = Unifier(measurement_cid = 3000905, \n",
    "                      file_path = file_path,\n",
    "                      cohort = cohort,\n",
    "                      version = version,\n",
    "                      file_type = file_type,\n",
    "                      save_annotation = True, \n",
    "                      drop_sites = True)\n",
    "\n",
    "# Execute the unify() function to annotate and save measurements for the given measurement_cid\n",
    "measurement.unify()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gsutil ls {bucket}/data/allofus/C2024Q3R5/measurement_data/annotations/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wbc_time_series = pl.read_parquet(f'{bucket}/data/allofus/C2024Q3R5/measurement_data/timeseries/timeseries_3000905.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "leukopenia_df = (\n",
    "   wbc_time_series\n",
    "   .filter(pl.col(\"value_as_number\") < 4.4)\n",
    "   .group_by(\"person_id\")\n",
    "   .agg(\n",
    "       pl.col(\"measurement_datetime\").sort().first().cast(pl.Date).alias(\"leukopenia_1\"),\n",
    "       pl.col(\"measurement_datetime\").sort().slice(1, 1).first().cast(pl.Date).alias(\"leukopenia_2\")\n",
    "   )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata.filter(pl.col('measurement_name').str.contains('platelet'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the unifier object\n",
    "measurement = Unifier(measurement_cid = 3024929, \n",
    "                      file_path = file_path,\n",
    "                      cohort = cohort,\n",
    "                      version = version,\n",
    "                      file_type = file_type,\n",
    "                      save_annotation = True, \n",
    "                      drop_sites = True)\n",
    "\n",
    "# Execute the unify() function to annotate and save measurements for the given measurement_cid\n",
    "measurement.unify()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt_time_series = pl.read_parquet(f'{bucket}/data/allofus/C2024Q3R5/measurement_data/timeseries/timeseries_3024929.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thrombocytopenia_df = (\n",
    "   plt_time_series\n",
    "   .filter(pl.col(\"value_as_number\") < 150)\n",
    "   .group_by(\"person_id\")\n",
    "   .agg(\n",
    "       pl.col(\"measurement_datetime\").sort().first().cast(pl.Date).alias(\"thrombocytopenia_1\"),\n",
    "       pl.col(\"measurement_datetime\").sort().slice(1, 1).first().cast(pl.Date).alias(\"thrombocytopenia_2\")\n",
    "   )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eosinophils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata.filter(pl.col('measurement_name').str.contains('eosinophil'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the unifier object\n",
    "measurement = Unifier(measurement_cid = 3028615, \n",
    "                      file_path = file_path,\n",
    "                      cohort = cohort,\n",
    "                      version = version,\n",
    "                      file_type = file_type,\n",
    "                      save_annotation = True, \n",
    "                      drop_sites = True)\n",
    "\n",
    "# Execute the unify() function to annotate and save measurements for the given measurement_cid\n",
    "measurement.unify()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aec_time_series = pl.read_parquet(f'{bucket}/data/allofus/C2024Q3R5/measurement_data/timeseries/timeseries_3028615.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aec_time_series.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pbe_df = (\n",
    "   aec_time_series\n",
    "   .filter(pl.col(\"value_as_number\") > 0.5)\n",
    "   .group_by(\"person_id\")\n",
    "   .agg(\n",
    "       pl.col(\"measurement_datetime\").sort().first().cast(pl.Date).alias(\"pbe_1\"),\n",
    "       pl.col(\"measurement_datetime\").sort().slice(1, 1).first().cast(pl.Date).alias(\"pbe_2\")\n",
    "   )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ca\n",
    "hypercalcemia\n",
    "https://www.ncbi.nlm.nih.gov/books/NBK430714/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata.filter(pl.col('measurement_name').str.contains('calcium'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the unifier object\n",
    "measurement = Unifier(measurement_cid = 3006906, \n",
    "                      file_path = file_path,\n",
    "                      cohort = cohort,\n",
    "                      version = version,\n",
    "                      file_type = file_type,\n",
    "                      save_annotation = True, \n",
    "                      drop_sites = True)\n",
    "\n",
    "# Execute the unify() function to annotate and save measurements for the given measurement_cid\n",
    "measurement.unify()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calcium_time_series = pl.read_parquet(f'{bucket}/data/allofus/C2024Q3R5/measurement_data/timeseries/timeseries_3006906.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "hypercalcemia_df = (\n",
    "   calcium_time_series\n",
    "   .filter(pl.col(\"value_as_number\") > 10.5)\n",
    "   .group_by(\"person_id\")\n",
    "   .agg(\n",
    "       pl.col(\"measurement_datetime\").sort().first().cast(pl.Date).alias(\"hypercalcemia_1\"),\n",
    "       pl.col(\"measurement_datetime\").sort().slice(1, 1).first().cast(pl.Date).alias(\"hypercalcemia_2\")\n",
    "   )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ACE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ace_q = f\"\"\"\n",
    "WITH filtered_concepts AS (\n",
    "    SELECT DISTINCT concept_id, concept_code, concept_name\n",
    "    FROM {dataset}.concept c\n",
    "    WHERE vocabulary_id = 'LOINC'\n",
    "        AND (LOWER(concept_name) LIKE '%angiotensin converting enzyme%')\n",
    ")\n",
    "SELECT concept_name, concept_id, COUNT(measurement_id) AS count\n",
    "FROM {dataset}.measurement m\n",
    "LEFT JOIN filtered_concepts fc ON fc.concept_id = m.measurement_concept_id\n",
    "WHERE measurement_concept_id IN (SELECT concept_id FROM filtered_concepts) \n",
    "GROUP BY concept_name, concept_id\n",
    "ORDER BY count DESC\n",
    "LIMIT 5\n",
    "\"\"\"\n",
    "\n",
    "polars_gbq(ace_q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "measurement_cid = 3034780                    # OMOP measurement_concept_id \n",
    "\n",
    "test_concept_q = f\"\"\"\n",
    "SELECT DISTINCT\n",
    "    c.concept_name as lab_concept_name,\n",
    "    c.concept_id as lab_concept_id, \n",
    "    c.concept_code as lab_concept_code,\n",
    "    c.vocabulary_id as lab_vocab,\n",
    "    c1.concept_name as standard_unit,\n",
    "    count(measurement_id) AS count\n",
    "FROM {dataset}.measurement m\n",
    "JOIN {dataset}.concept c ON m.measurement_concept_id = c.concept_id\n",
    "JOIN {dataset}.concept c1 ON m.unit_concept_id = c1.concept_id\n",
    "WHERE c.concept_id = {measurement_cid}\n",
    "GROUP BY lab_concept_name, lab_concept_id, lab_concept_code, lab_vocab, standard_unit\n",
    "ORDER BY count DESC\n",
    "LIMIT 5\n",
    "\"\"\"\n",
    "\n",
    "polars_gbq(test_concept_q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "measurement_cid = 3034780                    # OMOP measurement_concept_id \n",
    "measurement_name = \"ace\"                     # Self-assigned measurement_name\n",
    "standard_unit = \"unit per liter\"             # Standard unit for the measurement\n",
    "min_value = 1                                # Minimum physiologic value which is feasible for the measurement\n",
    "max_value = 500                              # Maximum physiologic value which is feasible for the measurement\n",
    "group = \"sarcoid\"                            # Grouping of the measurement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "units = Mapper(measurement_cid = measurement_cid, \n",
    "               measurement_name = measurement_name,\n",
    "               standard_unit = standard_unit,\n",
    "               min_value = min_value,\n",
    "               max_value = max_value,\n",
    "               group = group,\n",
    "               cohort = cohort,\n",
    "               version=version,\n",
    "               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "units.metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "units.init_map()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "units.predominant_unit_histogram()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_unit = units.next_unit()    # .previous_unit() if user wants to return to the last unit\n",
    "units.unit_histogram()              # Display the histogram for the current unit_concept_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conversion_factor = 1      # conversion factor to convert to the standard unit\n",
    "multimodal = 0             # 1 if distribution is multimodal or 0 if not\n",
    "\n",
    "units.unit_update(current_unit, \n",
    "                  conversion_factor = conversion_factor, \n",
    "                  multimodal = multimodal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "units.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "measurement_cid = 3036335                    # OMOP measurement_concept_id \n",
    "\n",
    "test_concept_q = f\"\"\"\n",
    "SELECT DISTINCT\n",
    "    c.concept_name as lab_concept_name,\n",
    "    c.concept_id as lab_concept_id, \n",
    "    c.concept_code as lab_concept_code,\n",
    "    c.vocabulary_id as lab_vocab,\n",
    "    c1.concept_name as standard_unit,\n",
    "    count(measurement_id) AS count\n",
    "FROM {dataset}.measurement m\n",
    "JOIN {dataset}.concept c ON m.measurement_concept_id = c.concept_id\n",
    "JOIN {dataset}.concept c1 ON m.unit_concept_id = c1.concept_id\n",
    "WHERE c.concept_id = {measurement_cid}\n",
    "GROUP BY lab_concept_name, lab_concept_id, lab_concept_code, lab_vocab, standard_unit\n",
    "ORDER BY count DESC\n",
    "LIMIT 5\n",
    "\"\"\"\n",
    "\n",
    "polars_gbq(test_concept_q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "measurement_cid = 3036335                    # OMOP measurement_concept_id \n",
    "measurement_name = \"ace\"                     # Self-assigned measurement_name\n",
    "standard_unit = \"unit per liter\"             # Standard unit for the measurement\n",
    "min_value = 1                                # Minimum physiologic value which is feasible for the measurement\n",
    "max_value = 500                              # Maximum physiologic value which is feasible for the measurement\n",
    "group = \"sarcoid\"                            # Grouping of the measurement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "units = Mapper(measurement_cid = measurement_cid, \n",
    "               measurement_name = measurement_name,\n",
    "               standard_unit = standard_unit,\n",
    "               min_value = min_value,\n",
    "               max_value = max_value,\n",
    "               group = group,\n",
    "               cohort = cohort,\n",
    "               version=version,\n",
    "               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "units.metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "units.init_map()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "units.predominant_unit_histogram()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_unit = units.next_unit()    # .previous_unit() if user wants to return to the last unit\n",
    "units.unit_histogram()              # Display the histogram for the current unit_concept_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conversion_factor = 1      # conversion factor to convert to the standard unit\n",
    "multimodal = 0             # 1 if distribution is multimodal or 0 if not\n",
    "\n",
    "units.unit_update(current_unit, \n",
    "                  conversion_factor = conversion_factor, \n",
    "                  multimodal = multimodal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "units.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display annotated variables\n",
    "metadata = explorer.variables()\n",
    "metadata.filter(pl.col('measurement_name').str.contains('ace'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the unifier object\n",
    "measurement = Unifier(measurement_cid = 3036335, \n",
    "                      file_path = file_path,\n",
    "                      cohort = cohort,\n",
    "                      version = version,\n",
    "                      file_type = file_type,\n",
    "                      save_annotation = True, \n",
    "                      drop_sites = True)\n",
    "\n",
    "# Execute the unify() function to annotate and save measurements for the given measurement_cid\n",
    "measurement.unify()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ace_1_time_series = pl.read_parquet(f'{bucket}/data/allofus/C2024Q3R5/measurement_data/timeseries/timeseries_3036335.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the unifier object\n",
    "measurement = Unifier(measurement_cid = 3034780, \n",
    "                      file_path = file_path,\n",
    "                      cohort = cohort,\n",
    "                      version = version,\n",
    "                      file_type = file_type,\n",
    "                      save_annotation = True, \n",
    "                      drop_sites = True)\n",
    "\n",
    "# Execute the unify() function to annotate and save measurements for the given measurement_cid\n",
    "measurement.unify()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ace_2_time_series = pl.read_parquet(f'{bucket}/data/allofus/C2024Q3R5/measurement_data/timeseries/timeseries_3034780.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ace_time_series = pl.concat([ace_1_time_series, ace_2_time_series])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "elevated_ace_df = (\n",
    "   ace_time_series\n",
    "   .filter(pl.col(\"value_as_number\") > 65)\n",
    "   .group_by(\"person_id\")\n",
    "   .agg(\n",
    "       pl.col(\"measurement_datetime\").sort().first().cast(pl.Date).alias(\"elevated_ace_1\"),\n",
    "       pl.col(\"measurement_datetime\").sort().slice(1, 1).first().cast(pl.Date).alias(\"elevated_ace_2\")\n",
    "   )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alk Phos\n",
    "Elevated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata.filter(pl.col('measurement_name').str.contains('phosphatase'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the unifier object\n",
    "measurement = Unifier(measurement_cid = 3035995, \n",
    "                      file_path = file_path,\n",
    "                      cohort = cohort,\n",
    "                      version = version,\n",
    "                      file_type = file_type,\n",
    "                      save_annotation = True, \n",
    "                      drop_sites = True)\n",
    "\n",
    "# Execute the unify() function to annotate and save measurements for the given measurement_cid\n",
    "measurement.unify()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ap_time_series = pl.read_parquet(f'{bucket}/data/allofus/C2024Q3R5/measurement_data/timeseries/timeseries_3035995.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elevated_alk_phos_df = (\n",
    "   ap_time_series\n",
    "   .filter(pl.col(\"value_as_number\") > 147)\n",
    "   .group_by(\"person_id\")\n",
    "   .agg(\n",
    "       pl.col(\"measurement_datetime\").sort().first().cast(pl.Date).alias(\"elevated_ap_1\"),\n",
    "       pl.col(\"measurement_datetime\").sort().slice(1, 1).first().cast(pl.Date).alias(\"elevated_ap_2\")\n",
    "   )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1,25-OH vitamin D\n",
    "Deficiency of 25-hydroxyvitamin D is nearly universal among patients with sarcoidosis, although 1,25-dihydroxyvitamin D is sufficient in 70 percent.\n",
    "Granulomas make 1,25 OH D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ace_q = f\"\"\"\n",
    "WITH filtered_concepts AS (\n",
    "    SELECT DISTINCT concept_id, concept_code, concept_name\n",
    "    FROM {dataset}.concept c\n",
    "    WHERE vocabulary_id = 'LOINC'\n",
    "        AND (LOWER(concept_name) LIKE '%vitamin d%')\n",
    ")\n",
    "SELECT concept_name, concept_id, COUNT(measurement_id) AS count\n",
    "FROM {dataset}.measurement m\n",
    "LEFT JOIN filtered_concepts fc ON fc.concept_id = m.measurement_concept_id\n",
    "WHERE measurement_concept_id IN (SELECT concept_id FROM filtered_concepts) \n",
    "GROUP BY concept_name, concept_id\n",
    "ORDER BY count DESC\n",
    "LIMIT 5\n",
    "\"\"\"\n",
    "\n",
    "polars_gbq(ace_q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "measurement_cid = 40765040                    # OMOP measurement_concept_id \n",
    "\n",
    "test_concept_q = f\"\"\"\n",
    "SELECT DISTINCT\n",
    "    c.concept_name as lab_concept_name,\n",
    "    c.concept_id as lab_concept_id, \n",
    "    c.concept_code as lab_concept_code,\n",
    "    c.vocabulary_id as lab_vocab,\n",
    "    c1.concept_name as standard_unit,\n",
    "    count(measurement_id) AS count\n",
    "FROM {dataset}.measurement m\n",
    "JOIN {dataset}.concept c ON m.measurement_concept_id = c.concept_id\n",
    "JOIN {dataset}.concept c1 ON m.unit_concept_id = c1.concept_id\n",
    "WHERE c.concept_id = {measurement_cid}\n",
    "GROUP BY lab_concept_name, lab_concept_id, lab_concept_code, lab_vocab, standard_unit\n",
    "ORDER BY count DESC\n",
    "LIMIT 5\n",
    "\"\"\"\n",
    "\n",
    "polars_gbq(test_concept_q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "measurement_cid = 40765040                    # OMOP measurement_concept_id \n",
    "measurement_name = \"25-Hydroxyvitamin D3+25-Hydroxyvitamin D2\"                     # Self-assigned measurement_name\n",
    "standard_unit = \"nanogram per milliliter\"             # Standard unit for the measurement\n",
    "min_value = 0                                # Minimum physiologic value which is feasible for the measurement\n",
    "max_value = 250                              # Maximum physiologic value which is feasible for the measurement\n",
    "group = \"sarcoid\"                            # Grouping of the measurement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "units = Mapper(measurement_cid = measurement_cid, \n",
    "               measurement_name = measurement_name,\n",
    "               standard_unit = standard_unit,\n",
    "               min_value = min_value,\n",
    "               max_value = max_value,\n",
    "               group = group,\n",
    "               cohort = cohort,\n",
    "               version=version,\n",
    "               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "units.metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "units.init_map()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "units.predominant_unit_histogram()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_unit = units.next_unit()    # .previous_unit() if user wants to return to the last unit\n",
    "units.unit_histogram()              # Display the histogram for the current unit_concept_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conversion_factor = 1      # conversion factor to convert to the standard unit\n",
    "multimodal = 0             # 1 if distribution is multimodal or 0 if not\n",
    "\n",
    "units.unit_update(current_unit, \n",
    "                  conversion_factor = conversion_factor, \n",
    "                  multimodal = multimodal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "units.save(overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "measurement_cid = 3049536                    # OMOP measurement_concept_id \n",
    "\n",
    "test_concept_q = f\"\"\"\n",
    "SELECT DISTINCT\n",
    "    c.concept_name as lab_concept_name,\n",
    "    c.concept_id as lab_concept_id, \n",
    "    c.concept_code as lab_concept_code,\n",
    "    c.vocabulary_id as lab_vocab,\n",
    "    c1.concept_name as standard_unit,\n",
    "    count(measurement_id) AS count\n",
    "FROM {dataset}.measurement m\n",
    "JOIN {dataset}.concept c ON m.measurement_concept_id = c.concept_id\n",
    "JOIN {dataset}.concept c1 ON m.unit_concept_id = c1.concept_id\n",
    "WHERE c.concept_id = {measurement_cid}\n",
    "GROUP BY lab_concept_name, lab_concept_id, lab_concept_code, lab_vocab, standard_unit\n",
    "ORDER BY count DESC\n",
    "LIMIT 5\n",
    "\"\"\"\n",
    "\n",
    "polars_gbq(test_concept_q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "measurement_cid = 3049536                    # OMOP measurement_concept_id \n",
    "measurement_name = \"25-hydroxyvitamin D2\"                     # Self-assigned measurement_name\n",
    "standard_unit = \"nanogram per milliliter\"             # Standard unit for the measurement\n",
    "min_value = 0                                # Minimum physiologic value which is feasible for the measurement\n",
    "max_value = 250                              # Maximum physiologic value which is feasible for the measurement\n",
    "group = \"sarcoid\"                            # Grouping of the measurement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "units = Mapper(measurement_cid = measurement_cid, \n",
    "               measurement_name = measurement_name,\n",
    "               standard_unit = standard_unit,\n",
    "               min_value = min_value,\n",
    "               max_value = max_value,\n",
    "               group = group,\n",
    "               cohort = cohort,\n",
    "               version=version,\n",
    "               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "units.metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "units.init_map()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "units.predominant_unit_histogram()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_unit = units.next_unit()    # .previous_unit() if user wants to return to the last unit\n",
    "units.unit_histogram()              # Display the histogram for the current unit_concept_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conversion_factor = 0      # conversion factor to convert to the standard unit\n",
    "multimodal = 0             # 1 if distribution is multimodal or 0 if not\n",
    "\n",
    "units.unit_update(current_unit, \n",
    "                  conversion_factor = conversion_factor, \n",
    "                  multimodal = multimodal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "units.save(overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "measurement_cid = 40765038                    # OMOP measurement_concept_id \n",
    "\n",
    "test_concept_q = f\"\"\"\n",
    "SELECT DISTINCT\n",
    "    c.concept_name as lab_concept_name,\n",
    "    c.concept_id as lab_concept_id, \n",
    "    c.concept_code as lab_concept_code,\n",
    "    c.vocabulary_id as lab_vocab,\n",
    "    c1.concept_name as standard_unit,\n",
    "    count(measurement_id) AS count\n",
    "FROM {dataset}.measurement m\n",
    "JOIN {dataset}.concept c ON m.measurement_concept_id = c.concept_id\n",
    "JOIN {dataset}.concept c1 ON m.unit_concept_id = c1.concept_id\n",
    "WHERE c.concept_id = {measurement_cid}\n",
    "GROUP BY lab_concept_name, lab_concept_id, lab_concept_code, lab_vocab, standard_unit\n",
    "ORDER BY count DESC\n",
    "LIMIT 5\n",
    "\"\"\"\n",
    "\n",
    "polars_gbq(test_concept_q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "measurement_cid = 40765038                    # OMOP measurement_concept_id \n",
    "measurement_name = \"1,25-Dihydroxyvitamin D\"                     # Self-assigned measurement_name\n",
    "standard_unit = \"picogram per milliliter\"             # Standard unit for the measurement\n",
    "min_value = 0                                # Minimum physiologic value which is feasible for the measurement\n",
    "max_value = 250                              # Maximum physiologic value which is feasible for the measurement\n",
    "group = \"sarcoid\"                            # Grouping of the measurement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "units = Mapper(measurement_cid = measurement_cid, \n",
    "               measurement_name = measurement_name,\n",
    "               standard_unit = standard_unit,\n",
    "               min_value = min_value,\n",
    "               max_value = max_value,\n",
    "               group = group,\n",
    "               cohort = cohort,\n",
    "               version=version,\n",
    "               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "units.metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "units.init_map()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "units.predominant_unit_histogram()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_unit = units.next_unit()    # .previous_unit() if user wants to return to the last unit\n",
    "units.unit_histogram()              # Display the histogram for the current unit_concept_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conversion_factor = 1      # conversion factor to convert to the standard unit\n",
    "multimodal = 0             # 1 if distribution is multimodal or 0 if not\n",
    "\n",
    "units.unit_update(current_unit, \n",
    "                  conversion_factor = conversion_factor, \n",
    "                  multimodal = multimodal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "units.save(overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display annotated variables\n",
    "metadata = explorer.variables()\n",
    "metadata.filter(pl.col('measurement_name').str.contains('vitamin D'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the unifier object\n",
    "measurement = Unifier(measurement_cid = 40765038, \n",
    "                      file_path = file_path,\n",
    "                      cohort = cohort,\n",
    "                      version = version,\n",
    "                      file_type = file_type,\n",
    "                      save_annotation = True, \n",
    "                      drop_sites = True)\n",
    "\n",
    "# Execute the unify() function to annotate and save measurements for the given measurement_cid\n",
    "measurement.unify()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vitamin_d_125_time_series = pl.read_parquet(f'{bucket}/data/allofus/C2024Q3R5/measurement_data/timeseries/timeseries_40765038.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "high_1_25_vitamin_d_df = (\n",
    "   vitamin_d_125_time_series\n",
    "   .filter(pl.col(\"value_as_number\") > 78)\n",
    "   .group_by(\"person_id\")\n",
    "   .agg(\n",
    "       pl.col(\"measurement_datetime\").sort().first().cast(pl.Date).alias(\"high_1_25_d_1\"),\n",
    "       pl.col(\"measurement_datetime\").sort().slice(1, 1).first().cast(pl.Date).alias(\"high_1_25_d_2\")\n",
    "   )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://emedicine.medscape.com/article/2088672-overview#:~:text=Increased%201%2C25%2Ddihydroxyvitamin%20D,increases%20in%201%CE%B1%2Dhydroxylase%20activity.\n",
    "'> 78'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 25-OH vitamin D\n",
    "Vitamin D sufficiency is defined as a 25(OH)D concentration 20 ng/mL (50 nmol/L)<br>\n",
    "Vitamin D insufficiency is defined as a 25(OH)D concentration of 12 to <20 ng/mL (30 to 50 nmol/L)<br>\n",
    "Vitamin D deficiency is defined as a 25(OH)D level <12 ng/mL (30 nmol/L)<br>\n",
    "https://www.uptodate.com/contents/vitamin-d-deficiency-in-adults-definition-clinical-manifestations-and-treatment?search=vitamin%20d%20deficiency&source=search_result&selectedTitle=1~150&usage_type=default&display_rank=1#H2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display annotated variables\n",
    "metadata.filter(pl.col('measurement_name').str.contains('vitamin D'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the unifier object\n",
    "measurement = Unifier(measurement_cid = 3020149, \n",
    "                      file_path = file_path,\n",
    "                      cohort = cohort,\n",
    "                      version = version,\n",
    "                      file_type = file_type,\n",
    "                      save_annotation = True, \n",
    "                      drop_sites = True)\n",
    "\n",
    "# Execute the unify() function to annotate and save measurements for the given measurement_cid\n",
    "measurement.unify()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vid_d3_25_time_series = pl.read_parquet(f'{bucket}/data/allofus/C2024Q3R5/measurement_data/timeseries/timeseries_3020149.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the unifier object\n",
    "measurement = Unifier(measurement_cid = 3049536, \n",
    "                      file_path = file_path,\n",
    "                      cohort = cohort,\n",
    "                      version = version,\n",
    "                      file_type = file_type,\n",
    "                      save_annotation = True, \n",
    "                      drop_sites = True)\n",
    "\n",
    "# Execute the unify() function to annotate and save measurements for the given measurement_cid\n",
    "measurement.unify()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vid_d2_25_time_series = pl.read_parquet(f'{bucket}/data/allofus/C2024Q3R5/measurement_data/timeseries/timeseries_3049536.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the unifier object\n",
    "measurement = Unifier(measurement_cid = 40765040, \n",
    "                      file_path = file_path,\n",
    "                      cohort = cohort,\n",
    "                      version = version,\n",
    "                      file_type = file_type,\n",
    "                      save_annotation = True, \n",
    "                      drop_sites = True)\n",
    "\n",
    "# Execute the unify() function to annotate and save measurements for the given measurement_cid\n",
    "measurement.unify()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vid_d23_25_time_series = pl.read_parquet(f'{bucket}/data/allofus/C2024Q3R5/measurement_data/timeseries/timeseries_40765040.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add date column to both datasets\n",
    "vid_d2_25_time_series = vid_d2_25_time_series.with_columns(\n",
    "    pl.col(\"measurement_datetime\").dt.date().alias(\"measurement_date\")\n",
    ")\n",
    "\n",
    "vid_d3_25_time_series = vid_d3_25_time_series.with_columns(\n",
    "    pl.col(\"measurement_datetime\").dt.date().alias(\"measurement_date\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find same-day measurements for both D2 and D3\n",
    "vid_d23_same_day = (\n",
    "    vid_d2_25_time_series\n",
    "    .join(\n",
    "        vid_d3_25_time_series, \n",
    "        on=[\"person_id\", \"measurement_date\"], \n",
    "        how=\"inner\",\n",
    "        suffix=\"_d3\"\n",
    "    )\n",
    "    .with_columns([\n",
    "        (pl.col(\"value_as_number\") + pl.col(\"value_as_number_d3\")).alias(\"value_as_number\")\n",
    "    ])\n",
    "    .select([\n",
    "        \"person_id\", \n",
    "        \"measurement_date\",\n",
    "        \"value_as_number\",\n",
    "        \"measurement_datetime\",\n",
    "        \"src_id\",\n",
    "        \"standard_concept_name\", \n",
    "        \"measurement_name\",\n",
    "        \"unit\"\n",
    "    ])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vid_d23_25_time_series.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vitamin_d_combined = pl.concat([vid_d23_same_day.select('person_id', 'measurement_datetime',\n",
    "                                                       'value_as_number'),\n",
    "                                vid_d23_25_time_series.select('person_id', 'measurement_datetime',\n",
    "                                                       'value_as_number')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "low_25_vitamin_d_df = (\n",
    "   vitamin_d_combined\n",
    "   .filter(pl.col(\"value_as_number\") < 12)\n",
    "   .group_by(\"person_id\")\n",
    "   .agg(\n",
    "       pl.col(\"measurement_datetime\").sort().first().cast(pl.Date).alias(\"low_25_d_1\"),\n",
    "       pl.col(\"measurement_datetime\").sort().slice(1, 1).first().cast(pl.Date).alias(\"low_25_d_2\")\n",
    "   )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vitamin D Deficiency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vit_d_deficiency_dict = create_icd_dict_from_phecodes(phecodex_map, [\"EM_232.4\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vit_d_deficiency_codes_phecode_df = (aou.find_diagnosis_codes(\n",
    "    exact_codes=vit_d_deficiency_dict\n",
    ").execute_gbq())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vit_d_deficiency_codes_phecode_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find diagnoses by string\n",
    "vit_d_deficiency_codes_string_df = (aou.find_diagnosis_codes(\n",
    "    vocabularies=[\"ICD9CM\", \"ICD10CM\", \"SNOMED\"],\n",
    "    search_terms=[\"vitamin d deficiency\", 'rickets'],\n",
    "    exclude_terms=['hereditary', 'family history', 'familial']\n",
    ").execute_gbq())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vit_d_deficiency_code_df = (aou.person_code_df(\n",
    "    name=\"vit_d_deficiency\",\n",
    "    vocabularies=[\"ICD9CM\", \"ICD10CM\", \"SNOMED\"],\n",
    "    search_terms=[\"vitamin d deficiency\", 'rickets'],\n",
    "    exclude_terms=['hereditary', 'family history', 'familial'],\n",
    "    dates=True\n",
    ").execute_gbq())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ergocalciferol or cholecalciferol"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A1AT\n",
    "https://www.ncbi.nlm.nih.gov/books/NBK1519/#:~:text=Demonstration%20of%20Low%20Serum%20Concentration%20of%20the,with%20lung%20disease%20are%20usually%20%3C57%20mg/dL.\n",
    "Normal serum levels are 20-53 mol/L or approximately 100-220 mg/dL by nephelometry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a1at_q = f\"\"\"\n",
    "WITH filtered_concepts AS (\n",
    "    SELECT DISTINCT concept_id, concept_code, concept_name\n",
    "    FROM {dataset}.concept c\n",
    "    WHERE vocabulary_id = 'LOINC'\n",
    "        AND (LOWER(concept_name) LIKE '%alpha 1 antitrypsin%')\n",
    ")\n",
    "SELECT concept_name, concept_id, COUNT(measurement_id) AS count\n",
    "FROM {dataset}.measurement m\n",
    "LEFT JOIN filtered_concepts fc ON fc.concept_id = m.measurement_concept_id\n",
    "WHERE measurement_concept_id IN (SELECT concept_id FROM filtered_concepts) \n",
    "GROUP BY concept_name, concept_id\n",
    "ORDER BY count DESC\n",
    "LIMIT 5\n",
    "\"\"\"\n",
    "\n",
    "polars_gbq(a1at_q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "measurement_cid = 3026285                    # OMOP measurement_concept_id \n",
    "\n",
    "test_concept_q = f\"\"\"\n",
    "SELECT DISTINCT\n",
    "    c.concept_name as lab_concept_name,\n",
    "    c.concept_id as lab_concept_id, \n",
    "    c.concept_code as lab_concept_code,\n",
    "    c.vocabulary_id as lab_vocab,\n",
    "    c1.concept_name as standard_unit,\n",
    "    count(measurement_id) AS count\n",
    "FROM {dataset}.measurement m\n",
    "JOIN {dataset}.concept c ON m.measurement_concept_id = c.concept_id\n",
    "JOIN {dataset}.concept c1 ON m.unit_concept_id = c1.concept_id\n",
    "WHERE c.concept_id = {measurement_cid}\n",
    "GROUP BY lab_concept_name, lab_concept_id, lab_concept_code, lab_vocab, standard_unit\n",
    "ORDER BY count DESC\n",
    "LIMIT 5\n",
    "\"\"\"\n",
    "\n",
    "polars_gbq(test_concept_q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "measurement_cid = 3026285                    # OMOP measurement_concept_id \n",
    "measurement_name = \"a1at\"                     # Self-assigned measurement_name\n",
    "standard_unit = \"milligram per deciliter\"             # Standard unit for the measurement\n",
    "min_value = 0                                # Minimum physiologic value which is feasible for the measurement\n",
    "max_value = 500                              # Maximum physiologic value which is feasible for the measurement\n",
    "group = \"sarcoid\"                            # Grouping of the measurement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "units = Mapper(measurement_cid = measurement_cid, \n",
    "               measurement_name = measurement_name,\n",
    "               standard_unit = standard_unit,\n",
    "               min_value = min_value,\n",
    "               max_value = max_value,\n",
    "               group = group,\n",
    "               cohort = cohort,\n",
    "               version=version,\n",
    "               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "units.metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "units.init_map()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "units.predominant_unit_histogram()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_unit = units.next_unit()    # .previous_unit() if user wants to return to the last unit\n",
    "units.unit_histogram()              # Display the histogram for the current unit_concept_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conversion_factor = 0      # conversion factor to convert to the standard unit\n",
    "multimodal = 0             # 1 if distribution is multimodal or 0 if not\n",
    "\n",
    "units.unit_update(current_unit, \n",
    "                  conversion_factor = conversion_factor, \n",
    "                  multimodal = multimodal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "units.save(overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "measurement_cid = 3001127                    # OMOP measurement_concept_id \n",
    "\n",
    "test_concept_q = f\"\"\"\n",
    "SELECT DISTINCT\n",
    "    c.concept_name as lab_concept_name,\n",
    "    c.concept_id as lab_concept_id, \n",
    "    c.concept_code as lab_concept_code,\n",
    "    c.vocabulary_id as lab_vocab,\n",
    "    c1.concept_name as standard_unit,\n",
    "    count(measurement_id) AS count\n",
    "FROM {dataset}.measurement m\n",
    "JOIN {dataset}.concept c ON m.measurement_concept_id = c.concept_id\n",
    "JOIN {dataset}.concept c1 ON m.unit_concept_id = c1.concept_id\n",
    "WHERE c.concept_id = {measurement_cid}\n",
    "GROUP BY lab_concept_name, lab_concept_id, lab_concept_code, lab_vocab, standard_unit\n",
    "ORDER BY count DESC\n",
    "LIMIT 5\n",
    "\"\"\"\n",
    "\n",
    "polars_gbq(test_concept_q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "measurement_cid = 3001127                    # OMOP measurement_concept_id \n",
    "measurement_name = \"a1at\"                     # Self-assigned measurement_name\n",
    "standard_unit = \"gram per deciliter\"             # Standard unit for the measurement\n",
    "min_value = 0                                # Minimum physiologic value which is feasible for the measurement\n",
    "max_value = 500                              # Maximum physiologic value which is feasible for the measurement\n",
    "group = \"sarcoid\"                            # Grouping of the measurement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "units = Mapper(measurement_cid = measurement_cid, \n",
    "               measurement_name = measurement_name,\n",
    "               standard_unit = standard_unit,\n",
    "               min_value = min_value,\n",
    "               max_value = max_value,\n",
    "               group = group,\n",
    "               cohort = cohort,\n",
    "               version=version,\n",
    "               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "units.metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "units.init_map()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "units.predominant_unit_histogram()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_unit = units.next_unit()    # .previous_unit() if user wants to return to the last unit\n",
    "units.unit_histogram()              # Display the histogram for the current unit_concept_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conversion_factor = 1      # conversion factor to convert to the standard unit\n",
    "multimodal = 0             # 1 if distribution is multimodal or 0 if not\n",
    "\n",
    "units.unit_update(current_unit, \n",
    "                  conversion_factor = conversion_factor, \n",
    "                  multimodal = multimodal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "units.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display annotated variables\n",
    "metadata = explorer.variables()\n",
    "metadata.filter(pl.col('measurement_name').str.contains('a1at'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the unifier object\n",
    "measurement = Unifier(measurement_cid = 3001127, \n",
    "                      file_path = file_path,\n",
    "                      cohort = cohort,\n",
    "                      version = version,\n",
    "                      file_type = file_type,\n",
    "                      save_annotation = True, \n",
    "                      drop_sites = True)\n",
    "\n",
    "# Execute the unify() function to annotate and save measurements for the given measurement_cid\n",
    "measurement.unify()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a1at_1_time_series = pl.read_parquet(f'{bucket}/data/allofus/C2024Q3R5/measurement_data/timeseries/timeseries_3001127.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the unifier object\n",
    "measurement = Unifier(measurement_cid = 3026285, \n",
    "                      file_path = file_path,\n",
    "                      cohort = cohort,\n",
    "                      version = version,\n",
    "                      file_type = file_type,\n",
    "                      save_annotation = True, \n",
    "                      drop_sites = True)\n",
    "\n",
    "# Execute the unify() function to annotate and save measurements for the given measurement_cid\n",
    "measurement.unify()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a1at_2_time_series = pl.read_parquet(f'{bucket}/data/allofus/C2024Q3R5/measurement_data/timeseries/timeseries_3026285.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a1at_time_series = pl.concat([a1at_1_time_series, a1at_2_time_series])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a1at_time_series.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(data=a1at_time_series, x='value_as_number', hue='standard_concept_name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "high_a1at_df = (\n",
    "   a1at_time_series\n",
    "   .filter(pl.col(\"value_as_number\") > 220)\n",
    "   .group_by(\"person_id\")\n",
    "   .agg(\n",
    "       pl.col(\"measurement_datetime\").sort().first().cast(pl.Date).alias(\"high_a1at_1\"),\n",
    "       pl.col(\"measurement_datetime\").sort().slice(1, 1).first().cast(pl.Date).alias(\"high_a1at_2\")\n",
    "   )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## soluble IL-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sol_il2_q = f\"\"\"\n",
    "WITH filtered_concepts AS (\n",
    "    SELECT DISTINCT concept_id, concept_code, concept_name\n",
    "    FROM {dataset}.concept c\n",
    "    WHERE vocabulary_id = 'LOINC'\n",
    "        AND (LOWER(concept_name) LIKE '%interleukin 2%')\n",
    ")\n",
    "SELECT concept_name, concept_id, COUNT(measurement_id) AS count\n",
    "FROM {dataset}.measurement m\n",
    "LEFT JOIN filtered_concepts fc ON fc.concept_id = m.measurement_concept_id\n",
    "WHERE measurement_concept_id IN (SELECT concept_id FROM filtered_concepts) \n",
    "GROUP BY concept_name, concept_id\n",
    "ORDER BY count DESC\n",
    "LIMIT 5\n",
    "\"\"\"\n",
    "\n",
    "polars_gbq(sol_il2_q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "measurement_cid = 46235736                    # OMOP measurement_concept_id \n",
    "\n",
    "test_concept_q = f\"\"\"\n",
    "SELECT DISTINCT\n",
    "    c.concept_name as lab_concept_name,\n",
    "    c.concept_id as lab_concept_id, \n",
    "    c.concept_code as lab_concept_code,\n",
    "    c.vocabulary_id as lab_vocab,\n",
    "    c1.concept_name as standard_unit,\n",
    "    count(measurement_id) AS count\n",
    "FROM {dataset}.measurement m\n",
    "JOIN {dataset}.concept c ON m.measurement_concept_id = c.concept_id\n",
    "JOIN {dataset}.concept c1 ON m.unit_concept_id = c1.concept_id\n",
    "WHERE c.concept_id = {measurement_cid}\n",
    "GROUP BY lab_concept_name, lab_concept_id, lab_concept_code, lab_vocab, standard_unit\n",
    "ORDER BY count DESC\n",
    "LIMIT 5\n",
    "\"\"\"\n",
    "\n",
    "polars_gbq(test_concept_q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "measurement_cid = 46235736                    # OMOP measurement_concept_id \n",
    "measurement_name = \"soluble_il2\"                     # Self-assigned measurement_name\n",
    "standard_unit = \"picogram per milliliter\"             # Standard unit for the measurement\n",
    "min_value = 0                               # Minimum physiologic value which is feasible for the measurement\n",
    "max_value = 50000                              # Maximum physiologic value which is feasible for the measurement\n",
    "group = \"sarcoid\"                            # Grouping of the measurement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "units = Mapper(measurement_cid = measurement_cid, \n",
    "               measurement_name = measurement_name,\n",
    "               standard_unit = standard_unit,\n",
    "               min_value = min_value,\n",
    "               max_value = max_value,\n",
    "               group = group,\n",
    "               cohort = cohort,\n",
    "               version=version,\n",
    "               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "units.metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "units.init_map()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "units.predominant_unit_histogram()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_unit = units.next_unit()    # .previous_unit() if user wants to return to the last unit\n",
    "units.unit_histogram()              # Display the histogram for the current unit_concept_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conversion_factor = 1      # conversion factor to convert to the standard unit\n",
    "multimodal = 0             # 1 if distribution is multimodal or 0 if not\n",
    "\n",
    "units.unit_update(current_unit, \n",
    "                  conversion_factor = conversion_factor, \n",
    "                  multimodal = multimodal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "units.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display annotated variables\n",
    "metadata = explorer.variables()\n",
    "metadata.filter(pl.col('measurement_name').str.contains('soluble'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the unifier object\n",
    "measurement = Unifier(measurement_cid = 46235736, \n",
    "                      file_path = file_path,\n",
    "                      cohort = cohort,\n",
    "                      version = version,\n",
    "                      file_type = file_type,\n",
    "                      save_annotation = True, \n",
    "                      drop_sites = True)\n",
    "\n",
    "# Execute the unify() function to annotate and save measurements for the given measurement_cid\n",
    "measurement.unify()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soluble_il2_time_series = pl.read_parquet(f'{bucket}/data/allofus/C2024Q3R5/measurement_data/timeseries/timeseries_46235736.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(soluble_il2_time_series['value_as_number'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elevated_sil2_df = (\n",
    "   soluble_il2_time_series\n",
    "   .filter(pl.col(\"value_as_number\") > 1000)\n",
    "   .group_by(\"person_id\")\n",
    "   .agg(\n",
    "       pl.col(\"measurement_datetime\").sort().first().cast(pl.Date).alias(\"elevated_sil2_1\"),\n",
    "       pl.col(\"measurement_datetime\").sort().slice(1, 1).first().cast(pl.Date).alias(\"elevated_sil2_2\")\n",
    "   )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge Procedures and Labs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to select only person_id and columns ending with '_1'\n",
    "def select_columns_1(df):\n",
    "    # Get all columns that end with '_1'\n",
    "    cols_ending_with_1 = [col for col in df.columns if col.endswith('_1')]\n",
    "    # Return dataframe with only person_id and those columns\n",
    "    if cols_ending_with_1:\n",
    "        return df.select(['person_id'] + cols_ending_with_1)\n",
    "    else:\n",
    "        return df.select('person_id')\n",
    "    \n",
    "def select_columns_2(df):\n",
    "    # Get all columns that end with '_1'\n",
    "    cols_ending_with_1 = [col for col in df.columns if col.endswith('_1')]\n",
    "    # Return dataframe with only person_id and those columns\n",
    "    if cols_ending_with_1:\n",
    "        return df.select(['person_id'] + cols_ending_with_1)\n",
    "    else:\n",
    "        return df.select('person_id')\n",
    "\n",
    "# Apply the function to each dataframe before merging\n",
    "cxr_filtered = select_columns_1(cxr_df)\n",
    "\n",
    "# List of all dataframes to merge (filtered)\n",
    "dfs_to_merge_filtered = [\n",
    "    select_columns_1(ct_chest_df),\n",
    "    select_columns_1(pulmonary_biopsy_df),\n",
    "    select_columns_1(non_pulmonary_biopsy_df),\n",
    "    select_columns_1(pft_df),\n",
    "    select_columns_1(ecg_df),\n",
    "    select_columns_1(leukopenia_df),\n",
    "    select_columns_1(thrombocytopenia_df),\n",
    "    select_columns_1(pbe_df),\n",
    "    select_columns_1(hypercalcemia_df),\n",
    "    select_columns_1(elevated_ace_df),\n",
    "    select_columns_1(elevated_alk_phos_df),\n",
    "    select_columns_1(low_25_vitamin_d_df),\n",
    "    select_columns_1(high_1_25_vitamin_d_df),\n",
    "    select_columns_2(vit_d_deficiency_code_df),\n",
    "    select_columns_1(high_a1at_df),\n",
    "    select_columns_1(elevated_sil2_df)\n",
    "]\n",
    "\n",
    "# Start with the first filtered dataframe\n",
    "procedure_df = cxr_filtered\n",
    "\n",
    "# Merge each filtered dataframe one by one\n",
    "for df in dfs_to_merge_filtered:\n",
    "    procedure_df = procedure_df.join(df, on='person_id', how='full', coalesce=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "procedure_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "procedure_df.write_csv(f'{bucket}/data/cohorts/all_procedures.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exclude Sarcoid Patients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sarcoid_final_df = sarcoid_df.filter(pl.col('sarcoid_n')>0).select('person_id', 'sarcoid_n', 'vocab', 'sarcoid_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Left join to merge exclusion conditions with sarcoid patients\n",
    "sarcoid_with_exclusions = sarcoid_final_df.join(\n",
    "    exclude_df,\n",
    "    on='person_id',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Create a new column drug_2 based on the exclusion_drug date and our logic\n",
    "sarcoid_with_exclusions = sarcoid_with_exclusions.with_columns(\n",
    "    drug_2=pl.when(\n",
    "        (pl.col('exclusion_drug').is_not_null()) & \n",
    "        (pl.col('exclusion_drug') < (pl.col('sarcoid_1') + pl.duration(days=365)))\n",
    "    )\n",
    "    .then(pl.col('exclusion_drug'))\n",
    "    .otherwise(None)\n",
    ")\n",
    "\n",
    "# Drop the original exclusion_drug column\n",
    "sarcoid_with_exclusions = sarcoid_with_exclusions.drop('exclusion_drug')\n",
    "\n",
    "# Create the has_exclusion_condition flag using all exclusion columns including the new drug_2\n",
    "exclusion_cols = [c for c in sarcoid_with_exclusions.columns \n",
    "                  if c != 'person_id' and c.endswith('_2')]\n",
    "\n",
    "# Set the has_exclusion_condition flag\n",
    "sarcoid_with_exclusions = sarcoid_with_exclusions.with_columns(\n",
    "    has_exclusion_condition=pl.any_horizontal([\n",
    "        pl.col(col).is_not_null() for col in exclusion_cols\n",
    "    ])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from upsetplot import plot\n",
    "from upsetplot import from_memberships\n",
    "from upsetplot import from_contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create binary indicators for each exclusion condition\n",
    "exclusion_cols = [col for col in sarcoid_with_exclusions.columns \n",
    "                  if col.endswith('_2')]\n",
    "\n",
    "# Convert to pandas for UpSetPlot\n",
    "pandas_df = sarcoid_with_exclusions.to_pandas()\n",
    "\n",
    "# Create a list of sets where each set contains person_ids that have a specific condition\n",
    "sets = {}\n",
    "for col in exclusion_cols:\n",
    "    condition = col.replace('_2', '')\n",
    "    # Get person_ids for patients with this condition\n",
    "    person_ids = pandas_df.loc[pandas_df[col].notnull(), 'person_id'].tolist()\n",
    "    sets[condition] = set(person_ids)  # Using set for efficiency\n",
    "\n",
    "# Create a list of memberships (each entry represents a patient's conditions)\n",
    "memberships = []\n",
    "for _, row in pandas_df.iterrows():\n",
    "    patient_conditions = []\n",
    "    for col in exclusion_cols:\n",
    "        if pd.notnull(row[col]):\n",
    "            condition = col.replace('_2', '')\n",
    "            patient_conditions.append(condition)\n",
    "    memberships.append(patient_conditions)\n",
    "\n",
    "# Create data for UpSetPlot using the correct syntax\n",
    "membership_data = from_memberships(memberships)\n",
    "\n",
    "plt.rcParams.update({'font.size': 12})  # General font size\n",
    "\n",
    "# Create the UpSet plot\n",
    "plot(membership_data, subset_size=\"count\", sort_by='cardinality', \n",
    "     sort_categories_by='-cardinality', \n",
    "     max_subset_rank=20,\n",
    "     show_counts=True,\n",
    "    )\n",
    "plt.title('')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list to store results\n",
    "count_data = []\n",
    "\n",
    "# Calculate counts for each exclusion condition\n",
    "for col in exclusion_cols:\n",
    "    condition_name = col.replace('_2', '')\n",
    "    # Count non-null values\n",
    "    count = sarcoid_with_exclusions.filter(pl.col(col).is_not_null()).height\n",
    "    count_data.append({\"condition\": condition_name, \"count\": count})\n",
    "\n",
    "# Convert to dataframe\n",
    "exclusion_counts = pl.DataFrame(count_data)\n",
    "\n",
    "# Sort by count in descending order\n",
    "exclusion_counts = exclusion_counts.sort(\"count\", descending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exclusion_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Describe Sarcoid Exclusion Cohort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sarcoid_without_exclusions = sarcoid_with_exclusions.filter(~pl.col('has_exclusion_condition')).select(['person_id', 'sarcoid_n', 'vocab', 'sarcoid_1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sns.color_palette(\"colorblind\").as_hex())\n",
    "sns.color_palette(\"colorblind\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming you're working with both dataframes\n",
    "df = sarcoid_df.to_pandas()\n",
    "df_without_exclusions = sarcoid_without_exclusions.to_pandas()\n",
    "\n",
    "# Create a figure with subplots\n",
    "fig = plt.figure(figsize=(10, 5))\n",
    "\n",
    "# 1. Histogram of sarcoid_n with percentage annotation\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.histplot(data=df, x='sarcoid_n', binwidth=1, color='#0173b2', kde=True)\n",
    "plt.xlim(0, 75)\n",
    "plt.title('Distribution of Sarcoid Counts per Person', fontsize=12)\n",
    "plt.xlabel('Sarcoid Count')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "# Calculate percentage of data within the x-limits\n",
    "total_rows = len(df)\n",
    "rows_in_range = len(df[df['sarcoid_n'] <= 75])\n",
    "percentage = (rows_in_range / total_rows) * 100\n",
    "\n",
    "# Add percentage annotation to top right\n",
    "plt.annotate(f'{percentage:.1f}% of data', \n",
    "             xy=(0.95, 0.95), \n",
    "             xycoords='axes fraction',\n",
    "             ha='right', va='top',\n",
    "             bbox=dict(boxstyle='round', fc='white', alpha=0.8))\n",
    "\n",
    "# Remove top and right spines\n",
    "sns.despine(ax=plt.gca())\n",
    "\n",
    "plt.gca().tick_params(which='major', width=1, left=True, bottom=True, color='#999', grid_alpha=0.2)\n",
    "\n",
    "# 2. Bar plot of counts per year from sarcoid_1 with improved x-axis\n",
    "plt.subplot(1, 2, 2)\n",
    "# Extract year from sarcoid_1 dates\n",
    "df_without_exclusions['year'] = pd.to_datetime(df_without_exclusions['sarcoid_1']).dt.year\n",
    "\n",
    "# Create empty dataframe with all years from 1982 to 2023\n",
    "all_years = pd.DataFrame({'year': range(1982, 2024)})\n",
    "year_counts = df_without_exclusions['year'].value_counts().reset_index()\n",
    "year_counts.columns = ['year', 'count']\n",
    "\n",
    "# Merge to ensure all years are represented\n",
    "complete_years = all_years.merge(year_counts, on='year', how='left').fillna(0)\n",
    "complete_years = complete_years.sort_values('year')\n",
    "\n",
    "# Plot the bar chart\n",
    "plt.bar(complete_years['year'], complete_years['count'], color='#0173b2', alpha=0.7)\n",
    "plt.title('Sarcoidosis Cases by Year', fontsize=12)\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Number of Cases')\n",
    "\n",
    "# Set up x-axis ticks\n",
    "plt.xticks(np.arange(1985, 2024, 5), rotation=45)\n",
    "plt.xlim(1981.5, 2023.5)\n",
    "\n",
    "# Remove top and right spines\n",
    "sns.despine(ax=plt.gca())\n",
    "plt.gca().tick_params(which='major', width=1, left=True, bottom=True, color='#999', grid_alpha=0.2)\n",
    "\n",
    "plt.minorticks_on()\n",
    "plt.gca().tick_params(which='minor', width=0.5, bottom=True, color='#999', grid_alpha=0.2)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = sarcoid_df.to_pandas()\n",
    "\n",
    "# UpSet plot of vocab\n",
    "# First, create binary indicators for each vocab category\n",
    "vocab_categories = [\"9\", \"10\", \"SNO\"]\n",
    "\n",
    "# Create dictionary of sets for each category\n",
    "vocab_dict = {}\n",
    "for category in vocab_categories:\n",
    "    # Find patients with this category in their vocab\n",
    "    vocab_dict[category] = set(df[df['vocab'].str.contains(category, na=False)]['person_id'])\n",
    "\n",
    "# Create memberships list for UpSet plot\n",
    "memberships = []\n",
    "for _, row in df.iterrows():\n",
    "    if pd.isna(row['vocab']):\n",
    "        memberships.append([])\n",
    "        continue\n",
    "        \n",
    "    patient_vocabs = []\n",
    "    for category in vocab_categories:\n",
    "        if category in str(row['vocab']):\n",
    "            patient_vocabs.append(category)\n",
    "    memberships.append(patient_vocabs)\n",
    "\n",
    "membership_data = from_memberships(memberships)\n",
    "\n",
    "# Create the UpSet plot\n",
    "\n",
    "fig = plt.figure(figsize=(5, 5))\n",
    "plot(membership_data, subset_size=\"count\", sort_by='cardinality', \n",
    "     sort_categories_by='-cardinality', \n",
    "     max_subset_rank=20,\n",
    "     show_counts=True,\n",
    "    )\n",
    "plt.title('')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add Covariates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_sarcoid_cases = sarcoid_with_exclusions.select(['person_id', 'sarcoid_n', 'vocab', 'sarcoid_1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sarcoid_cases_without_exclusions = sarcoid_without_exclusions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_person_ids_str = ', '.join(all_sarcoid_cases['person_id'].cast(pl.Utf8).to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_q = f\"\"\"\n",
    "SELECT MAX(observation_date)\n",
    "FROM {dataset}.observation\n",
    "\"\"\"\n",
    "\n",
    "polars_gbq(test_q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heart rate rhythm, Heart rate, Blood pressure panel, Adult Waist Circumference Protocol, PhenX - hip circumference protocol 020801\n",
    "# Body height, Body weight, Diastolic blood pressure, Systolic blood pressure, Body mass index (BMI) [Ratio], Body weight Measured --pre pregnancy\n",
    "vitals_exclusion = [3022318, 3027018, 3031203, 40759207, 40765148, 3036277, 3025315, 3012888, 3004249, 3038553, 3022281]\n",
    "vitals_exclusion_str = ', '.join(map(str, vitals_exclusion))\n",
    "\n",
    "# unique person_id w/ ICD or SNOMED in source_ values in observation/condition_occurrence\n",
    "distinct_participants_cte = f\"\"\"\n",
    "WITH distinct_participants AS (\n",
    "    SELECT DISTINCT o.person_id\n",
    "    FROM {dataset}.observation AS o\n",
    "    JOIN {dataset}.concept AS c \n",
    "        ON o.observation_source_value = c.concept_code\n",
    "        OR o.observation_source_concept_id = c.concept_id\n",
    "    WHERE c.vocabulary_id IN ('ICD9CM', 'ICD10CM', 'SNOMED')\n",
    "\n",
    "    UNION DISTINCT\n",
    "    \n",
    "    SELECT DISTINCT co.person_id\n",
    "    FROM {dataset}.condition_occurrence AS co\n",
    "    JOIN {dataset}.concept AS c \n",
    "        ON co.condition_source_value = c.concept_code\n",
    "        OR co.condition_source_concept_id = c.concept_id\n",
    "    WHERE c.vocabulary_id IN ('ICD9CM', 'ICD10CM', 'SNOMED')\n",
    ")\n",
    "\"\"\"\n",
    "\n",
    "total_ehr_q = f\"\"\"\n",
    "{distinct_participants_cte}\n",
    "SELECT person_id\n",
    "FROM distinct_participants\n",
    "ORDER BY person_id\n",
    "\"\"\"\n",
    "\n",
    "total_ehr_df = polars_gbq(total_ehr_q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_ehr_df.height\n",
    "# ICD only: 350,427\n",
    "# ICD + SNOMED: 358,180"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here, end_of_study_age is age at death, or age at end of study period ()\n",
    "demographics_q = f\"\"\"\n",
    "{distinct_participants_cte}\n",
    "SELECT DISTINCT\n",
    "    p.person_id,\n",
    "    CAST(p.birth_datetime AS DATE) AS dob,\n",
    "    p_race_concept.concept_name as race,\n",
    "    p_ethnicity_concept.concept_name as ethnicity,\n",
    "    p_sex_at_birth_concept.concept_name as sex_at_birth,\n",
    "    p_gender_concept.concept_name as gender,\n",
    "    DATETIME_DIFF(\n",
    "                IF(DATETIME(death_datetime) IS NULL, DATETIME('2023-10-01'), DATETIME(death_datetime)), \n",
    "                DATETIME(birth_datetime), \n",
    "                DAY\n",
    "            )/365.2425 AS end_of_study_age\n",
    "FROM\n",
    "    {dataset}.person p\n",
    "LEFT JOIN\n",
    "    {dataset}.concept p_gender_concept \n",
    "        ON p.gender_concept_id = p_gender_concept.concept_id \n",
    "LEFT JOIN\n",
    "    {dataset}.concept p_race_concept \n",
    "        ON p.race_concept_id = p_race_concept.concept_id \n",
    "LEFT JOIN\n",
    "    {dataset}.concept p_ethnicity_concept \n",
    "        ON p.ethnicity_concept_id = p_ethnicity_concept.concept_id \n",
    "LEFT JOIN\n",
    "    {dataset}.concept p_sex_at_birth_concept \n",
    "        ON p.sex_at_birth_concept_id = p_sex_at_birth_concept.concept_id  \n",
    "LEFT JOIN\n",
    "    {dataset}.death d\n",
    "        ON p.person_id = d.person_id\n",
    "WHERE\n",
    "    p.person_id IN (SELECT person_id FROM distinct_participants)\n",
    "\"\"\"\n",
    "\n",
    "demographics_df = polars_gbq(demographics_q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = {\n",
    "    \"None of these\": \"None\",\n",
    "    \"I prefer not to answer\": \"PNA\",\n",
    "    \"Black or African American\": \"Black\",\n",
    "    \"PMI: Skip\": \"Skip\",\n",
    "    \"More than one population\": \"Multip\",\n",
    "    \"Asian\": \"Asian\",\n",
    "    \"Native Hawaiian or Other Pacific Islander\": \"NHPI\",\n",
    "    \"None Indicated\": \"NoInd\",\n",
    "    \"White\": \"White\",\n",
    "    \"Middle Eastern or North African\": \"MENA\",\n",
    "    \"American Indian or Alaska Native\": \"AIAN\"\n",
    "}\n",
    "demographics_df = demographics_df.with_columns(\n",
    "    pl.col(\"race\").map_elements(lambda x: mapping.get(x, x), return_dtype=pl.Utf8)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = {\n",
    "    \"PMI: Prefer Not To Answer\": \"PNA\",\n",
    "    \"No matching concept\": \"NoMatch\",\n",
    "    \"What Race Ethnicity: Race Ethnicity None Of These\": \"None\",\n",
    "    \"Not Hispanic or Latino\": \"NotHisp\",\n",
    "    \"PMI: Skip\": \"Skip\",\n",
    "    \"Hispanic or Latino\": \"HispLat\",\n",
    "}\n",
    "demographics_df = demographics_df.with_columns(\n",
    "    pl.col(\"ethnicity\").map_elements(lambda x: mapping.get(x, x), return_dtype=pl.Utf8)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = {\n",
    "    \"I prefer not to answer\": \"PNA\",\n",
    "    \"No matching concept\": \"NoMatch\",\n",
    "    \"Male\": \"Male\",\n",
    "    \"Intersex\": \"Intersex\",\n",
    "    \"Female\": \"Female\",\n",
    "    \"PMI: Skip\": \"Skip\",\n",
    "    \"None\": \"None\"\n",
    "}\n",
    "demographics_df = demographics_df.with_columns(\n",
    "    pl.col(\"sex_at_birth\").map_elements(lambda x: mapping.get(x, x), return_dtype=pl.Utf8)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppi_employment_q = f\"\"\"\n",
    "{distinct_participants_cte},\n",
    "categorized AS (\n",
    "    SELECT \n",
    "        obs.person_id,\n",
    "        CASE\n",
    "            WHEN obs.value_source_concept_id = 1585960 THEN 'disabled'\n",
    "            WHEN obs.value_source_concept_id IN (1585953, 1585954) THEN 'employed'\n",
    "            WHEN obs.value_source_concept_id = 1585959 THEN 'retired'\n",
    "            WHEN obs.value_source_concept_id = 1585958 THEN 'student'\n",
    "            WHEN obs.value_source_concept_id = 1585957 THEN 'homemaker'\n",
    "            WHEN obs.value_source_concept_id IN (1585955, 1585956) THEN 'out of work'\n",
    "            WHEN obs.value_source_concept_id IN (903079, 903096) THEN 'unk_skip'\n",
    "        END AS employ,\n",
    "        CASE\n",
    "            WHEN obs.value_source_concept_id = 1585960 THEN 1\n",
    "            WHEN obs.value_source_concept_id IN (1585953, 1585954) THEN 2\n",
    "            WHEN obs.value_source_concept_id = 1585959 THEN 3\n",
    "            WHEN obs.value_source_concept_id = 1585958 THEN 4\n",
    "            WHEN obs.value_source_concept_id = 1585957 THEN 5\n",
    "            WHEN obs.value_source_concept_id IN (1585955, 1585956) THEN 6\n",
    "            WHEN obs.value_source_concept_id IN (903079, 903096) THEN 7\n",
    "        END AS priority\n",
    "    FROM \n",
    "        {dataset}.observation AS obs\n",
    "    WHERE \n",
    "        obs.observation_source_concept_id IN (1585952)\n",
    "        AND obs.person_id IN (SELECT person_id FROM distinct_participants)\n",
    "),\n",
    "ranked AS (\n",
    "    SELECT\n",
    "        person_id,\n",
    "        employ,\n",
    "        ROW_NUMBER() OVER (PARTITION BY person_id ORDER BY priority) AS rank\n",
    "    FROM \n",
    "        categorized\n",
    ")\n",
    "SELECT \n",
    "    person_id,\n",
    "    employ\n",
    "FROM \n",
    "    ranked\n",
    "WHERE \n",
    "    rank = 1\n",
    "\"\"\"\n",
    "\n",
    "ppi_employment_df = polars_gbq(ppi_employment_q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demographics_df = demographics_df.join(\n",
    "    ppi_employment_df, \n",
    "    on='person_id',\n",
    "    how='left' \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppi_income_q = f\"\"\"\n",
    "{distinct_participants_cte},\n",
    "categorized AS (\n",
    "    SELECT \n",
    "        obs.person_id,\n",
    "        CASE\n",
    "            WHEN obs.value_source_concept_id = 1585960 THEN 'disabled'\n",
    "            WHEN obs.value_source_concept_id = 1585376 THEN 'less_10'\n",
    "            WHEN obs.value_source_concept_id = 1585377 THEN '10_25'\n",
    "            WHEN obs.value_source_concept_id = 1585378 THEN '25_35'\n",
    "            WHEN obs.value_source_concept_id = 1585379 THEN '35_50'\n",
    "            WHEN obs.value_source_concept_id = 1585380 THEN '50_75'\n",
    "            WHEN obs.value_source_concept_id = 1585381 THEN '75_100'\n",
    "            WHEN obs.value_source_concept_id = 1585382 THEN '100_150'\n",
    "            WHEN obs.value_source_concept_id = 1585383 THEN '150_200'\n",
    "            WHEN obs.value_source_concept_id = 1585384 THEN '200_more'\n",
    "            WHEN obs.value_source_concept_id IN (903079, 903096) THEN 'skip'\n",
    "        END AS income,\n",
    "    FROM \n",
    "        {dataset}.observation AS obs\n",
    "    WHERE \n",
    "        obs.observation_source_concept_id IN (1585375)\n",
    "        AND obs.person_id IN (SELECT person_id FROM distinct_participants)\n",
    ")\n",
    "SELECT \n",
    "    person_id,\n",
    "    income\n",
    "FROM \n",
    "    categorized\n",
    "\"\"\"\n",
    "\n",
    "ppi_income_df = polars_gbq(ppi_income_q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demographics_df = demographics_df.join(\n",
    "    ppi_income_df, \n",
    "    on='person_id',\n",
    "    how='left' \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppi_edu_q = f\"\"\"\n",
    "{distinct_participants_cte},\n",
    "categorized AS (\n",
    "    SELECT \n",
    "        obs.person_id,\n",
    "        CASE\n",
    "        WHEN obs.value_source_concept_id = 1585941 THEN 'none'\n",
    "        WHEN obs.value_source_concept_id = 1585942 THEN '1_4'\n",
    "        WHEN obs.value_source_concept_id = 1585943 THEN '5_8'\n",
    "        WHEN obs.value_source_concept_id = 1585944 THEN '9_11'\n",
    "        WHEN obs.value_source_concept_id = 1585945 THEN '12_GED'\n",
    "        WHEN obs.value_source_concept_id = 1585946 THEN 'coll_1_3'\n",
    "        WHEN obs.value_source_concept_id = 1585947 THEN 'coll_grad'\n",
    "        WHEN obs.value_source_concept_id = 1585948 THEN 'adv_degree'\n",
    "        WHEN obs.value_source_concept_id IN (903079, 903096) THEN 'skip'\n",
    "        END AS edu,\n",
    "    FROM \n",
    "        {dataset}.observation AS obs\n",
    "    WHERE \n",
    "        obs.observation_source_concept_id IN (1585940)\n",
    "        AND obs.person_id IN (SELECT person_id FROM distinct_participants)\n",
    ")\n",
    "SELECT \n",
    "    person_id,\n",
    "    edu\n",
    "FROM \n",
    "    categorized\n",
    "\"\"\"\n",
    "\n",
    "ppi_edu_df = polars_gbq(ppi_edu_q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demographics_df = demographics_df.join(\n",
    "    ppi_edu_df, \n",
    "    on='person_id',\n",
    "    how='left' \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppi_ins_q = f\"\"\"\n",
    "{distinct_participants_cte},\n",
    "categorized AS (\n",
    "    SELECT \n",
    "        obs.person_id,\n",
    "        CASE\n",
    "        WHEN obs.value_source_concept_id = 1585387 THEN '1'\n",
    "        WHEN obs.value_source_concept_id = 1585388 THEN '0'\n",
    "        WHEN obs.value_source_concept_id IN (903096, 903087, 903079) THEN '-9'\n",
    "        END AS ins,\n",
    "    FROM \n",
    "        {dataset}.observation AS obs\n",
    "    WHERE \n",
    "        obs.observation_source_concept_id IN (1585386)\n",
    "        AND obs.person_id IN (SELECT person_id FROM distinct_participants)\n",
    ")\n",
    "SELECT \n",
    "    person_id,\n",
    "    ins\n",
    "FROM \n",
    "    categorized\n",
    "\"\"\"\n",
    "\n",
    "ppi_ins_df = polars_gbq(ppi_ins_q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppi_ins_type_q = f\"\"\"\n",
    "{distinct_participants_cte},\n",
    "categorized AS (\n",
    "    SELECT \n",
    "        obs.person_id,\n",
    "        CASE\n",
    "            WHEN obs.value_source_concept_id = 43529209 THEN 'medicaid'\n",
    "            WHEN obs.value_source_concept_id = 43529926 THEN 'va'\n",
    "            WHEN obs.value_source_concept_id = 43529920 THEN 'military'\n",
    "            WHEN obs.value_source_concept_id = 43529111 THEN 'ihs'\n",
    "            WHEN obs.value_source_concept_id = 43529210 THEN 'medicare'\n",
    "            WHEN obs.value_source_concept_id = 43529120 THEN 'emp'\n",
    "            WHEN obs.value_source_concept_id = 43529119 THEN 'purchased'\n",
    "            WHEN obs.value_source_concept_id = 43528423 THEN 'other'\n",
    "            WHEN obs.value_source_concept_id = 43529095 THEN 'none'\n",
    "            WHEN obs.value_source_concept_id IN (903096, 46237613) THEN '-9'\n",
    "        END AS ins_type,\n",
    "        CASE\n",
    "            WHEN obs.value_source_concept_id = 43529209 THEN 1\n",
    "            WHEN obs.value_source_concept_id = 43529926 THEN 2\n",
    "            WHEN obs.value_source_concept_id = 43529920 THEN 3\n",
    "            WHEN obs.value_source_concept_id = 43529111 THEN 4\n",
    "            WHEN obs.value_source_concept_id = 43529210 THEN 5\n",
    "            WHEN obs.value_source_concept_id = 43529120 THEN 6\n",
    "            WHEN obs.value_source_concept_id = 43529119 THEN 7\n",
    "            WHEN obs.value_source_concept_id = 43528423 THEN 8\n",
    "            WHEN obs.value_source_concept_id = 43529095 THEN 0\n",
    "            WHEN obs.value_source_concept_id IN (903096, 46237613) THEN 7\n",
    "        END AS priority\n",
    "    FROM \n",
    "        {dataset}.observation AS obs\n",
    "    WHERE \n",
    "        obs.observation_source_concept_id IN (43528428)\n",
    "        AND obs.person_id IN (SELECT person_id FROM distinct_participants)\n",
    "),\n",
    "ranked AS (\n",
    "    SELECT\n",
    "        person_id,\n",
    "        ins_type,\n",
    "        ROW_NUMBER() OVER (PARTITION BY person_id ORDER BY priority) AS rank\n",
    "    FROM \n",
    "        categorized\n",
    ")\n",
    "SELECT \n",
    "    person_id,\n",
    "    ins_type\n",
    "FROM \n",
    "    ranked\n",
    "WHERE \n",
    "    rank = 1\n",
    "\"\"\"\n",
    "\n",
    "ppi_ins_type_df = polars_gbq(ppi_ins_type_q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppi_ins_df = ppi_ins_df.join(\n",
    "    ppi_ins_type_df, \n",
    "    on='person_id',\n",
    "    how='full', coalesce=True \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppi_ins_df = ppi_ins_df.with_columns(\n",
    "    pl.when((pl.col('ins') == '-9') & (pl.col('ins_type').is_not_null()) & (pl.col('ins_type') == 'none'))\n",
    "    .then(0)\n",
    "    .when((pl.col('ins') == '-9') & (pl.col('ins_type').is_not_null()) & (pl.col('ins_type') != '-9'))\n",
    "    .then(1)\n",
    "    .otherwise(pl.col('ins'))\n",
    "    .alias('ins')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demographics_df = demographics_df.join(\n",
    "    ppi_ins_df, \n",
    "    on='person_id',\n",
    "    how='left' \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# total (ICD): 350,427\n",
    "# total (ICD/SNOMED): 358,180\n",
    "demographics_df.null_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demographics_df = demographics_df.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demographics_df[['race', 'ethnicity']].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demographics_df = pl.from_pandas(demographics_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_sarcoid_cases = all_sarcoid_cases.with_columns(\n",
    "    pl.lit(1).alias('case')\n",
    ")\n",
    "sarcoid_cases_without_exclusions = sarcoid_cases_without_exclusions.with_columns(\n",
    "    pl.lit(1).alias('case')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_sarcoid_cases = demographics_df.join(\n",
    "    all_sarcoid_cases,\n",
    "    on='person_id',\n",
    "    how='left'\n",
    ")\n",
    "sarcoid_cases_without_exclusions = demographics_df.join(\n",
    "    sarcoid_cases_without_exclusions,\n",
    "    on='person_id',\n",
    "    how='left'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_sarcoid_cases = all_sarcoid_cases.with_columns(\n",
    "    (\n",
    "        (pl.col(\"sarcoid_1\") - pl.col(\"dob\")).dt.total_days() / 365.25\n",
    "    ).alias(\"age_at_diagnosis\")\n",
    ")\n",
    "sarcoid_cases_without_exclusions = sarcoid_cases_without_exclusions.with_columns(\n",
    "    (\n",
    "        (pl.col(\"sarcoid_1\") - pl.col(\"dob\")).dt.total_days() / 365.25\n",
    "    ).alias(\"age_at_diagnosis\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_sarcoid_cases = all_sarcoid_cases.with_columns(\n",
    "    pl.col('case').fill_null(0)\n",
    ")\n",
    "sarcoid_cases_without_exclusions = sarcoid_cases_without_exclusions.with_columns(\n",
    "    pl.col('case').fill_null(0)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demographics_df = demographics_df.join(procedure_df, on='person_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_sarcoid_cases = all_sarcoid_cases.join(procedure_df, on='person_id', how='left')\n",
    "sarcoid_cases_without_exclusions = sarcoid_cases_without_exclusions.join(procedure_df, on='person_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_sarcoid_cases.write_csv(f'{bucket}/data/cohorts/all_sarcoid_cases.csv')\n",
    "sarcoid_cases_without_exclusions.write_csv(f'{bucket}/data/cohorts/sarcoid_cases_without_exclusions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_sarcoid_cases_pd = all_sarcoid_cases.to_pandas()\n",
    "sarcoid_cases_without_exclusions_pd = sarcoid_cases_without_exclusions.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_sarcoid_cases_pd = pd.read_csv(f'{bucket}/data/cohorts/all_sarcoid_cases.csv')\n",
    "# sarcoid_cases_without_exclusions_pd = pd.read_csv(f'{bucket}/data/cohorts/sarcoid_cases_without_exclusions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_covariates(df, sarcoid=True):\n",
    "    age_bins = [17, 24, 34, 44, 54, 64, 74, float('inf')]\n",
    "    age_labels = ['17_24', '25_34', '35_44', '45_54', '55_64', '65_74', '75_plus']\n",
    "    dx_labels = ['dx_17_24', 'dx_25_34', 'dx_35_44', 'dx_45_54', 'dx_55_64', 'dx_65_74', 'dx_75_plus']\n",
    "\n",
    "    # Create binary columns for each age group\n",
    "    for i, label in enumerate(age_labels):\n",
    "        df[label] = ((df['end_of_study_age'] >= age_bins[i]) & (df['end_of_study_age'] < age_bins[i + 1])).astype(int)\n",
    "    if sarcoid:\n",
    "        for i, label in enumerate(dx_labels):\n",
    "            df[label] = ((df['age_at_diagnosis'] >= age_bins[i]) & (df['age_at_diagnosis'] < age_bins[i + 1])).astype(int)\n",
    "\n",
    "    # Handling sex_at_birth with specified conditions\n",
    "    conditions_sex = {'Female': 1, 'Male': 0, 'NoMatch': -9, 'Skip': -9, 'PNA': -9, 'Intersex': -9}\n",
    "    df['female'] = df['sex_at_birth'].map(conditions_sex).fillna(-9)\n",
    "    \n",
    "    # Race\n",
    "    df['black'] = (df['race'] == 'Black').astype(int)\n",
    "    df['asian'] = (df['race'] == 'Asian').astype(int)\n",
    "    df['nhpi'] = (df['race'] == 'NHPI').astype(int)\n",
    "    df['multip'] = (df['race'] == 'Multip').astype(int)\n",
    "    df['white'] = (df['race'] == 'White').astype(int)\n",
    "    df['mena'] = (df['race'] == 'MENA').astype(int)\n",
    "    df['aian'] = (df['race'] == 'AIAN').astype(int)\n",
    "    df['race_none'] = (df['race'] == 'None').astype(int)\n",
    "    df['race_NoInd'] = (df['race'] == 'NoInd').astype(int)\n",
    "    df['race_skip'] = ((df['race'] == 'Skip') | (df['race'] == 'PNA')).astype(int)\n",
    "\n",
    "    # Ethnicity\n",
    "    df['hispanic'] = (df['ethnicity'] == 'HispLat').astype(int)\n",
    "    df['not_hispanic'] = (df['ethnicity'] == 'NotHisp').astype(int)\n",
    "    df['ethnicity_none'] = ((df['ethnicity'] == 'None') | (df['ethnicity'] == 'NoMatch')).astype(int)\n",
    "    df['ethnicity_skip'] = ((df['ethnicity'] == 'Skip') | (df['ethnicity'] == 'PNA')).astype(int)\n",
    "\n",
    "    # Employment\n",
    "    df['employed'] = (df['employ'] == 'employed').astype(int)\n",
    "    df['student'] = (df['employ'] == 'student').astype(int)\n",
    "    df['homemaker'] = (df['employ'] == 'homemaker').astype(int)\n",
    "    df['retired'] = (df['employ'] == 'retired').astype(int)\n",
    "    df['out_of_work'] = (df['employ'] == 'out of work').astype(int)\n",
    "    df['disabled'] = (df['employ'] == 'disabled').astype(int)\n",
    "    df['emp_skip'] = (df['employ'] == 'unk_skip').astype(int)\n",
    "\n",
    "    # Income\n",
    "    df['less_25'] = ((df['income'] == 'less_10') | (df['income'] == '10_25')).astype(int)\n",
    "    df['25_100'] = ((df['income'] == '25_35') | (df['income'] == '35_50') | (df['income'] == '50_75') | (df['income'] == '75_100')).astype(int)\n",
    "    df['100_more'] = ((df['income'] == '100_150') | (df['income'] == '150_200') | (df['income'] == '200_more')).astype(int)\n",
    "    df['inc_skip'] = (df['income'] == 'skip').astype(int)\n",
    "\n",
    "    # Education\n",
    "    df['edu_none'] = (df['edu'] == 'none').astype(int)\n",
    "    df['k_12'] = ((df['edu'] == '1_4') | (df['edu'] == '5_8') | (df['edu'] == '9_11') | (df['edu'] == '12_GED')).astype(int)\n",
    "    df['coll_1_3'] = (df['edu'] == 'coll_1_3').astype(int)\n",
    "    df['coll_grad'] = (df['edu'] == 'coll_grad').astype(int)\n",
    "    df['adv_degree'] = (df['edu'] == 'adv_degree').astype(int)\n",
    "    df['edu_skip'] = (df['edu'] == 'skip').astype(int)\n",
    "\n",
    "    # Insurance type\n",
    "    df['medicaid'] = (df['ins_type'] == 'medicaid').astype(int)\n",
    "    df['medicare'] = (df['ins_type'] == 'medicare').astype(int)\n",
    "    df['emp'] = (df['ins_type'] == 'emp').astype(int)\n",
    "    df['none'] = (df['ins_type'] == 'none').astype(int)\n",
    "    df['other'] = ((df['ins_type'] == 'ihs') | (df['ins_type'] == 'purchased other') | (df['ins_type'] == 'military') | (df['ins_type'] == 'va')).astype(int)\n",
    "    df['ins_skip'] = (df['ins_type'] == '-9').astype(int)\n",
    "\n",
    "    # Sarcoid finginds\n",
    "    conditions = ['cxr', 'ct_chest', 'pulm_bx', 'non_pulm_bx', 'pft', 'ecg', 'leukopenia', \n",
    "                  'thrombocytopenia', 'pbe', 'hypercalcemia', 'elevated_ace', 'elevated_ap', \n",
    "                  'low_25_d', 'high_1_25_d', 'vit_d_deficiency', 'high_a1at', 'elevated_sil2']\n",
    "\n",
    "    for cond in conditions:\n",
    "        # Check if condition case date exists (not null) - 1 if ever had condition, 0 if never\n",
    "        df[cond] = df[f'{cond}_1'].notna().astype(int)\n",
    "\n",
    "    return df\n",
    "\n",
    "# Apply the function\n",
    "all_sarcoid_cases_pd = update_covariates(all_sarcoid_cases_pd, sarcoid=True)\n",
    "sarcoid_cases_without_exclusions_pd = update_covariates(sarcoid_cases_without_exclusions_pd, sarcoid=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demographics_df = demographics_df.to_pandas()\n",
    "demographics_df = update_covariates(demographics_df, sarcoid=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def describe_group(df, sarcoid=True):\n",
    "    \"\"\"\n",
    "    Generate descriptive statistics for a group within the DataFrame.\n",
    "    \"\"\"\n",
    "    def custom_format(x):\n",
    "        return f\"{x:.1f}\".rstrip('0').rstrip('.') if not pd.isna(x) else \"NaN\"\n",
    "\n",
    "    # Descriptive statistics for continuous variables\n",
    "    age_desc = df['end_of_study_age'].agg(['median', lambda x: x.quantile(0.25), lambda x: x.quantile(0.75)]).map(custom_format)\n",
    "    \n",
    "    if sarcoid == True:\n",
    "        dx_age_desc = df['age_at_diagnosis'].agg(['median', lambda x: x.quantile(0.25), lambda x: x.quantile(0.75)]).map(custom_format)\n",
    "\n",
    "    # Count and percentages for categorical variables\n",
    "    def calc_percentage(col):\n",
    "        valid_data = df[col][df[col] != -9]\n",
    "        count = valid_data.sum()\n",
    "        total = valid_data.count()\n",
    "        perc = np.round(count / total * 100, 1) if total != 0 else 0\n",
    "        \n",
    "        # Handle small counts\n",
    "        if 1 <= count < 20:\n",
    "            count_str = \"< 20\"\n",
    "            perc_str = f\"< {np.round(20/total * 100, 1)}\"\n",
    "        else:\n",
    "            count_str = str(count)\n",
    "            perc_str = custom_format(perc)\n",
    "\n",
    "        # Only include total if different from df length\n",
    "        output = f\"{count_str} ({perc_str})\" if total == len(df) else f\"{count_str}/{total} ({perc_str})\"\n",
    "        return output\n",
    "\n",
    "    # Applying calc_percentage to various columns\n",
    "    demographics_percentages = {col: calc_percentage(col) for col in ['female', 'white', 'race_skip', 'black', \n",
    "                                                                      'asian', 'multip', 'mena', 'aian', 'nhpi', \n",
    "                                                                      'race_none', 'race_NoInd', 'hispanic']}\n",
    "\n",
    "    # Applying calc_percentage to various columns\n",
    "    ses_percentages = {col: calc_percentage(col) for col in ['employed', 'retired', 'disabled', 'student', 'homemaker', 'out_of_work', \n",
    "                                                             'emp_skip', 'less_25', '25_100', '100_more', 'inc_skip', 'edu_none', 'k_12',\n",
    "                                                             'coll_1_3', 'coll_grad', 'adv_degree', 'edu_skip', 'medicare', \n",
    "                                                             'medicaid', 'emp', 'none', 'other', 'ins_skip']}\n",
    "    # Sarcoid conditions\n",
    "    conditions_percentages = {col: calc_percentage(col) for col in ['cxr', 'ct_chest', 'pulm_bx', \n",
    "                                                                    'non_pulm_bx', 'pft', 'ecg', 'leukopenia', \n",
    "                                                                    'thrombocytopenia', 'pbe', 'hypercalcemia', \n",
    "                                                                    'elevated_ace', 'elevated_ap',\n",
    "                                                                    'low_25_d', 'high_1_25_d', \n",
    "                                                                    'vit_d_deficiency', 'high_a1at', \n",
    "                                                                    'elevated_sil2']}\n",
    "\n",
    "    # Building the results dictionary\n",
    "    if sarcoid == True:\n",
    "        results = {\n",
    "            'Total': len(df),\n",
    "            'End of Study Age, median (IQR)': f\"{age_desc['median']} ({age_desc.iloc[1]}, {age_desc.iloc[2]})\",\n",
    "            'Sarcoid Dx Age, median (IQR)': f\"{dx_age_desc['median']} ({dx_age_desc.iloc[1]}, {dx_age_desc.iloc[2]})\",\n",
    "            **{f\"{key.capitalize()} (n (%))\": value for key, value in demographics_percentages.items()},\n",
    "            **{f\"{key.capitalize()} (n (%))\": value for key, value in ses_percentages.items()},\n",
    "            **{f\"{key.capitalize()} (n (%))\": value for key, value in conditions_percentages.items()}\n",
    "        }    \n",
    "    else:\n",
    "        results = {\n",
    "            'Total': len(df),\n",
    "            'End of Study Age, median (IQR)': f\"{age_desc['median']} ({age_desc.iloc[1]}, {age_desc.iloc[2]})\",\n",
    "            'Sarcoid Dx Age, median (IQR)': f\"NA\",\n",
    "            **{f\"{key.capitalize()} (n (%))\": value for key, value in demographics_percentages.items()},\n",
    "            **{f\"{key.capitalize()} (n (%))\": value for key, value in ses_percentages.items()},\n",
    "            **{f\"{key.capitalize()} (n (%))\": value for key, value in conditions_percentages.items()}\n",
    "        }           \n",
    "\n",
    "    return pd.DataFrame(results, index=[0])\n",
    "\n",
    "total_ehr_cohort = describe_group(demographics_df, sarcoid=False)\n",
    "        \n",
    "all_summaries = pd.concat([\n",
    "    describe_group(all_sarcoid_cases_pd[(all_sarcoid_cases_pd[\"case\"]==1) & (all_sarcoid_cases_pd[\"sarcoid_n\"]==1)]), \n",
    "    describe_group(all_sarcoid_cases_pd[(all_sarcoid_cases_pd[\"case\"]==1) & (all_sarcoid_cases_pd[\"sarcoid_n\"]>=1)]), \n",
    "    describe_group(all_sarcoid_cases_pd[(all_sarcoid_cases_pd[\"case\"]==1) & (all_sarcoid_cases_pd[\"sarcoid_n\"]>=2)]), \n",
    "    describe_group(sarcoid_cases_without_exclusions_pd[(sarcoid_cases_without_exclusions_pd[\"case\"]==1) & (all_sarcoid_cases_pd[\"sarcoid_n\"]==1)]), \n",
    "    describe_group(sarcoid_cases_without_exclusions_pd[(sarcoid_cases_without_exclusions_pd[\"case\"]==1) & (all_sarcoid_cases_pd[\"sarcoid_n\"]>=1)]), \n",
    "    describe_group(sarcoid_cases_without_exclusions_pd[(sarcoid_cases_without_exclusions_pd[\"case\"]==1) & (all_sarcoid_cases_pd[\"sarcoid_n\"]>=2)]), \n",
    "    ],\n",
    "    keys=[\"All Sarcoid Cases (1 Phecode Only)\", \n",
    "        \"All Sarcoid Cases (1 Phecode)\", \n",
    "        \"All Sarcoid Cases (2 Phecodes)\",\n",
    "        \"Sarcoid Cases Without Exclusions (Phecode Only)\",\n",
    "        \"Sarcoid Cases Without Exclusions (1 Phecode)\",\n",
    "        \"Sarcoid Cases Without Exclusions (2 Phecodes)\"]\n",
    ")\n",
    "\n",
    "# Then concatenate with total_ehr_cohort using a single-level index\n",
    "table_1 = pd.concat([\n",
    "    pd.DataFrame(total_ehr_cohort).assign(category='Total Cohort'),\n",
    "    pd.DataFrame(all_summaries).assign(category='')\n",
    "]).set_index('category', append=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transposed_table = table_1.transpose()\n",
    "transposed_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PheWAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PheTK.PheWAS import PheWAS\n",
    "from PheTK.Phecode import Phecode\n",
    "from PheTK.Plot import Plot\n",
    "from PheTK.Cohort import Cohort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phecode = Phecode(platform=\"aou\")\n",
    "phecode.count_phecode(\n",
    "    phecode_version=\"X\", \n",
    "    icd_version=\"US\",\n",
    "    phecode_map_file_path=None, \n",
    "    output_file_name=\"phecode_X_counts.csv\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_ehr_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_sarcoid_cases_pd[\"case\"] = 1\n",
    "sarcoid_cases_without_exclusions_pd[\"case\"] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Merge and fillna for all_sarcoid_cases\n",
    "all_sarcoid_cases_cohort = demographics_df.merge(\n",
    "    all_sarcoid_cases_pd[['person_id', 'case']],\n",
    "    on='person_id',\n",
    "    how='left'\n",
    ")\n",
    "all_sarcoid_cases_cohort['case'] = all_sarcoid_cases_cohort['case'].fillna(0)\n",
    "all_sarcoid_cases_cohort = all_sarcoid_cases_cohort[all_sarcoid_cases_cohort['female'] != -9]\n",
    "all_sarcoid_cases_cohort['female'] = all_sarcoid_cases_cohort['female'].map({1: 0, 0: 1})\n",
    "\n",
    "# Save to CSV\n",
    "all_sarcoid_cases_cohort.to_csv('all_sarcoid_cases_cohort.csv', index=False)\n",
    "\n",
    "# Merge and fillna for sarcoid_cases_without_exclusions\n",
    "sarcoid_cases_without_exclusions_df = demographics_df.merge(\n",
    "    sarcoid_cases_without_exclusions_pd[['person_id', 'case']],\n",
    "    on='person_id',\n",
    "    how='left'\n",
    ")\n",
    "sarcoid_cases_without_exclusions_df['case'] = sarcoid_cases_without_exclusions_df['case'].fillna(0)\n",
    "sarcoid_cases_without_exclusions_df = sarcoid_cases_without_exclusions_df[sarcoid_cases_without_exclusions_df['female'] != -9]\n",
    "sarcoid_cases_without_exclusions_df['female'] = sarcoid_cases_without_exclusions_df['female'].map({1: 0, 0: 1})\n",
    "\n",
    "# Save to CSV\n",
    "sarcoid_cases_without_exclusions_df.to_csv('sarcoid_cases_without_exclusions_cohort.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sarcoid_cases_without_exclusions_df.value_counts('female')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_sarcoid_phewas = PheWAS(\n",
    "    phecode_version=\"X\",\n",
    "    phecode_count_csv_path=\"phecode_X_counts.csv\",\n",
    "    cohort_csv_path=\"all_sarcoid_cases_cohort.csv\",\n",
    "    sex_at_birth_col=\"female\",\n",
    "    male_as_one=True,\n",
    "    covariate_cols=[\"end_of_study_age\", \"female\", \"white\", \"black\", \"asian\", \"hispanic\"],\n",
    "    independent_variable_of_interest=\"case\",\n",
    "    min_cases=50,\n",
    "    min_phecode_count=2,\n",
    "    output_file_name=\"all_sarcoid_phewas_results.csv\"\n",
    ")\n",
    "all_sarcoid_phewas.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sarcoid_without_exclusions_phewas = PheWAS(\n",
    "    phecode_version=\"X\",\n",
    "    phecode_count_csv_path=\"phecode_X_counts.csv\",\n",
    "    cohort_csv_path=\"sarcoid_cases_without_exclusions_cohort.csv\",\n",
    "    sex_at_birth_col=\"female\",\n",
    "    male_as_one=True,\n",
    "    covariate_cols=[\"end_of_study_age\", \"female\", \"white\", \"black\", \"asian\", \"hispanic\"],\n",
    "    independent_variable_of_interest=\"case\",\n",
    "    min_cases=50,\n",
    "    min_phecode_count=2,\n",
    "    output_file_name=\"sarcoid_without_exclusions_phewas_results.csv\"\n",
    ")\n",
    "sarcoid_without_exclusions_phewas.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = Plot(\"all_sarcoid_phewas_results.csv\")\n",
    "p.manhattan(label_values=\"p_value\", label_count=25, save_plot=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = Plot(\"sarcoid_without_exclusions_phewas_results.csv\")\n",
    "p.manhattan(label_values=\"p_value\", label_count=25, save_plot=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pgrm_bucket = '{bucket or my_bucket}'\n",
    "acaf_person_id_df = pl.read_csv(f'{pgrm_bucket}/data/hail/pgrm_filtered_acaf_plink.fam', \n",
    "                                separator=\"\\t\", \n",
    "                                new_columns=[\"A\",\"B\",\"C\",\"D\",\"E\",\"F\"])\n",
    "\n",
    "acaf_person_id_df = acaf_person_id_df.select('B')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_sarcoid_cases = pl.read_csv('all_sarcoid_cases.csv', try_parse_dates=True)\n",
    "sarcoid_cases_without_exclusions = pl.read_csv('sarcoid_cases_without_exclusions.csv', try_parse_dates=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Count people who are both in sarcoid_cases_without_exclusions with case=1 and in acaf_person_id_df\n",
    "overlap_count = (\n",
    "    sarcoid_cases_without_exclusions\n",
    "    .filter(pl.col(\"case\") == 1)\n",
    "    .join(\n",
    "        acaf_person_id_df.select(pl.col(\"B\").alias(\"person_id\")),\n",
    "        on=\"person_id\",\n",
    "        how=\"inner\"\n",
    "    )\n",
    "    .select(pl.len())\n",
    "    .item()\n",
    ")\n",
    "\n",
    "print(f\"Number of people with case=1 that are also in acaf_person_id_df: {overlap_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zip3"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "exclusion_cols = [\n",
    "    'tb_2', 'tb_skin_2', 'ntm_2', 'histo_2', 'blasto_2', 'cocci_2', \n",
    "    'asp_2', 'ild_2', 'hp_2', 'pneumoconiosis_2', 'vasc_2', 'cvid_2', \n",
    "    'igg4_2', 'lymphoma_2', 'lg_2', 'lung_ca_2', 'lch_2', 'ibd_2', \n",
    "    'pbc_2', 'aih_2', 'hiv_2', 'drug_2'\n",
    "]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Map of column names to more readable labels (remove '_2' suffix)\n",
    "exclusion_labels = {col: col.replace('_2', '') for col in exclusion_cols}"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "exclusion_labels = {\n",
    "    'tb_2': 'tb',\n",
    "    'tb_skin_2': 'abnormal_tb_skin_test',\n",
    "    'ntm_2': 'ntm',\n",
    "    'histo_2': 'histo',\n",
    "    'blasto_2': 'blasto',\n",
    "    'cocci_2': 'cocci',\n",
    "    'asp_2': 'aspergillus',\n",
    "    'ild_2': 'ild',\n",
    "    'hp_2': 'hp',\n",
    "    'pneumoconiosis_2': 'pneumoconiosis',\n",
    "    'vasc_2': 'vasculitis',\n",
    "    'cvid_2': 'cvid',\n",
    "    'igg4_2': 'igg4',\n",
    "    'lymphoma_2': 'lymphoma',\n",
    "    'lg_2': 'lymphomatoid granulomatosis',\n",
    "    'lung_ca_2': 'lung_ca',\n",
    "    'lch_2': 'langerhans_cell_histiocytosis',\n",
    "    'ibd_2': 'ibd',\n",
    "    'pbc_2': 'pbc',\n",
    "    'aih_2': 'autoimmune_hepatitis',\n",
    "    'hiv_2': 'hiv',\n",
    "    'drug_2': 'drug'\n",
    "}"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Create the 'exclusion' column with a list of labels where the date is not null\n",
    "sarcoid_with_exclusions = sarcoid_with_exclusions.with_columns([\n",
    "    pl.concat_list([\n",
    "        pl.when(pl.col(col).is_not_null()).then(pl.lit(exclusion_labels[col])).otherwise(pl.lit(None))\n",
    "        for col in exclusion_cols\n",
    "    ]).alias('exclusion')\n",
    "])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "sarcoid_with_exclusions = sarcoid_with_exclusions.with_columns([\n",
    "    pl.col('exclusion').list.eval(pl.element().filter(pl.element().is_not_null())).alias('exclusion')\n",
    "])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# sarcoid_with_exclusions = sarcoid_with_exclusions.select(['person_id', 'sarcoid_1', 'exclusion'])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "total_cohort_q = f\"\"\"\n",
    "        WITH combined AS (\n",
    "            \n",
    "            -- Codes from observation (source_value)\n",
    "            SELECT o.person_id\n",
    "            FROM {dataset}.observation AS o\n",
    "            JOIN {dataset}.concept AS c ON o.observation_source_value = c.concept_code\n",
    "            WHERE c.vocabulary_id IN ('ICD9CM', 'ICD10CM', 'SNOMED')\n",
    "\n",
    "            UNION ALL\n",
    "\n",
    "            -- Codes from observation (source_concept_id)\n",
    "            SELECT o.person_id\n",
    "            FROM {dataset}.observation AS o\n",
    "            JOIN {dataset}.concept AS c ON o.observation_source_concept_id = c.concept_id\n",
    "            WHERE c.vocabulary_id IN ('ICD9CM', 'ICD10CM', 'SNOMED')\n",
    "\n",
    "            UNION ALL\n",
    "\n",
    "            -- Codes from condition_occurrence (source_value)\n",
    "            SELECT co.person_id\n",
    "            FROM {dataset}.condition_occurrence AS co\n",
    "            JOIN {dataset}.concept AS c ON co.condition_source_value = c.concept_code\n",
    "            WHERE c.vocabulary_id IN ('ICD9CM', 'ICD10CM', 'SNOMED')\n",
    "\n",
    "            UNION ALL\n",
    "\n",
    "            -- Codes from condition_occurrence (source_concept_id)\n",
    "            SELECT co.person_id\n",
    "            FROM {dataset}.condition_occurrence AS co\n",
    "            JOIN {dataset}.concept AS c ON co.condition_source_concept_id = c.concept_id\n",
    "            WHERE c.vocabulary_id IN ('ICD9CM', 'ICD10CM', 'SNOMED')            \n",
    "        ),\n",
    "        zip AS (\n",
    "            SELECT\n",
    "                observation.person_id,\n",
    "                value_as_string as zip_code\n",
    "            FROM\n",
    "                {dataset}.observation observation\n",
    "            WHERE\n",
    "                observation_source_concept_id = 1585250\n",
    "        )\n",
    "  \n",
    "        SELECT\n",
    "            DISTINCT c.person_id,\n",
    "            zip_code\n",
    "        FROM combined AS c\n",
    "        JOIN zip AS z ON c.person_id = z.person_id\n",
    "\"\"\"\n",
    "\n",
    "zip_df = polars_gbq(total_cohort_q)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "zip_df = zip_df.join(\n",
    "    sarcoid_with_exclusions,\n",
    "    on='person_id',\n",
    "    how='left'\n",
    ")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Trim zip_code to first three digits and create a new column zip_3\n",
    "zip_df = zip_df.with_columns([\n",
    "    pl.col(\"zip_code\").str.slice(0, 3).alias(\"zip_3\")\n",
    "]).drop('zip_code')\n",
    "\n",
    "zip_df = zip_df.with_columns([\n",
    "    pl.when(pl.col(\"sarcoid_1\").is_not_null())\n",
    "    .then(pl.lit(1))\n",
    "    .otherwise(pl.lit(0))\n",
    "    .alias(\"case\")\n",
    "])\n",
    "\n",
    "# Fill NA values in exclusion column with empty list\n",
    "zip_df = zip_df.with_columns([\n",
    "    pl.when(pl.col(\"exclusion\").is_null())\n",
    "    .then(pl.lit([]))\n",
    "    .otherwise(pl.col(\"exclusion\"))\n",
    "    .alias(\"exclusion\")\n",
    "])\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Select the desired columns\n",
    "result_df = zip_df.select(['case', 'sarcoid_1', 'exclusion', 'zip_3'])\n",
    "\n",
    "result_df = result_df.with_columns([\n",
    "    pl.col(\"exclusion\").list.join(\", \").alias(\"exclusion_str\")\n",
    "])\n",
    "\n",
    "# Drop the original list column\n",
    "result_df = result_df.drop(\"exclusion\")\n",
    "\n",
    "# Now save to TSV\n",
    "result_df.write_csv(\"sarcoid_zip3.tsv\", separator=\"\\t\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Create sarcoid_zip3 DataFrame (cases by zip code)\n",
    "sarcoid_zip3 = (\n",
    "    result_df\n",
    "    .filter(pl.col(\"case\") == 1)\n",
    "    .group_by(\"zip_3\")\n",
    "    .agg(pl.count().alias(\"case_count\"))\n",
    "    .sort(\"zip_3\")\n",
    ")\n",
    "\n",
    "# Create control_zip3 DataFrame (controls by zip code)\n",
    "control_zip3 = (\n",
    "    result_df\n",
    "    .filter(pl.col(\"case\") == 0)\n",
    "    .group_by(\"zip_3\")\n",
    "    .agg(pl.count().alias(\"control_count\"))\n",
    "    .sort(\"zip_3\")\n",
    ")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "sarcoid_zip3.write_csv('sarcoid_zip3_trim.tsv', separator='\\t')\n",
    "control_zip3.write_csv('control_zip3_trim.tsv', separator='\\t')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "263px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
