{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load libraries\n",
    "from IPython.display import display, HTML\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "\n",
    "import os\n",
    "import subprocess\n",
    "\n",
    "version = %env WORKSPACE_CDR\n",
    "my_bucket = os.getenv('WORKSPACE_BUCKET')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !gsutil ls {my_bucket}/data/stg009/eur/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_dsub_status(user=None, full=False):\n",
    "    \"\"\"Check status of dsub jobs for the specified user\"\"\"\n",
    "    if user is None:\n",
    "        # Get current user if not specified\n",
    "        user = os.getenv(\"OWNER_EMAIL\").split('@')[0]\n",
    "    \n",
    "    project = os.getenv(\"GOOGLE_PROJECT\")\n",
    "\n",
    "    if full:\n",
    "        make_full = ' --full'\n",
    "    else:\n",
    "        make_full = ''\n",
    "    \n",
    "    cmd = f\"dstat --provider google-cls-v2 --user {user} --status '*' --project {project}{make_full}\"\n",
    "    # cmd = f\"ddel --provider google-cls-v2 --project terra-vpc-sc-840afe1e --location us-central1 --jobs 'transances--bwaxse--250319-022343-75' --users 'bwaxse'\"\n",
    "    print(f\"Running: {cmd}\")\n",
    "    return subprocess.run(cmd, shell=True, capture_output=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def job_details(user=None, job=None):\n",
    "    \"\"\"List all jobs for the user, including failed ones\"\"\"\n",
    "    project = os.getenv(\"GOOGLE_PROJECT\")\n",
    "    \n",
    "    if user is None:\n",
    "        user = os.getenv(\"OWNER_EMAIL\").split('@')[0]\n",
    "        \n",
    "    if job is None:\n",
    "        job = \"'*' \"\n",
    "    else:\n",
    "        job = f'--jobs {job} '\n",
    "    \n",
    "    cmd = f\"dstat --provider google-cls-v2 --project {project} --user {user} --status {job}--full\"\n",
    "    print(f\"Running: {cmd}\")\n",
    "    return subprocess.run(cmd, shell=True, capture_output=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cancel_running_jobs():\n",
    "    \"\"\"Cancel only running/pending jobs (safer)\"\"\"\n",
    "    project = os.getenv(\"GOOGLE_PROJECT\")\n",
    "    \n",
    "    # Cancel only running jobs\n",
    "    cancel_cmd = f\"ddel --provider google-cls-v2 --project {project} --users 'bwaxse' --jobs '*'\"\n",
    "    print(f\"Canceling running jobs: {cancel_cmd}\")\n",
    "    \n",
    "    return subprocess.run(cancel_cmd, shell=True, capture_output=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cancel_job(job_id):\n",
    "    \"\"\"Cancel a specific job\"\"\"\n",
    "    project = os.getenv(\"GOOGLE_PROJECT\")\n",
    "    \n",
    "    cmd = f\"ddel --provider google-cls-v2 --project {project} --jobs {job_id}\"\n",
    "    print(f\"Running: {cmd}\")\n",
    "    return subprocess.run(cmd, shell=True, capture_output=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variant filter script and function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile run_vcf_export.sh\n",
    "\n",
    "#!/bin/bash\n",
    "\n",
    "# VCF export for single chromosome\n",
    "# Input: Single chromosome pgen files by ancestry\n",
    "# Output: Single chromosome vcf file by ancestry\n",
    "\n",
    "INPUT_PGEN_BASE=\"${INPUT_PGEN_PGEN%.*}\"  # Remove .pgen extension\n",
    "echo \"Derived INPUT_PGEN_BASE: $INPUT_PGEN_BASE\"\n",
    "\n",
    "nthread=$(python -c \"import os; print(len(os.sched_getaffinity(0)))\");\n",
    "echo \"Running with $nthread threads\";\n",
    "\n",
    "OUTPUT_PREFIX=\"${OUTPUT_RESULTS%\\*}\"\n",
    "# Set ancestry-specific output\n",
    "\n",
    "echo \"Processing ancestry: $ANCESTRY, chromosome: $CHROM\"\n",
    "echo \"Output prefix: $OUTPUT_PREFIX\"\n",
    "\n",
    "echo \"Converting pgen to vcf\"\n",
    "plink2 \\\n",
    "    --pfile $INPUT_PGEN_BASE \\\n",
    "    --export vcf bgz \\\n",
    "    --threads $nthread \\\n",
    "    --out $OUTPUT_PREFIX\n",
    "\n",
    "# Index the VCF (creates .tbi and .csi)\n",
    "echo \"Creating tabix index\"\n",
    "tabix -p vcf ${OUTPUT_PREFIX}.vcf.gz\n",
    "bcftools index -c ${OUTPUT_PREFIX}.vcf.gz\n",
    "\n",
    "echo \"vcf output complete for $ANCESTRY\"\n",
    "echo \"Files created with prefix: $OUTPUT_PREFIX\"\n",
    "ls -la ${OUTPUT_PREFIX}*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_file_list(query_dir):\n",
    "    tmp = subprocess.run(\n",
    "        f'gsutil ls {query_dir}',\n",
    "        shell=True,\n",
    "        capture_output=True\n",
    "    )\n",
    "    files = tmp.stdout.decode('utf-8').split('\\n')\n",
    "    return(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dsub_script(\n",
    "    machine_type,\n",
    "    out_base,\n",
    "    anc,\n",
    "    chrom=1,\n",
    "    boot_disk=100,\n",
    "    disk_size=100,\n",
    "    memory=12000,\n",
    "    script='run_vcf_export.sh'\n",
    "):\n",
    "    \n",
    "    # get useful info\n",
    "    dsub_user_name = os.getenv(\"OWNER_EMAIL\").split('@')[0]\n",
    "    user_name = os.getenv(\"OWNER_EMAIL\").split('@')[0].replace('.', '-')\n",
    "\n",
    "    job_name = f'{anc}_{chrom}_vcf_export'\n",
    "\n",
    "    # Template for input files (will be substituted in script)\n",
    "    my_bucket = os.getenv('WORKSPACE_BUCKET') \n",
    "    input_pgen_base = f'gs://fc-aou-datasets-controlled/v8/wgs/short_read/snpindel/acaf_threshold/pgen/acaf_threshold.chr{chrom}'\n",
    "    \n",
    "    # Build dsub command\n",
    "    cmd = [\n",
    "        'dsub',\n",
    "        '--provider', 'google-cls-v2',\n",
    "        '--machine-type', machine_type,\n",
    "        '--disk-type', 'pd-ssd',\n",
    "        '--boot-disk-size', str(boot_disk),\n",
    "        '--disk-size', str(disk_size),\n",
    "        '--user-project', os.environ['GOOGLE_PROJECT'],\n",
    "        '--project', os.environ['GOOGLE_PROJECT'],\n",
    "        '--image', 'us.gcr.io/broad-dsp-gcr-public/terra-jupyter-aou:2.2.14',\n",
    "        '--network', 'network',\n",
    "        '--subnetwork', 'subnetwork',\n",
    "        '--service-account', subprocess.check_output(['gcloud', 'config', 'get-value', 'account']).decode().strip(),\n",
    "        '--user', dsub_user_name,\n",
    "        '--logging', f\"{os.environ['WORKSPACE_BUCKET']}/dsub/logs/{{job-name}}/{{user-id}}/{{job-id}}-{{task-id}}-{{task-attempt}}.log\",\n",
    "        '--name', job_name,\n",
    "        '--env', f'GOOGLE_PROJECT={os.environ[\"GOOGLE_PROJECT\"]}',\n",
    "        '--env', f'ANCESTRY={anc}',\n",
    "        '--env', f'CHROM={chrom}',\n",
    "        # Input files\n",
    "        '--input', f'INPUT_PGEN_PGEN={input_pgen_base}.pgen',\n",
    "        '--input', f'INPUT_PGEN_PSAM={input_pgen_base}.psam', \n",
    "        '--input', f'INPUT_PGEN_PVAR={input_pgen_base}.pvar',\n",
    "        # Output files\n",
    "        '--output', f'OUTPUT_RESULTS={out_base}*',\n",
    "        '--script', script\n",
    "    ]\n",
    "            \n",
    "    subprocess.run(cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_vcf_export(\n",
    "    my_bucket,\n",
    "    ancestries,\n",
    "    script='run_vcf_export.sh',\n",
    "):\n",
    "    \"\"\"\n",
    "    Run VCF export for each ancestry and chromosome\n",
    "    Output: one vcf.gz file with index per ancestry-chromosome\n",
    "    \"\"\"\n",
    "\n",
    "    # Process each chromosome for each ancestry\n",
    "    for chrom in [str(i) for i in range(1, 23)] + ['X', 'Y']:\n",
    "        for anc in ancestries:\n",
    "            # Output directory\n",
    "            out_dir = f'{my_bucket}/data/stg009/{anc}'\n",
    "    \n",
    "            # Check if already exists (check for a few chromosome files)\n",
    "            existing_files = get_file_list(out_dir)\n",
    "            check_chroms = [1, 10, 22]  # Check beginning, middle, end\n",
    "            if any(f'{anc}_genotypes_chr{chrom}.vcf.gz' in f for f in existing_files):\n",
    "                print(f\"VCF files already exist for {anc} chr{chrom}\")\n",
    "                continue  # Skip this combination\n",
    "        \n",
    "            print(f\"Starting serial vcf export for {anc} ancestry...\")\n",
    "\n",
    "            dsub_script(\n",
    "                machine_type='c3-standard-8',\n",
    "                out_base=f'{out_dir}/{anc}_genotypes_chr{chrom}',\n",
    "                anc=anc,\n",
    "                chrom=chrom,\n",
    "                boot_disk=100,\n",
    "                disk_size=100,\n",
    "                script=script\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ancestries_considered = ['eur', 'afr', 'amr', 'eas', 'sas', 'mid']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # Test\n",
    "run_vcf_export(my_bucket, ['mid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_vcf_export(my_bucket, ancestries_considered)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check dsub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_dsub_status(full=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_id = 'mid-22-vcf--bwaxse--250618-175310-96'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_details(job=job_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gsutil cat {bucket or my_bucket}/dsub/logs/mid-22-vcf-export/bwaxse/mid-22-vcf--bwaxse--250618-150520-32-task-None.log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gsutil du -h {bucket or my_bucket}/data/stg009/mid/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
